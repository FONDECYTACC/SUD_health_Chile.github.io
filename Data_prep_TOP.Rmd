---
title: "Data Preparation of TOP Dataset"
description: | 
  Scientific and technical writing about DB standarization, native to the web
Date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide 
    toc: true # table of content true
    toc_depth: 3  # upto three depths of headings (specified by #, ## and ###)
    toc_float: true
  sidebar:
  - title: "Title"
    image: http://placehold.it/350x250
    image_alt: "image"
    text: "Some text here."
  - title: "Another Title"
    text: "More text here."
---

<style type="text/css">
.tablelines table, .tablelines td, .tablelines th {
        border: 1px solid black;
        }
.centrado {
    text-align: center;
}
.table.center {
    margin-left:auto; 
    margin-right:auto;
  }
.table_wrapper{
    display: block;
    overflow-x: auto;
    white-space: nowrap;
}
code.r{
  font-size: 8px;
}
body{ /* Normal  */
      text-align: justify;
  }
</style>



<!---

[//]: # (This is <span style="color: red">written in red</span>.)

[//]: # (Hey! Hover the cursor over me and guess what?! :) {: .purple})

[//]: # (I am in <span style="font-family:Papyrus; font-size:4em;">that!</span>)

[//]: #(#687886)

-->

```{r setup, include=FALSE}
rm(list=ls());gc()
unlink('SUD_CL/Data_prep_TOP_cache', recursive = TRUE)
load("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/3.RData")
#setwd("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/SUD_CL")
#path <-"G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/SUD_CL"
#Libraries used in the routine. Dont change the order
if(!require(tidyr)){install.packages("tidyr")}
if(!require(DataExplorer)){install.packages("DataExplorer")}
if(!require(stringi)){install.packages("stringi", dependencies=TRUE, INSTALL_opts = c('--no-lock'))}
if(!require(stringr)){install.packages("stringr")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(Hmisc)){install.packages("Hmisc")}
if(!require(kableExtra)){install.packages("kableExtra")}
if(!require(plotly)){install.packages("plotly")}
if(!require(rbokeh)){install.packages("rbokeh")}
if(!require(altair)){install.packages("altair")}
if(!require(zoo)){install.packages("zoo")}
if(!require(broom)){install.packages("broom")}
if(!require(sqldf)){install.packages("sqldf")} 
if(!require(data.table)){install.packages("data.table")}
if(!require(dplyr)){install.packages("dplyr")}


```

&nbsp;

TOP or Treatment Outcomes Profile ("Perfil de Resultados de Tratamiento") serves as a tool for monitoring and follow up of SUD treatments. This questionnaire must be completed at entry to treatment, each 3 months during treatment, at treatment discharge and some centers may aaply it after discharg. Hence, it is important to capture the date of application and the date of admission, and in order to characterize each user, it is important to standardize his birth date.

&nbsp;
<br>

### 1. Change Dates of Admission, Aplication of TOP and Birth

As can be seen in Table 1, every date was formatted into dates in a format disposed to show first a 4-digit year, 2-digit month and 2-digit day. Additionally, SENDA's ID was masked to avoid recognition from third parties.

<br>

```{r changes_dates, cache=T}
#create the first changes into TOP dataset
CONS_TOP %>%
  dplyr::mutate(ano_bd=as.numeric(substr(TABLE,4,7))) %>%
  dplyr::mutate(id_mod=sub("(.{5}).", "\\1*",as.character(ID))) %>%
  dplyr::mutate(id_mod=sub("(.{6}).", "\\1*",as.character(id_mod))) %>% 
  dplyr::select(HASH_KEY, hash_rut_completo, id_mod, ID, ano_bd, everything()) %>%
  dplyr::arrange(desc(ano_bd)) %>% 
  assign("CONS_TOP_df",.,envir = .GlobalEnv)

#change dates
CONS_TOP_df %>%
  dplyr::mutate(fech_ing= lubridate::parse_date_time(Fecha.de.Ingreso.a.Tratamiento, c("%d/%m/%Y"),exact=T)) %>% #No parse failures
  #dplyr::select(Fecha.de.Ingreso.a.Tratamiento,fech_ing) %>% head() #To see how it responds to changes. Many null values
  dplyr::mutate(fech_ing_sin_fmt= Fecha.de.Ingreso.a.Tratamiento) %>% #keep this variable for comparison
  dplyr::mutate(fech_ap_top= lubridate::parse_date_time(Fecha.Aplicación.TOP, c("%Y-%m-%d"),exact=T)) %>% #No parse failures
  #dplyr::select(Fecha.Aplicación.TOP,fech_ap_top) %>% head() #To see how it responds to changes.
  dplyr::mutate(fech_nac= lubridate::parse_date_time(str_trim(Fecha.Nacimiento), orders = c("%d/%m/%Y"),exact=T)) %>%
  #dplyr::select(Fecha.Nacimiento,fech_nac) %>% View() #To see how it responds to changes. No failures
  assign("CONS_TOP_df",.,envir = .GlobalEnv) #
#Example of transformations
CONS_TOP_df %>%
  dplyr::select(Fecha.de.Ingreso.a.Tratamiento,fech_ing,Fecha.Aplicación.TOP,fech_ap_top,Fecha.Nacimiento,fech_nac) %>% head() %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 1. Example of date of admission to treatment",
              col.names = c("Unformatted Date of Admission","Date of Admission", "Unformatted Date of Application", "Date of Application", "Unformatted Date of Birth","Date of Birth"),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10)
```

&nbsp;
<br>

In the transformation of the dates of admission, we found an important amount of missing values. However, **there were `r CONS_TOP_df %>% dplyr::filter(is.na(fech_ap_top)) %>% summarise(n())` missing dates of application of the TOP** and  `r CONS_TOP_df %>% dplyr::filter(is.na(fech_nac)) %>% summarise(n())` missing birth dates (despite `r CONS_TOP_df %>% dplyr::filter(!is.na(fech_nac)) %>% dplyr::select(fech_nac) %>% dplyr::filter(fech_nac<"1929-11-01"|fech_nac>"2001-11-01")  %>% nrow()` cases could be invalid according to the criteria stated by SENDA's professionals). **Considering the characteristics of TOP programs and monitoring, it may be possible to impute these dates from the C1 dataset, using the date of application if it is within the ranges of an specific treatment.**

<br>

```{r fech_ing_nas, echo=FALSE, fig.align='center',fig.cap= "Figure 1. Pie Chart of Missing Dates of Admission"}
#Hay un 1% de casos perdidos
CONS_TOP_df %>%
  dplyr::group_by(is.na(Fecha.de.Ingreso.a.Tratamiento)) %>% 
  dplyr::rename("MISS_DATE_ADM"=`is.na(Fecha.de.Ingreso.a.Tratamiento)`) %>% 
  summarise(n=n()) %>% 
  data.frame() %>%  mutate(perc=n/sum(n)) %>%
  ggplot(aes(x="", y=n, fill=MISS_DATE_ADM))+
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start=0) + 
  scale_fill_brewer("Missing Date\nof Admission") + theme_minimal() +
  theme(axis.text.x=element_blank())+
  geom_text(aes(y = n/2 + c(0, cumsum(n)[-length(n)]), 
                label = paste0(formatC(n, format="f", big.mark=",", digits=0), "\n(",scales::percent(perc),")")), size=4) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.border = element_blank(),
    panel.grid=element_blank(),
    axis.ticks = element_blank(),
    plot.title=element_text(size=14, face="bold")
  ) 
```

<br>

Considering that the dates of admission to the treatment and discharge may let us merge the dataset with the correspondent to C1, we need to obtain the remining dates that were missed.

<br>

### 2. Replacing dates.

<br>

In order to replace the dates of admission, we should obtain it not only from the TOP dataset, but also using the C1 agreement. First, we  should identify applications of the TOP that were done for the same stage and for the same HASH, but have dates of admission. 

```{r replace_date_adm}
CONS_TOP_df_dup_fech_ing_adm <- dplyr::select(CONS_TOP_df, HASH_KEY, fech_ap_top, fech_ing, TOP)%>% 
  dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") 
CONS_TOP_df_dup_fech_ing <- dplyr::select(CONS_TOP_df, HASH_KEY, fech_ap_top, fech_ing, TOP)%>% 
  dplyr::filter(!is.na(fech_ing)) 
nrow(CONS_TOP_df_dup_fech_ing) ##DESPITE HAS MORE ROWS, DOES NOT MAKE A DIFFERENCE IN THE QUANTITY
nrow(CONS_TOP_df_dup_fech_ing_adm)
#Join datasets 
dplyr::left_join(CONS_TOP_df,CONS_TOP_df_dup_fech_ing_adm, by = c("HASH_KEY", "fech_ap_top"), suffix = c("", ".y")) %>% #names() #junto con la BD que hice
  dplyr::filter(!is.na(fech_ing.y), is.na(fech_ing)) %>%  #filtro los casos que en que sí tengo fecha de ingreso en el merge, pero no la tengo en la BD.
  dplyr::select(row,ano_bd, HASH_KEY, hash_rut_completo, id_mod, Edad, Sexo, fech_ing, fech_ap_top, TOP, fech_ing.y) %>% #dejo para ver cómo la icorporo
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table XX. HASHs with missing dates of admission that can be replaced by",
              col.names = c("Row ID","Year of Dataset", "HASH KEY","HASH Key (Alternative)","SENDA's ID", "Year", "Sex", "Date of Admission", "Date of Application","Stage of TOP", "Date of Admission (replacement)" ),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
            scroll_box(width = "100%", height = "350px")
```



### 3. Inconsistencies between SENDA's ID and HASH Key

<br>

In order to check whether individual IDs (RUT) masked into HASH keys are consistent by each SENDA's ID and do not depend on other factors (eg., how the individual ID was written in the computer), we searched for more than one HASH Key in each SENDA's ID. There were 33 IDs that had more than one HASH key. These 33 IDs affect 183 registries. **They will be sent to SENDA's professionals and check what would be the cause of the differences**.

<br>

```{r inconsistencies_in_id}
    #Take which has a combination of IDs and HASH Keys distinct to the rest
    #With this I may be subestimating the number of cases with a different concatenation.
    #Considering all the distinct combinations, i take what they have a duplicate ID
    #Select the duplicate IDs, it orders and...
    #Filter only cases that has distinct id.
    CONS_TOP_df %>% mutate(concat=paste0(ID,"_",HASH_KEY)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% 
      dplyr::filter(duplicated(ID)) %>% #filter cases that have than one 
  dplyr::arrange(ID) %>%  #filter cases in which there is more than one ID, 
      #despite there is differents combinations of HASH and IDs, and then arrange IDs. This is possible only if a different HASH-Key contains more than one ID or viceversa.
      #take distincts IDs (exclude duplicated repeated IDs)
      dplyr::distinct(ID) %>% 
      assign("ids_more_one_hash_TOP",., envir = .GlobalEnv) # Differently put, take the distints IDs per HASH-Key, of the cases in which there are different combinations                                                      
    # of IDs and hash, and in which subgroup exists duplicated IDs.


    #There are 33 IDs that have more than one HASH key.
    
    #IMPORTANT: IF THE ID IS DUPLICATED, MIGHT NOT BE REFLECTED IN THIS RESUME IN TERMS OF QUANTITY.
    
    # Then, apply these cases to the whole population. 
    CONS_TOP_df %>%
      dplyr::filter(ID %in% as.character(as.vector(unlist(as.data.table(unlist(ids_more_one_hash_TOP)))))) %>% # Select IDs of cited cases
      dplyr::arrange(ID) %>% #ordeno por ids 
      #183 cases may be affected with this problem
      dplyr::select(row, ano_bd, id_mod, HASH_KEY, hash_rut_completo , Edad, Sexo,fech_ing,Plan.de.Tratamiento, Nombre.del.Centro, Tipo.Centro, Región.Centro, Comentario) %>%
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 2. Total registries that each ID have more than one HASH-KEY",
              col.names = c("Row ID","Year of Dataset", "SENDA's ID", "HASH KEY", "HASH Key (Alternative)","Year", "Sex", "Date of Admission", "Treatment Plan", "Center", "Type of Center", "Region", "Comment"),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
            scroll_box(width = "100%", height = "350px")

```
<br>
&nbsp;

### 4. Duplicated cases

<br>
To define what can be considered as a unique event, we identified how many unique combinations of dates of admission and HASH keys. We found that only 41.4% of the registries are unique combinations. Attending the characteristics of the questionnaires, it is possible to explore more specific time points.

<br>


```{r Duplicated}
    #create the duplicated dataset, following the recommendation to separate columns
    
    as.data.table(CONS_TOP_df)[, dup_hash_date_top := .N, by = c("HASH_KEY","fech_ing")] %>% ##dim()
      dplyr::group_by(dup_hash_date_top) %>%
      dplyr::summarise(n=n()) %>%
      mutate(perc = round(n / sum(n),2)*100) %>%
      mutate(perc = paste0(perc,"%")) %>%
      as.data.frame(.) %>%
    # Duplicated rows
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 3. Frequency and Percentage of Duplicated Values of the combination of HASH-Key & Date of Admission", 
                   col.names= c("Times present in Dataset", " Frequencies", "Percentage"),  align =rep('c', 2))  %>%
      kable_styling(bootstrap_options = c("striped", "hover"),font_size = 11) %>%
  scroll_box(width = "100%", height = "350px")
    ```
<br>

One of them is the date of application of the TOP questionnaire. As can be seen in Table 4, 94% of the registries are unique combinations of date of application of the TOP questionnaire and HASH key.

<br>

```{r Duplicated2}
    duplicated_rows_concat_TOP2 <- data.frame(duplicated_HASH_date = duplicated(CONS_TOP_df[,c("HASH_KEY","fech_ap_top")]), 
                                         row_dup_HASH_date = 1:nrow(CONS_TOP_df[,c("HASH_KEY","fech_ap_top")])) #%>%

    as.data.table(CONS_TOP_df)[, dup_hash_date_ap := .N, by = c("HASH_KEY","fech_ap_top")] %>% ##dim()
      dplyr::group_by(dup_hash_date_ap) %>%
      dplyr::summarise(n=n()) %>%
      mutate(perc = round(n / sum(n),3)*100) %>%
      mutate(perc = paste0(perc,"%")) %>%
      as.data.frame(.) %>%
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 4. Frequency and Percentage of Duplicated Values of the combination of HASH-Key & Date of Application of TOP", 
                   col.names= c("Times present in Dataset", " Frequencies", "Percentage"),  align =rep('c', 2))  %>%
      kable_styling(bootstrap_options = c("striped", "hover"),font_size = 11) %>%
  scroll_box(width = "100%", height = "350px")
```
<br>

  As can be seen in Table 5, in some cases the only thing that varies is the stage of treatment (005238a56b9614ead0903bb264de7be9_2016-12-28) in others also varies the qualitative observations (67e87f8ff93505867ccab2eb0150c7f0_2016-06-29) or variables relative to the content of the evaluation (f414c49e178c414f020b114b09d962d2_2017-06-23). **Can a single  combination of date of query and HASH have different dates of admission?**

<br>

```{r Duplicated2.2}
as.data.table(CONS_TOP_df)[, dup_hash_date_ap := .N, by = c("HASH_KEY","fech_ap_top")] %>%
  dplyr::filter(dup_hash_date_ap>1) %>% #Aquí veo quienes aparecen más de una vez
  dplyr::arrange(HASH_KEY,fech_ap_top) %>% 
  dplyr::select(HASH_KEY, hash_rut_completo, id_mod, ano_bd, fech_ap_top, TOP,fech_nac, Edad, Sexo, Plan.de.Tratamiento, Nombre.del.Centro, Sustancia.Principal.1, Sustancia.Principal.2, Sustancia.Principal.3, starts_with("Total"),starts_with("Dósis")) %>%
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 5. Duplicated rows of the combination of HASH-Key & Date of Application of TOP", 
                   #col.names= c("Duplicated", " Frequencies", "Percentage"),
                   align =rep('c', 102))  %>%
      kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  scroll_box(width = "100%", height = "350px")
```


### 5. Deletion of nearly exact duplicated cases

nbsp;
<br>
We need reduce the number of cases, but in the mean time, try to reduce the loss of information due to specific changes in each entry, despite it could be originated by different mechanisms (eg. different professionals evaluated the same patients for an specific stage of the treatment, but highlighting different things), other than comming from the same yearly dataset.

<br>


```{r deduplication1 echo=T, cache=T, paged.print=TRUE}
#create vector with variable names
names_top <- names(CONS_TOP_df[,c(1,2,4,8,10:48)])
#Group by duplicated rows 
as.data.table(CONS_TOP_df)[, dup_todo_TOP := .N, by = names_top] %>%
  data.table::as.data.table() %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev",.,envir = .GlobalEnv)
#summarise duplicates and times
as.data.table(CONS_TOP_df)[, dup_todo_TOP := .N, by = names_top] %>%
  dplyr::group_by(dup_todo_TOP) %>%
  dplyr::summarise(n()) %>%
  data.frame() %>%
  dplyr::rename("Times present in Dataset"=dup_todo_TOP, "Number of Rows"=`n..`) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 5. Duplicated cases in almost every variable",
                 align ="cccc")  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10)
```

```{r dataset_creation, echo=F, paged.print=TRUE, cache=T, warning=F}
data.table::data.table(CONS_TOP_df_dup_ENE_2020_prev) %>%
  dplyr::arrange(desc(ano_bd)) %>%
  dplyr::distinct_(.dots = names_top, .keep_all = TRUE) %>%
  dplyr::arrange(HASH_KEY, fech_ing, fech_ap_top, desc(ano_bd)) %>%
  data.table::as.data.table() %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev2",.,envir = .GlobalEnv)
#Unlike base sorting with sort(), NA are: always sorted to the end for local data, even when wrapped with desc().
```

&nbsp;
<br>

As seen in Table 5, not many cases were dropped, which can be interpreted that there is different information regarding patients and specific treatments in each of the remaining `r nrow(CONS_TOP_df_dup_ENE_2020_prev2) %>% formatC(., format="f", big.mark=",", digits=0)` rows. 


&nbsp;
<br>
