---
title: "Data Preparation of TOP Dataset"
description: | 
  Scientific and technical writing about DB standarization, native to the web
Date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide 
    toc: true # table of content true
    toc_depth: 3  # upto three depths of headings (specified by #, ## and ###)
    toc_float: true
---

<style type="text/css">
.tablelines table, .tablelines td, .tablelines th {
        border: 1px solid black;
        }
.centrado {
    text-align: center;
}
.table.center {
    margin-left:auto; 
    margin-right:auto;
  }
.table_wrapper{
    display: block;
    overflow-x: auto;
    white-space: nowrap;
}
code.r{
  font-size: 8px;
}
body{ /* Normal  */
      text-align: justify;
  }
</style>


```{r setup, include=FALSE}
rm(list=ls());gc()
unlink('SUD_CL/Data_prep_TOP_cache', recursive = TRUE)
load("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/3.RData")
#setwd("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/SUD_CL")
#path <-"G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/SUD_CL"
#Libraries used in the routine. Dont change the order
if(!require(tidyr)){install.packages("tidyr")}
if(!require(DataExplorer)){install.packages("DataExplorer")}
if(!require(stringi)){install.packages("stringi", dependencies=TRUE, INSTALL_opts = c('--no-lock'))}
if(!require(stringr)){install.packages("stringr")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(Hmisc)){install.packages("Hmisc")}
if(!require(kableExtra)){install.packages("kableExtra")}
if(!require(plotly)){install.packages("plotly")}
if(!require(rbokeh)){install.packages("rbokeh")}
if(!require(altair)){install.packages("altair")}
if(!require(zoo)){install.packages("zoo")}
if(!require(broom)){install.packages("broom")}
if(!require(sqldf)){install.packages("sqldf")} 
if(!require(data.table)){install.packages("data.table")}
if(!require(dplyr)){install.packages("dplyr")}
```

&nbsp;

TOP or Treatment Outcomes Profile ("Perfil de Resultados de Tratamiento") serves as a tool for monitoring and follow up of SUD treatments. This questionnaire must be completed at entry to treatment, each 3 months during treatment, at treatment discharge and some centers may aaply it after discharg. Hence, it is important to capture the date of application and the date of admission, and in order to characterize each user, it is important to standardize his birth date.

&nbsp;
<br>

### 1. Change Dates of Admission, Aplication of TOP and Birth

As can be seen in Table 1, every date was formatted into dates in a format disposed to show first a 4-digit year, 2-digit month and 2-digit day. Additionally, SENDA's ID was masked to avoid recognition from third parties.

<br>

```{r changes_dates, cache=T}
#create the first changes into TOP dataset
CONS_TOP %>%
  dplyr::mutate(ano_bd=as.numeric(substr(TABLE,4,7))) %>%
  dplyr::mutate(id_mod=sub("(.{5}).", "\\1*",as.character(ID))) %>%
  dplyr::mutate(id_mod=sub("(.{6}).", "\\1*",as.character(id_mod))) %>% 
  dplyr::select(HASH_KEY, hash_rut_completo, id_mod, ID, ano_bd, everything()) %>%
  dplyr::arrange(desc(ano_bd)) %>% 
  assign("CONS_TOP_df",.,envir = .GlobalEnv)

#change dates
CONS_TOP_df %>%
  dplyr::mutate(fech_ing= lubridate::parse_date_time(Fecha.de.Ingreso.a.Tratamiento, c("%d/%m/%Y"),exact=T)) %>% #No parse failures
  #dplyr::select(Fecha.de.Ingreso.a.Tratamiento,fech_ing) %>% head() #To see how it responds to changes. Many null values
  dplyr::mutate(fech_ing_sin_fmt= Fecha.de.Ingreso.a.Tratamiento) %>% #keep this variable for comparison
  dplyr::mutate(fech_ap_top= lubridate::parse_date_time(Fecha.Aplicación.TOP, c("%Y-%m-%d"),exact=T)) %>% #No parse failures
  #dplyr::select(Fecha.Aplicación.TOP,fech_ap_top) %>% head() #To see how it responds to changes.
  dplyr::mutate(fech_nac= lubridate::parse_date_time(str_trim(Fecha.Nacimiento), orders = c("%d/%m/%Y"),exact=T)) %>%
  #dplyr::select(Fecha.Nacimiento,fech_nac) %>% View() #To see how it responds to changes. No failures
  assign("CONS_TOP_df",.,envir = .GlobalEnv) #
#Example of transformations
CONS_TOP_df %>%
  dplyr::select(Fecha.de.Ingreso.a.Tratamiento,fech_ing,Fecha.Aplicación.TOP,fech_ap_top,Fecha.Nacimiento,fech_nac) %>% head() %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 1. Example of date of admission to treatment",
              col.names = c("Unformatted Date of Admission","Date of Admission", "Unformatted Date of Application", "Date of Application", "Unformatted Date of Birth","Date of Birth"),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10)
```

&nbsp;
<br>

In the transformation of the dates of admission, we found an important amount of missing values. However, **there were `r CONS_TOP_df %>% dplyr::filter(is.na(fech_ap_top)) %>% summarise(n())` missing dates of application of the TOP** and  `r CONS_TOP_df %>% dplyr::filter(is.na(fech_nac)) %>% summarise(n())` missing birth dates (despite `r CONS_TOP_df %>% dplyr::select(Edad) %>% dplyr::filter(Edad<18|Edad>90) %>% nrow()` cases could be invalid according to the criteria stated by SENDA's professionals). **Considering the characteristics of TOP programs and monitoring, it may be possible to replace dates from the cases that share the same information within the TOP dataset, or obtain it from C1 dataset, using the date of application as a reference to determine the adequate date of admission.**

<br>

```{r fech_ing_nas, echo=FALSE, fig.align='center',fig.cap= "Figure 1. Pie Chart of Missing Dates of Admission"}
#Hay un 1% de casos perdidos
CONS_TOP_df %>%
  dplyr::group_by(is.na(Fecha.de.Ingreso.a.Tratamiento)) %>% 
  dplyr::rename("MISS_DATE_ADM"=`is.na(Fecha.de.Ingreso.a.Tratamiento)`) %>% 
  summarise(n=n()) %>% 
  data.frame() %>%  mutate(perc=n/sum(n)) %>%
  ggplot(aes(x="", y=n, fill=MISS_DATE_ADM))+
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start=0) + 
  scale_fill_brewer("Missing Date\nof Admission") + theme_minimal() +
  theme(axis.text.x=element_blank())+
  geom_text(aes(y = n/2 + c(0, cumsum(n)[-length(n)]), 
                label = paste0(formatC(n, format="f", big.mark=",", digits=0), "\n(",scales::percent(perc),")")), size=4) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.border = element_blank(),
    panel.grid=element_blank(),
    axis.ticks = element_blank(),
    plot.title=element_text(size=14, face="bold")
  ) 
```

<br>

Considering that the dates of admission to the treatment and discharge may let us merge the dataset with the correspondent to C1, we need to obtain the remining dates that were missed.

<br>

### 2. Replacing dates

<br>

In order to replace the dates of admission, we should obtain it not only from the TOP dataset, but also using the C1 agreement. First, we  should identify applications of the TOP that were done for the same stage and for the same HASH, but this specific registry have a date of admission. 

```{r replace_date_adm_table_top}
CONS_TOP_df_dup_fech_ing_adm <- dplyr::select(CONS_TOP_df, HASH_KEY, fech_ap_top, fech_ing, TOP)%>% 
  dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") 
CONS_TOP_df_dup_fech_ing <- dplyr::select(CONS_TOP_df, HASH_KEY, fech_ap_top, fech_ing, TOP)%>% 
  dplyr::filter(!is.na(fech_ing)) 
######################################
#nrow(CONS_TOP_df_dup_fech_ing) ##DESPITE HAS MORE ROWS, DOES NOT MAKE A DIFFERENCE IN THE QUANTITY
#nrow(CONS_TOP_df_dup_fech_ing_adm)
#################################
#Join datasets 
dplyr::left_join(CONS_TOP_df,CONS_TOP_df_dup_fech_ing, by = c("HASH_KEY", "fech_ap_top"), suffix = c("", ".y")) %>% #names() #junto con la BD que hice
  dplyr::filter(!is.na(fech_ing.y), is.na(fech_ing)) %>%  #filtro los casos que en que sí tengo fecha de ingreso en el merge, pero no la tengo en la BD.
  dplyr::select(row,ano_bd, HASH_KEY, hash_rut_completo, id_mod, Edad, Sexo, fech_ing, fech_ap_top, TOP, fech_ing.y) %>% #dejo para ver cómo la icorporo
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 2. HASHs with missing dates of admission that can be replaced by another case with the same characteristics",
              col.names = c("Row ID","Year of Dataset", "HASH KEY","HASH Key (Alternative)","SENDA's ID", "Year", "Sex", "Date of Admission", "Date of Application","Stage of TOP", "Date of Admission (replacement)" ),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
            scroll_box(width = "100%", height = "350px")
```

```{r save_changes0, cache=T}

CONS_TOP_df_dup_fech_ing_adm <- dplyr::select(CONS_TOP_df, HASH_KEY, fech_ap_top, fech_ing, TOP)%>% 
  dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::group_by(HASH_KEY, fech_ap_top) %>% dplyr::mutate(row_leftjoin=row_number()) %>% ungroup()
CONS_TOP_df %>%
  dplyr::group_by(HASH_KEY, fech_ap_top) %>% dplyr::mutate(row_leftjoin=row_number()) %>% ungroup() %>%
dplyr::left_join(CONS_TOP_df_dup_fech_ing_adm, by = c("HASH_KEY", "fech_ap_top","row_leftjoin"), suffix = c("", ".y")) %>% #names() #junto con la BD que hice
  dplyr::mutate(fech_ing= ifelse(is.na(fech_ing),as.Date(as.numeric(fech_ing.y), format="%Y-%m-%d"), fech_ing)) %>%
  dplyr::mutate(fech_ing=as.POSIXct(strftime(as.POSIXct(as.POSIXct(as.Date(as.character(lubridate::as_datetime(as.numeric(fech_ing)))),format='%Y-%m-%d',usetz = FALSE)+ 3*60*60,format='%Y-%m-%d',usetz = FALSE), format="%Y-%m-%d"),format='%Y-%m-%d',usetz = FALSE)) %>%
  dplyr::select(-fech_ing.y, -TOP.y, -row_leftjoin) %>%
  #dplyr::filter(HASH_KEY=="c91ec6bb76b4cf5cb8b60f20944a2208")
  #dplyr::group_by(Edad) %>% summarise(n=n()) %>% View()
  assign("CONS_TOP_df_dup_ENE_2020_prev0",., envir = .GlobalEnv) 
#str(CONS_TOP_df_dup_ENE_2020_prev0) #TENGO PROBLEMAS PARA FORMATEAR LA ECHA DE INGRESO SIN HORAS
```

Done this, we still find many cases (`r formatC(CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(is.na(fech_ing)) %>% nrow(), format="f", big.mark=",", digits=0)`) that do not have a date of admission. Another option would be to replace the date of admission from the date of application, in the event of application. However, this was not possible due to an inaccuracy of data, observed in the difference between those that have both dates available (Mean=`r CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% summarise(Mean= mean(diff_fech_ing_ap), Median=quantile(diff_fech_ing_ap, c(.5)), Q25=quantile(diff_fech_ing_ap, c(.25)), Q75=quantile(diff_fech_ing_ap, c(.75))) %>% round(2) %>% dplyr::select(Mean)`; Mdn= `r CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% summarise(Mean= mean(diff_fech_ing_ap), Median=quantile(diff_fech_ing_ap, c(.5)), Q25=quantile(diff_fech_ing_ap, c(.25)), Q75=quantile(diff_fech_ing_ap, c(.75))) %>% round(2) %>% dplyr::select(Median)` [Q1= `r CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% summarise(Mean= mean(diff_fech_ing_ap), Median=quantile(diff_fech_ing_ap, c(.5)), Q25=quantile(diff_fech_ing_ap, c(.25)), Q75=quantile(diff_fech_ing_ap, c(.75))) %>% round(2) %>% dplyr::select(Q25)`, Q3= `r CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% summarise(Mean= mean(diff_fech_ing_ap), Median=quantile(diff_fech_ing_ap, c(.5)), Q25=quantile(diff_fech_ing_ap, c(.25)), Q75=quantile(diff_fech_ing_ap, c(.75))) %>% round(2) %>% dplyr::select(Q75)`]).

```{r diff_dates_adm_application, echo=FALSE, fig.align='center',fig.cap= "Figure 2. Histogram of Differences Between Dates of Admission and Dates of Application of TOP, among those questionnaires applied in the stage of admission"}
CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% dplyr::select(diff_fech_ing_ap) %>% dplyr::rename("Diff. in Dates of Admission & Date of Application of TOP"="diff_fech_ing_ap") %>% hist()
```

<br>

In Table 3, we may see how many dates could be replaced by the dates in C1. We replace these dates by filtering the applications correspondent to the event of admission that had missing data. Then, we pair them with cases in C1 with the same HASH and the same date of admission (in which the date of application of the TOP for admission coincides with the date of admission in C1), and finally we replace it with this corresponding date.

```{r replace_date_adm_table_c1}
  #debiese poneruyha, HASHs with missing dates of admission that can be replaced by cases in C1 with the same characteristics",
CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(TOP=="Ingreso", is.na(fech_ing)) %>% #son aplicación Ingreso, les falta la fecha de ingreso
  dplyr::inner_join(dplyr::select(CONS_C1_df,HASH_KEY, fech_ing), by=c("HASH_KEY"="HASH_KEY", "fech_ap_top"="fech_ing"), suffix=c(".TOP",".C1")) %>% as.data.frame() %>%
  dplyr::select(row,ano_bd, HASH_KEY, hash_rut_completo, id_mod, Edad, Sexo, fech_ing, fech_ap_top, TOP) %>% 
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 3, HASHs with missing dates of admission that can be replaced by cases in C1 with the same characteristics",
              col.names = c("Row ID","Year of Dataset", "HASH KEY","HASH Key (Alternative)","SENDA's ID", "Year", "Sex", "Date of Admission", "Date of Application","Stage of TOP"),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 9) %>%
      kableExtra::add_footnote( c("Note. The date of application of TOP should replace the missing Date of Admission."), notation = "none") %>%
            scroll_box(width = "100%", height = "350px")
```

```{r save_changes1, cache=T}
CONS_C1_df_rownum <-CONS_C1_df %>% mutate(fech_ing_C1=fech_ing) %>% 
  dplyr::group_by(HASH_KEY, fech_ing) %>%  
  dplyr::mutate(row_leftjoin=row_number()) %>% 
  ungroup()
#join
#n_veces_dup_hash_fech_top
CONS_TOP_df_dup_ENE_2020_prev0 %>% 
  mutate(fech_ing_na=fech_ing) %>%# solo hecha para visibilizar los que fueron reemplazados
  dplyr::group_by(HASH_KEY, fech_ap_top, row) %>% dplyr::mutate(row_leftjoin=row_number()) %>%  #agrupo por row porque no me interesa que no me traiga el repetido de la fecha de aplicación del top y el HASH, sólo me interesa que desde C1 no me traiga más de una fila.
  ungroup() %>%
  dplyr::left_join(dplyr::select(CONS_C1_df_rownum,HASH_KEY, fech_ing,row_leftjoin, fech_ing_C1), by=c("HASH_KEY"="HASH_KEY", "fech_ap_top"="fech_ing", "row_leftjoin", "row_leftjoin"), suffix=c(".TOP",".C1"))%>%
  dplyr::mutate(fech_ing= ifelse((is.na(fech_ing))&(TOP=="Ingreso"),as.Date(as.numeric(fech_ing_C1), format="%Y-%m-%d"), fech_ing)) %>%
  dplyr::mutate(fech_ing=as.POSIXct(strftime(as.POSIXct(as.POSIXct(as.Date(as.character(lubridate::as_datetime(as.numeric(fech_ing)))),format='%Y-%m-%d',usetz = FALSE)+ 3*60*60,format='%Y-%m-%d',usetz = FALSE), format="%Y-%m-%d"),format='%Y-%m-%d',usetz = FALSE)) %>% 
  dplyr::select(-fech_ing_C1, -row_leftjoin) %>%
#  dplyr::filter(HASH_KEY %in% c("9b74476e88c81cb019a468106d65ac85","f0210e3f219b7c4b85d9767fc5446c73","d4eeee40471666533d3cbbda0901fada", "c6b57a1ddf9555842bd46216851bf2ee", "92be85e2ace88e24a99fe3980bcd5fc0", "2adfa7e2f6d763c1c6c2b5ed35889243", "ec15af2d6521535ae5bdc50459a62f8c", "978988a1c417f54963eb9f5d84f07c60"), TOP=="Ingreso", is.na(fech_ing_na)) %>% #c6b57a1ddf9555842bd46216851bf2ee  este no debería incorporarlo, porque debiese ser NA
 # View()
  assign("CONS_TOP_df_dup_ENE_2020_prev1",., envir = .GlobalEnv) 
```


<br>

And what about another important event that is present along the C1 dataset?. Unfortunatelly, dates of admission could hot be replaced by the dates in C1 following this criteria. We filtered the applications correspondent to the event of discharge that had missing data in the date of admission (n= `r CONS_TOP_df_dup_ENE_2020_prev1 %>% dplyr::filter(TOP=="Egreso", is.na(fech_ing)) %>% nrow()`). Then, we paired them with cases in C1 with the same HASH and the same date of discharge (in which the date of application of the TOP for discharge coincides with the date of discharge in C1), but we ended with `r CONS_TOP_df_dup_ENE_2020_prev1 %>% dplyr::filter(TOP=="Egreso", is.na(fech_ing)) %>% dplyr::inner_join(dplyr::select(CONS_C1_df_dup_ENE_2020,HASH_KEY, fech_ing, fech_egres), by=c("HASH_KEY"="HASH_KEY", "fech_ap_top"="fech_egres"), suffix=c(".TOP",".C1")) %>% as.data.frame() %>% nrow()` cases to match.

<br>

Another alternative could be the matching by coincing HASHs and years at the time of admission. However, we require to have valid ages in the TOP dataset. There were `r CONS_TOP_df_dup_ENE_2020_prev1 %>% dplyr::filter(!is.na(fech_nac)) %>% dplyr::select(fech_nac) %>% dplyr::filter(fech_nac<"1929-03-19"|fech_nac>"2001-11-01")  %>% nrow()` cases with invalid values in age. In the following table, these cases are described in depth.

<br>

```{r edad, cache=T}
#CONS_TOP_df_dup_ENE_2020_prev1 %>% dplyr::filter(!is.na(fech_nac)) %>% dplyr::select(fech_nac, Edad) %>% dplyr::filter(fech_nac<"1929-03-19"|fech_nac>"2001-11-01")  %>% nrow()

#El filtro que hice yo no sirvió mucho, los rangos de edad. Ahí lo corregí por la influencia de 1929-03-20
#INVESTIGAR ESTE CASO.
  CONS_TOP_df_dup_ENE_2020_prev1 %>% dplyr::filter(Edad<18|Edad>90) %>%
    dplyr::select(row, HASH_KEY, id_mod, fech_nac, ano_bd,Edad,fech_ing) %>%
 knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 4. Cases that have a wrongly asigned age",
              col.names = c("Row ID","HASH KEY","SENDA's ID","Year of Birth","Year of Dataset",  "Age", "Date of Admission"),
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
```

<br>

An important amount of cases were available in the TOP dataset, permitting to replace invalid ages with the right information. The next table presents those HASHs that had other registries with a valid age.

<br>

```{r wrong ages duplicates, echo=T,cache=T, paged.print=TRUE}
#list of distinct HASHs that have a wrongly assigned age
CONS_TOP_df_dup_ENE_2020_prev1 %>% dplyr::filter(Edad<18|Edad>90) %>%
   dplyr::select(HASH_KEY, Edad) %>%
  dplyr::distinct(HASH_KEY) %>%
  assign("distinct_hash_wrong_age2_top",., envir = .GlobalEnv)

#Then, apply these cases to the whole population
CONS_TOP_df_dup_ENE_2020_prev1 %>%
dplyr::filter(HASH_KEY %in% as.character(as.vector(unlist(as.data.table(unlist(distinct_hash_wrong_age2_top)))))) %>% # select hashs of wrongly assigned ages
dplyr::arrange(HASH_KEY) %>% #order by hashs 
  dplyr::filter(Edad>=18,Edad<=90) %>% #nrow() #if you want to see how many cases would be changed: 58
      dplyr::select(row, ano_bd, HASH_KEY, id_mod, fech_nac, ano_bd,Edad, fech_ing, fech_ap_top, everything()) %>%
  dplyr::select(-ID) %>%
 knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 5. Total cases with wrong ages but their HASH had a valid age along the dataset",
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
```

<br>

We replaced SENDA's ID, age, ID and date of birth to those cases, to get a much clean dataset of valid cases. **One observation that come from this transformation, is that many of TOPs applications that had missing values in one value, has missing values in many other more. Possibly, there are duplicated events, and some of them were invalid. If this is true, we only need to discard events with incomplete data instead of replacing them with valid information. But first we need to check whether this happens or not. This have to be contrasted in the next stages of data preparation**.

<br>

```{r edad_save, cache=T}
CONS_TOP_df_dup_age <- dplyr::select(CONS_TOP_df_dup_ENE_2020_prev1, HASH_KEY, ID, id_mod, Edad, fech_nac)%>% 
                      dplyr::filter(Edad>=18, Edad<=90) %>% #%>%  #dim rows 85490, 4 columns
                      dplyr::filter(!duplicated(HASH_KEY)) #lo mismo que  dplyr::distinct(HASH_KEY)
##CON EL DISTINCT ME SALVO DE SUMAR MÁS FILAS A LA BASE DE DATOS.
#Join datasets 
  dplyr::left_join(CONS_TOP_df_dup_ENE_2020_prev1,dplyr::select(CONS_TOP_df_dup_age,HASH_KEY,Edad, ID,id_mod, fech_nac), by = "HASH_KEY", suffix = c("", ".y")) %>% # dim()
    dplyr::mutate(ID= ifelse((Edad<18 & !is.na(Edad.y))|(Edad>90 & !is.na(Edad.y)),ID.y, ID)) %>%
    dplyr::mutate(id_mod=ifelse((Edad<18 & !is.na(Edad.y))|(Edad>90 & !is.na(Edad.y)),id_mod.y,id_mod)) %>% 
    dplyr::mutate(fech_nac=ifelse((Edad<18 & !is.na(Edad.y))|(Edad>90 & !is.na(Edad.y)),as.Date(as.numeric(fech_nac.y), format="%Y-%m-%d"),fech_nac)) %>% 
    dplyr::mutate(Edad= ifelse(Edad<18|Edad>90,Edad.y, Edad)) %>% #treat as invalID
    dplyr::mutate(fech_nac=as.POSIXct(strftime(as.POSIXct(as.POSIXct(as.Date(as.character(lubridate::as_datetime(as.numeric(fech_nac)))),format='%Y-%m-%d',usetz = FALSE)+ 3*60*60,format='%Y-%m-%d',usetz = FALSE), format="%Y-%m-%d"),format='%Y-%m-%d',usetz = FALSE)) %>%
    dplyr::mutate(Edad_al_ing=lubridate::time_length(difftime(as.Date(fech_ing), as.Date(fech_nac)),"years")) %>%
    dplyr::mutate(Edad_al_ing=replace(Edad_al_ing, is.na(Edad), NA)) %>%
##un resumen   
     #dplyr::group_by(Edad) %>% summarise(n=n()) %>%  #baja de 273 a 227
#PA4RA REVISAR
        #dplyr::filter(HASH_KEY %in% as.character(as.vector(unlist(as.data.table(unlist(distinct_hash_wrong_age2_top)))))) %>% # select hashs of wrongly assigned ages. Hay               algunos que no los va a encontrar porque no los tiene, no mas
        #dplyr::select(HASH_KEY, Edad, fech_nac, Edad.y, fech_nac.y, fech_ing, ID, id_mod, ID.y, Edad_al_ing) %>%
        #arrange(HASH_KEY) %>%
         #   View() 
dplyr::select(-id_mod.y, -ID.y, -Edad.y, -fech_nac.y) %>% 
assign("CONS_TOP_df_dup_ENE_2020_prev2",., envir = .GlobalEnv) 
#POR QUÉ ESTE CASO NO QUEDO INCORPORADO  
  #CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::filter(!is.na(fech_ing), !is.na(Edad),is.na(Edad_al_ing)) %>% View()
  #CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::filter(!is.na(fech_ing), !is.na(Edad),is.na(Edad_al_ing)) %>% 
  #dplyr::mutate(HASH_KEY, id_mod, Fecha.Aplicación, fech_ing, fech_nac, Edad, Edad_al_ing)
```

```{r edad_save_correction, cache=T}
#EL CASO QUEDÓ PERDIDO EN ESTA TRANSFORMACIÓN. INVESTIGAR POR QUÉ, PERO POR MIENTRAS RESOLVERLO MANUALMENTE.
#POR QUÉ ESTE CASO NO QUEDO INCORPORADO  
  #CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::filter(!is.na(fech_ing), !is.na(Edad),is.na(Edad_al_ing)) %>% View()
#CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::filter(!is.na(fech_ing), !is.na(Edad),is.na(Edad_al_ing)) %>% 
#    dplyr::select(HASH_KEY, id_mod, Fecha.Nacimiento, fech_ing, fech_nac, Edad, Edad_al_ing)
#CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::filter(HASH_KEY=="ee0360d19dd5f300526c624c58090c79") %>% 
#    dplyr::select(HASH_KEY, id_mod, Fecha.Nacimiento, fech_ing, fech_nac, Edad, Edad_al_ing)

CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::mutate(fech_nac=ifelse(HASH_KEY=="ee0360d19dd5f300526c624c58090c79",lubridate::as_datetime("1942-08-02"), fech_nac)) %>%
    dplyr::mutate(Edad_al_ing=lubridate::time_length(difftime(as.Date(fech_ing), as.Date(fech_nac)),"years")) %>%
    dplyr::mutate(Edad_al_ing=replace(Edad_al_ing, is.na(Edad), NA)) %>%
    dplyr::filter(HASH_KEY=="ee0360d19dd5f300526c624c58090c79") %>% 
    dplyr::select(HASH_KEY, id_mod, Fecha.Nacimiento, fech_ing, fech_nac, Edad, Edad_al_ing) %>% 
  print()
```

### 3. Inconsistencies between SENDA's ID and HASH Key

<br>

```{r inconsistencies_in_id_inconsistent_hashs, cache=T}
    #Take which has a combination of IDs and HASH Keys distinct to the rest
    #With this I may be subestimating the number of cases with a different concatenation.
    #Considering all the distinct combinations, i take what they have a duplicate ID
    #Select the duplicate IDs, it orders and...
    #Filter only cases that has distinct id.
    CONS_TOP_df_dup_ENE_2020_prev2 %>% mutate(concat=paste0(ID,"_",HASH_KEY)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% 
      dplyr::filter(duplicated(ID)) %>% #filter cases that have than one 
  dplyr::arrange(ID) %>%  #filter cases in which there is more than one ID, 
      #despite there is differents combinations of HASH and IDs, and then arrange IDs. This is possible only if a different HASH-Key contains more than one ID or viceversa.
      #take distincts IDs (exclude duplicated repeated IDs)
      dplyr::distinct(ID) %>% 
      assign("ids_more_one_hash_TOP",., envir = .GlobalEnv) # Differently put, take the distints IDs per HASH-Key, of the cases in which there are different combinations                                                      
    # of IDs and hash, and in which subgroup exists duplicated IDs.
    #There are 33 IDs that have more than one HASH key.
    #IMPORTANT: IF THE ID IS DUPLICATED, MIGHT NOT BE REFLECTED IN THIS RESUME IN TERMS OF QUANTITY.
```

In order to check whether individual IDs (RUT) masked into HASH keys are consistent by each SENDA's ID and do not depend on other factors (eg., how the individual ID was written in the computer), we searched for more than one HASH Key in each SENDA's ID. There were `r nrow(ids_more_one_hash_TOP)` IDs that had more than one HASH key. These `r nrow(ids_more_one_hash_TOP)` IDs affect 183 registries. **They will be sent to SENDA's professionals and check what would be the cause of the differences**.

<br>

```{r inconsistencies_in_id}
    # Then, apply these cases to the whole population. 
    CONS_TOP_df_dup_ENE_2020_prev2 %>%
      dplyr::filter(ID %in% as.character(as.vector(unlist(as.data.table(unlist(ids_more_one_hash_TOP)))))) %>% # Select IDs of cited cases
      dplyr::arrange(ID) %>% #ordeno por ids 
      #183 cases may be affected with this problem
      dplyr::select(row, ano_bd, id_mod, HASH_KEY, hash_rut_completo , Edad, Sexo,fech_ing,Plan.de.Tratamiento, Nombre.del.Centro, Tipo.Centro, Región.Centro, Comentario) %>%
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 6. Total registries that each ID have more than one HASH-KEY",
              col.names = c("Row ID","Year of Dataset", "SENDA's ID", "HASH KEY", "HASH Key (Alternative)","Year", "Sex", "Date of Admission", "Treatment Plan", "Center", "Type of Center", "Region", "Comment"),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
            scroll_box(width = "100%", height = "350px")

```
<br>
&nbsp;

### 4. Duplicated cases

<br>
To define what can be considered as a unique event, we identified how many unique combinations of dates of admission and HASH keys. We found that only 41.4% of the registries are unique combinations. Attending the characteristics of the questionnaires, it is possible to explore more specific time points.

<br>


```{r Duplicated, include=}
    #create the duplicated dataset, following the recommendation to separate columns
    
--------------------------------------------------#0a. Pakcages--------------------
View()

#Remove Data
rm(list=ls())

#load("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/SUD_CL/.RData")

#Libraries used in the routine. Dont change the order
if(!require(backports)){install.packages("backports")}
if(!require(rowr)){install.packages("rowr")}
if(!require(plyr)){install.packages("plyr")}
if(!require(fUnitRoots)){install.packages("fUnitRoots")}
if(!require(reshape2)){install.packages("reshape2")}
if(!require(tidyr)){install.packages("tidyr")}
if(!require(data.table)){install.packages("data.table")}
if(!require(DataExplorer)){install.packages("DataExplorer")}
if(!require(stringi)){install.packages("stringi")}
if(!require(stringr)){install.packages("stringr")}
if(!require(zoo)){install.packages("zoo")}
if(!require(readxl)){install.packages("readxl")}
if(!require(httr)){install.packages("httr")}
if(!require(splitstackshape)){install.packages("splitstackshape")}
if(!require(acs)){install.packages("acs")}
if(!require(htmltab)){install.packages("htmltab")}
if(!require(remotes)){install.packages("remotes")}
if(!require(IRdisplay)){install.packages("IRdisplay")}
if(!require(statar)){install.packages("statar")}
if(!require(compareDF)){install.packages("compareDF")}
if(!require(qpcR)){install.packages("qpcR")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(blogdown)){install.packages("blogdown")}
if(!require(dataMaid)){install.packages("dataMaid")}
if(!require(pander)){install.packages("pander")}
if(!require(Hmisc)){install.packages("Hmisc")}
if(!require(fuzzyjoin)){install.packages("fuzzyjoin")}
if(!require(janitor)){install.packages("janitor")}
if(!require(dplyr)){install.packages("dplyr")}

detach(package:plyr, unload = TRUE)

devtools::install_github("joachim-gassen/ExPanDaR")
3
#   rm(list=setdiff(ls(), c("df1", "df2")))
#   rm(list=startsWith("opc")
#   rm(list = c('temp1','temp2'))
#   rm(list=ls(pattern="matches"))

######0.B. SYSTEM SPECIFICATIONS------------------
View()

##set dots as decimals based on the operative system.
sessionInfo()[4]
sessionInfo()[3]

if(version$platform =="x86_64-w64-mingw32") { options(OutDec= ",")
}  else {options(OutDec= ".")
}

##set commas as decimals.

ifelse(grepl('Spanish_', sessionInfo()[3]), options(OutDec= ","), ifelse(grepl('English_', sessionInfo()[3]), options(OutDec= "."), NA))
print( pi )

#Sys.setlocale("LC_CTYPE", locale="Japanese") # set locale

######0.C. functions------------------
View()

read_excel_mult <- function(dir, filename) {
  assign(paste0(substr(filename, 1, 7)),read.delim(paste0(dir, filename),
        na.strings="null", header = T, fileEncoding="UTF-8"),envir = .GlobalEnv)
  }

#function to copy names
copiar_nombres <- function(x,row.names=FALSE,col.names=TRUE,...) {
  write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
  return(x)}

#function to save datasets in excel files (x=object to change; y=name of the excel file)
guardar_tablas <- function (x,y) {writexl::write_xlsx(as.data.frame(x, keeprownames= T),paste0(y,".xlsx"))}


######0.D. DATASETS------------------
View()

#in case you want to erase every created object in the Enviroment
#rm(list=objects())

#Get working directory
dir_c1 <-toString(paste0("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)","/Encriptado c1/Personas tratadas c1/"))
dir_top <-toString(paste0("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)","/encriptados TOP/"))
                                    
                  
#Define files in the Directory folder, as long as they have the excel extension,
#and they do not start with ~  (represent a working temporary file in excel)
SISTRAT_c1<-list.files(path=toString(dir_c1), all.files=T, pattern="^[2].*\\s*txt$")
SISTRAT_top<-list.files(path=toString(dir_top), all.files=T, pattern="^[t].*\\s*txt$")

#Import datasets
for (x in SISTRAT_c1) {
  read_excel_mult(as.character(dir_c1), x)
}

for (x in SISTRAT_top) {
  read_excel_mult(as.character(dir_top), x)
}

#only years from 2010 to 2018
tab_10_18=ls()[(ls() %in% paste0(c(2010:2018),"tab"))]

#unlist(list(ls()[grep("^[2].*tab",ls())]))

#Function to execute datasets of C1
tab_10_18_mod <- function(x,y) {  get(x) %>% dplyr::rename("HASH_KEY" = !!names(.[91])) %>%
    as.data.frame() %>% 
    assign(paste0(y, as.character(x)),.,envir = .GlobalEnv)
}
for (i in paste0(c(2010:2018),"tab")) {tab_10_18_mod(i,y="c1_")}

rm(list= ls()[(ls() %in% paste0(c(2010:2018),"tab"))])

#Apply function to every State dataset.
#Tab10_18<- lapply(mget(tab_10_18), function(x) tab_10_18_mod(x))

#TAB, incluiding dataset of 2019 (93 columns)
#tab_10_19=c(unlist(list(ls()[grep("^[2].*tab",ls())])),unlist(list(ls()[grep("*_En*",ls())])))

`2019_En` %>% dplyr::rename("HASH_KEY" = !!names(.[92])) %>%
  as.data.frame() %>% 
  assign(paste0("c1_", "2019tab"),.,envir = .GlobalEnv)

#top- replace columns
list_top_db=unlist(list(ls()[grep("^top",ls())]))

 tab_15_19_top_mod <- function(x) {  get(x) %>% dplyr::rename("HASH_KEY" = !!names(.[44])) %>%
    as.data.frame() %>% assign(paste0(as.character(x)),.,envir = .GlobalEnv)
}

for (i in list_top_db) {tab_15_19_top_mod(i)}

CONS_C1=rbindlist(mget(paste0("c1_",c(2010:2019),"tab")), idcol="TABLE", fill=T)
CONS_TOP=rbindlist(mget(list_top_db), idcol="TABLE")

CONS_C1 <- CONS_C1 %>% dplyr::mutate(row=1:nrow(CONS_C1)) %>% dplyr::select(row,everything())
CONS_TOP <- CONS_TOP %>% dplyr::mutate(row=1:nrow(CONS_TOP)) %>% dplyr::select(row,everything())


######1. CONS DATASET_ C1------------------
View()
#
#
#-#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#-#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#-#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#-#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#-#_#
#
######1.a Rename and Format Dates- CONS DATASET_ C1------------------
#
#Definir variables y formatos
require(dplyr)

CONS_C1 %>% 
  dplyr::rename(id=`Codigo.Identificación`) %>%
  dplyr::rename(fech_ing=`Fecha.Ingreso.a.Tratamiento`) %>%
  dplyr::rename(fech_egres=`Fecha.Egreso.de.Tratamiento`) %>%
  dplyr::rename(dias_trat=`Dias.en.Tratamiento`) %>%
  dplyr::rename(eva_consumo=`Evaluación.al.Egreso.Respecto.al.Patrón.de.consumo`) %>%
  dplyr::rename(eva_fam=`Evaluación.al.Egreso.Respecto.a.Situación.Familiar`) %>%
  dplyr::rename(eva_sm=`Evaluación.al.Egreso.Respecto.Salud.Mental`) %>%
  dplyr::rename(eva_fisica=`Evaluación.al.Egreso.Respecto.Salud.Física`) %>%
  dplyr::rename(eva_transgnorma=`Evaluación.al.Egreso.Respecto.Trasgresión.a.la.Norma.Social`) %>% 
  dplyr::rename(eva_relinterp=`Evaluación.al.Egreso.Respecto.Relaciones.Interpersonales`) %>%
  dplyr::rename(eva_ocupacion=`Evaluación.al.Egreso.Respecto.a.Situación.Ocupacional`) %>%
  dplyr::rename(evaluacindelprocesoteraputico=`Evaluación.del.Proceso.Terapéutico`) %>%
  dplyr::rename(nmesesentratamiento=`N.Meses.en.Tratamiento`) %>%
  dplyr::rename(motivodeegreso=`Motivo.de.Egreso`) %>%
  dplyr::rename(tipo_centro=`Tipo.Centro`) %>%
  dplyr::mutate(ano_bd=as.numeric(substr(TABLE,4,7))) %>%
  dplyr::select(row, TABLE, HASH_KEY,ano_bd, everything()) %>%
  dplyr::arrange(id) %>%
  assign("CONS_C1_df",.,envir = .GlobalEnv)

#variables que podrían ser factores
unique(CONS_C1_df$motivodeegreso)
unique(CONS_C1_df$evaluacindelprocesoteraputico)
unique(CONS_C1_df$eva_consumo)
unique(CONS_C1_df$eva_fam)
unique(CONS_C1_df$eva_relinterp)
unique(CONS_C1_df$eva_ocupacion)
unique(CONS_C1_df$eva_sm)
unique(CONS_C1_df$eva_fisica)
unique(CONS_C1_df$eva_transgnorma)
unique(CONS_C1_df$Sexo)
unique(CONS_C1_df$X.Se.trata.de.una.mujer.embarazada.)
unique(CONS_C1_df$`Tipo.de.Plan`)
unique(CONS_C1_df$`Tipo.de.Programa`)

#si se quiere exportar a stata
#generarlos como factores
#      CONS_C1_df %>%
#        dplyr::mutate(motivodeegreso_fac=as.factor(motivodeegreso)) %>%
#        dplyr::mutate(evaluacindelprocesoteraputico_fac=as.factor(evaluacindelprocesoteraputico)) %>%
#        dplyr::mutate(eva_consumo_fac=as.factor(eva_consumo)) %>%
#        dplyr::mutate(eva_fam_fac=as.factor(eva_fam)) %>%  
#        dplyr::mutate(eva_relinterp_fac=as.factor(eva_relinterp)) %>%  
#        dplyr::mutate(eva_ocupacion_fac=as.factor(eva_ocupacion)) %>%
#        dplyr::mutate(eva_sm_fac=as.factor(eva_sm)) %>%  
#        dplyr::mutate(eva_fisica_fac=as.factor(eva_fisica)) %>%
#        dplyr::mutate(eva_transgnorma_fac=as.factor(eva_transgnorma)) %>%  
#        dplyr::mutate(sexo_fac=as.factor(Sexo)) %>%
#        dplyr::mutate(embarazo_fac=as.factor(`X.Se.trata.de.una.mujer.embarazada.`)) %>%
#        dplyr::mutate(tipo_de_plan_fac=as.factor(`Tipo.de.Plan`)) %>%  
#        dplyr::mutate(tipo_de_programa_fac=as.factor(`Tipo.de.Programa`)) %>%  
#        assign("CONS_C1_df",.,envir = .GlobalEnv)

CONS_C1_df %>%
  dplyr::mutate(motivodeegreso=as.factor(motivodeegreso)) %>%
  dplyr::mutate(evaluacindelprocesoteraputico=as.factor(evaluacindelprocesoteraputico)) %>%
  dplyr::mutate(eva_consumo=as.factor(eva_consumo)) %>%
  dplyr::mutate(eva_fam=as.factor(eva_fam)) %>%  
  dplyr::mutate(eva_relinterp=as.factor(eva_relinterp)) %>%  
  dplyr::mutate(eva_ocupacion=as.factor(eva_ocupacion)) %>%
  dplyr::mutate(eva_sm=as.factor(eva_sm)) %>%  
  dplyr::mutate(eva_fisica=as.factor(eva_fisica)) %>%
  dplyr::mutate(eva_transgnorma=as.factor(eva_transgnorma)) %>%  
  dplyr::mutate(sexo=as.factor(Sexo)) %>%
  dplyr::mutate(embarazo=as.factor(`X.Se.trata.de.una.mujer.embarazada.`)) %>%
  dplyr::mutate(tipo_de_plan=as.factor(`Tipo.de.Plan`)) %>%  
  dplyr::mutate(tipo_de_programa=as.factor(`Tipo.de.Programa`)) %>%
#actualizacion a ene 2020
  dplyr::mutate(`tipo_centro`=as.factor(`tipo_centro`)) %>%
  dplyr::mutate(`Servicio.de.Salud`=as.factor(`Servicio.de.Salud`)) %>%
  dplyr::mutate(SENDA=as.factor(SENDA)) %>%
  dplyr::mutate(Origen.de.Ingreso=as.factor(Origen.de.Ingreso)) %>%
  dplyr::mutate(País.Nacimiento=as.factor(País.Nacimiento)) %>%
  dplyr::mutate(Nacionalidad=as.factor(Nacionalidad)) %>%
  dplyr::mutate(Etnia=as.factor(Etnia)) %>%
  dplyr::mutate(Estado.Conyugal=as.factor(Estado.Conyugal)) %>%
  dplyr::mutate(Sustancia.de.Inicio=as.factor(Sustancia.de.Inicio)) %>%
  dplyr::mutate(X.Se.trata.de.una.mujer.embarazada.=as.factor(X.Se.trata.de.una.mujer.embarazada.)) %>%
  dplyr::mutate(Escolaridad..último.año.cursado.=as.factor(Escolaridad..último.año.cursado.)) %>%
  dplyr::mutate(Condicion.Ocupacional=as.factor(Condicion.Ocupacional)) %>%
  dplyr::mutate(Categoría.Ocupacional=as.factor(Categoría.Ocupacional)) %>%
  dplyr::mutate(Rubro.Trabaja=as.factor(Rubro.Trabaja)) %>%
  dplyr::mutate(Con.Quién.Vive=as.factor(Con.Quién.Vive)) %>%
  dplyr::mutate(Tipo.de.vivienda=as.factor(Tipo.de.vivienda)) %>%
  dplyr::mutate(Tenencia.de.la.vivienda=as.factor(Tenencia.de.la.vivienda)) %>%
  dplyr::mutate(Sustancia.Principal=as.factor(Sustancia.Principal)) %>%
  dplyr::mutate(Otras.Sustancias.nº1=as.factor(Otras.Sustancias.nº1)) %>%
  dplyr::mutate(Otras.Sustancias.nº2=as.factor(Otras.Sustancias.nº2)) %>%
  dplyr::mutate(Otras.Sustancias.nº3=as.factor(Otras.Sustancias.nº3)) %>%
  dplyr::mutate(Frecuencia.de.Consumo..Sustancia.Principal.=as.factor(Frecuencia.de.Consumo..Sustancia.Principal.)) %>%
  dplyr::mutate(Vía.Administración..Sustancia.Principal.=as.factor(Vía.Administración..Sustancia.Principal.)) %>%
  dplyr::mutate(Diagnóstico.Trs..Consumo.Sustancia=as.factor(Diagnóstico.Trs..Consumo.Sustancia)) %>%
  dplyr::mutate(Diagnóstico.Trs..Psiquiátrico.DSM.IV=as.factor(Diagnóstico.Trs..Psiquiátrico.DSM.IV)) %>%
  dplyr::mutate(Diagnóstico.Trs..Psiquiátrico.SUB.DSM.IV=as.factor(Diagnóstico.Trs..Psiquiátrico.SUB.DSM.IV)) %>%
  dplyr::mutate(X2.Diagnóstico.Trs..Psiquiátrico.DSM.IV=as.factor(X2.Diagnóstico.Trs..Psiquiátrico.DSM.IV)) %>%
  dplyr::mutate(X2.Diagnóstico.Trs..Psiquiátrico.SUB.DSM.IV=as.factor(X2.Diagnóstico.Trs..Psiquiátrico.SUB.DSM.IV)) %>%
  dplyr::mutate(X3.Diagnóstico.Trs..Psiquiátrico.DSM.IV=as.factor(X3.Diagnóstico.Trs..Psiquiátrico.DSM.IV)) %>%
  dplyr::mutate(X3.Diagnóstico.Trs..Psiquiátrico.SUB.DSM.IV=as.factor(X3.Diagnóstico.Trs..Psiquiátrico.SUB.DSM.IV)) %>%
  dplyr::mutate(Diagnóstico.Trs..Psiquiátrico.CIE.10=as.factor(Diagnóstico.Trs..Psiquiátrico.CIE.10)) %>%
  dplyr::mutate(Diagnóstico.Trs..Psiquiátrico.SUB.CIE.10=as.factor(Diagnóstico.Trs..Psiquiátrico.SUB.CIE.10)) %>%
  dplyr::mutate(X2.Diagnóstico.Trs..Psiquiátrico.CIE.10=as.factor(X2.Diagnóstico.Trs..Psiquiátrico.CIE.10)) %>%
  dplyr::mutate(X2.Diagnóstico.Trs..Psiquiátrico.SUB.CIE.10=as.factor(X2.Diagnóstico.Trs..Psiquiátrico.SUB.CIE.10)) %>%
  dplyr::mutate(X3.Diagnóstico.Trs..Psiquiátrico.CIE.10=as.factor(X3.Diagnóstico.Trs..Psiquiátrico.CIE.10)) %>%
  dplyr::mutate(X3.Diagnóstico.Trs..Psiquiátrico.SUB.CIE.10=as.factor(X3.Diagnóstico.Trs..Psiquiátrico.SUB.CIE.10)) %>%
  dplyr::mutate(Diagnóstico.Trs..Físico=as.factor(Diagnóstico.Trs..Físico)) %>%
  dplyr::mutate(Otros.Problemas.de.Atención.de.Salud.Mental=as.factor(Otros.Problemas.de.Atención.de.Salud.Mental)) %>%
  dplyr::mutate(Compromiso.Biopsicosocial=as.factor(Compromiso.Biopsicosocial)) %>%
  dplyr::mutate(DIAGNOSTICO.GLOBAL.DE.NECESIDADES.DE.INTEGRACION.SOCIAL=as.factor(DIAGNOSTICO.GLOBAL.DE.NECESIDADES.DE.INTEGRACION.SOCIAL)) %>%
  dplyr::mutate(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.HUMANO=as.factor(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.HUMANO)) %>%
  dplyr::mutate(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.FISICO=as.factor(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.FISICO)) %>%
  dplyr::mutate(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.SOCIAL=as.factor(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.SOCIAL)) %>%
  dplyr::mutate(Usuario.de.Tribunales..Tratamiento.Drogas=as.factor(Usuario.de.Tribunales..Tratamiento.Drogas)) %>%
  dplyr::mutate(Consentimiento.Informado=as.factor(Consentimiento.Informado)) %>%
  dplyr::mutate(motivodeegreso=as.factor(motivodeegreso)) %>%
  dplyr::mutate(Tipo.Centro.Derivación=as.factor(Tipo.Centro.Derivación)) %>%
  dplyr::mutate(evaluacindelprocesoteraputico=as.factor(evaluacindelprocesoteraputico)) %>%
  dplyr::mutate(eva_consumo=as.factor(eva_consumo)) %>%
  dplyr::mutate(eva_fam=as.factor(eva_fam)) %>%
  dplyr::mutate(eva_relinterp=as.factor(eva_relinterp)) %>%
  dplyr::mutate(eva_ocupacion=as.factor(eva_ocupacion)) %>%
  dplyr::mutate(eva_sm=as.factor(eva_sm)) %>%
  dplyr::mutate(eva_fisica=as.factor(eva_fisica)) %>%
  dplyr::mutate(eva_transgnorma=as.factor(eva_transgnorma)) %>%
  dplyr::mutate(Diagnóstico.Trastorno.Psiquiátrico.CIE.10.al.Egreso=as.factor(Diagnóstico.Trastorno.Psiquiátrico.CIE.10.al.Egreso)) %>%
  dplyr::mutate(DIAGNOSTICO.GLOBAL.DE.NECESIDADES.DE.INTEGRACION.SOCIAL.1=as.factor(DIAGNOSTICO.GLOBAL.DE.NECESIDADES.DE.INTEGRACION.SOCIAL.1)) %>%
  dplyr::mutate(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.HUMANO.1=as.factor(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.HUMANO.1)) %>%
  dplyr::mutate(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.FISICO.1=as.factor(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.FISICO.1)) %>%
  dplyr::mutate(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.SOCIAL.1=as.factor(DIAGNOSTICO.DE.NECESIDADES.DE.INTEGRACIóN.SOCIAL.EN.CAPITAL.SOCIAL.1)) %>%
  dplyr::mutate(Motivo.de.egreso.Alta.Administrativa=as.factor(Motivo.de.egreso.Alta.Administrativa)) %>%
  dplyr::mutate(Ha.estado.embarazada.egreso.=as.factor(Ha.estado.embarazada.egreso.)) %>%
  dplyr::mutate(identidad.de.genero=as.factor(identidad.de.genero)) %>%
  dplyr::mutate(discapacidad=as.factor(discapacidad)) %>%
  dplyr::mutate(Opción.discapacidad=as.factor(Opción.discapacidad)) %>%
  dplyr::mutate(sexo=as.factor(sexo)) %>%
  dplyr::mutate(embarazo=as.factor(embarazo)) %>%
  dplyr::mutate(tipo_de_plan=as.factor(tipo_de_plan)) %>%
  dplyr::mutate(tipo_de_programa=as.factor(tipo_de_programa)) %>%
  assign("CONS_C1_df",.,envir = .GlobalEnv)

#Ver si los está formateando como corresponde, similar a STATA
str(CONS_C1_df$motivodeegreso)
table(CONS_C1_df$motivodeegreso)

str(CONS_C1_df$embarazo)
table(CONS_C1_df$embarazo)

str(CONS_C1_df$tipo_de_plan)
table(CONS_C1_df$tipo_de_plan)

str(CONS_C1_df$tipo_de_programa)
table(CONS_C1_df$tipo_de_programa)

str(CONS_C1_df$eva_ocupacion)
table(CONS_C1_df$eva_ocupacion)
#
#
#-#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#-#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#-#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#-#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#-#_#
#
#
##FECHAS
View()
dim(CONS_C1[which(is.na(CONS_C1$`Fecha.Egreso.de.Tratamiento`)),]) #
dim(CONS_C1_df[which(is.na(CONS_C1_df$fech_egres)),]) #9830
#9830-9743 es igual a 87 casos que no pudieron ser transformados en fechas, coincidentes con el parse

CONS_C1_df %>%
  dplyr::mutate(fech_ing= ifelse(row=="14504", "10/01/2011",
                          ifelse(row=="88379", "09/07/2015", #ACTUALIZACION 2020-01-17: cambio fecha ingreso
                          ifelse(row=="79428", "09/07/2015", #ACTUALIZACION 2020-01-17: cambio fecha ingreso             
                                        fech_ing))))  %>%
  dplyr::mutate(fech_ing= lubridate::parse_date_time(fech_ing, c("%d/%m/%Y"),exact=T)) %>% #un caso falla en ser transformado
  dplyr::mutate(fech_egres_sin_fmt= fech_egres) %>% #me quedo con esta variable por si acaso
  dplyr::mutate(fech_egres= ifelse(row=="36308", "02/04/2013",
                            ifelse(row=="14083", "03/05/2011",
                            ifelse(row=="6349", "01/07/2010",
                            ifelse(row=="42741", "02/08/2013",
                            ifelse(row=="8608","01/02/2011",
                            ifelse(row=="11709","01/02/2011",
                            ifelse(row=="40486","03/07/2013",
                            ifelse(row=="42521","09/07/2013",
                            ifelse(row=="5757", "04/10/2010", #cambiado
                            ifelse(row=="39507", "02/07/2013",
                            ifelse(row=="3195", "04/10/2010",
                            ifelse(row=="37845", "01/07/2013",
                            ifelse(row=="40180", "07/08/2013",
                            ifelse(row=="28008", "27/11/2012",
                            ifelse(row=="35971", "01/03/2013",
                            ifelse(row=="5172", "03/05/2011",
                            ifelse(row=="10415", "03/05/2011",
                            ifelse(row=="16385", "30/08/2011",
                            ifelse(row=="39932", "02/08/2013",
                            ifelse(row=="16983", "06/09/2011",
                            ifelse(row=="88379", "11/04/2016", #ACTUALIZACION 2020-01-17: cambio fecha egreso
                            ifelse(row=="79428", "11/04/2016", #ACTUALIZACION 2020-01-17: cambio fecha egreso
                            ifelse(row=="37004", "02/08/2013",fech_egres)))))))))))))))))))))))) %>%
  dplyr::mutate(fech_egres= lubridate::parse_date_time(stringr::str_trim(fech_egres), 
                                                       orders = c("%d/%m/%Y", "%d/%m/%y","%d%m%Y"),exact=T)) %>%
  dplyr::arrange(desc(ano_bd)) %>% 
  assign("CONS_C1_df",.,envir = .GlobalEnv) #87 failed to parse, bajé a 37, y 30 después de quitar espacios

# 2019-12-11, had to format this date because it was bad labellled.
#CONS_C1_df[CONS_C1_df$row=="5757","fech_egres"] <- lubridate::parse_date_time(stringr::str_trim("04/10/2010"), 
#                                                                              orders = c("%d/%m/%Y", "%d/%m/%y","%d%m%Y"),exact=T)

#
######1.b. new variables------------------
View()

#To protect the ID of each patient
CONS_C1_df %>%
  dplyr::mutate(id_mod=sub("(.{5}).", "\\1*",id)) %>%
  dplyr::mutate(id_mod=sub("(.{6}).", "\\1*",id_mod)) %>%
  assign("CONS_C1_df",.,envir = .GlobalEnv)

# Transform ID to identify date of birth
CONS_C1_df %>%
  dplyr::mutate(ano_nac=as.numeric(stringi::stri_sub(id,-4,-1))) %>%
  assign("CONS_C1_df",.,envir = .GlobalEnv)

  #be careful of different ages
      #example of duplicated age
    CONS_C1_df %>% dplyr::filter(HASH_KEY=="f69caa1b82135a69956c4f4293ec4d6f" |HASH_KEY== "6c409c18bf7cc518819dc63c4e8e98ef") %>% #ACTUALIZACION ENE 2020, incluí caso que me informó Maureen
    dplyr::select(row, HASH_KEY, id, ano_nac, ano_bd,fech_ing, Edad) 

######1.c. Create Factor Variables (2020-01-08)------------------
    #Región.del.Centro
    #'Región de Arica y Parinacota', 
    #'Región de Tarapacá', 
    #'Región de Antofagasta', 
    #'Región de Atacama', 
    #'Región de Coquimbo', 
    #'Región de Valparaíso', 
    #'Región Metropolitana de Santiago', 
    #'Región del Libertador General Bernardo OHiggins', 
    #'Región del Maule', 
    #'Región de Ñuble', 
    #'Región del Biobío', 
    #'Región de La Araucanía', 
    #'Región de Los Ríos', 
    #'Región de Los Lagos', 
    #'Región de Aysén del General Carlos Ibáñez del Campo', 
    #'Región de Magallanes y de la Antártica Chilena'
    #"Arica y Parinacota y Tarapacá"
    #"Antofagasta"
    #"Atacama y Coquimbo"
    #"Valparaíso"
    #"O'Higgins"

save.image("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/1.RData")
    ```
<br>

One of them is the date of application of the TOP questionnaire. As can be seen in Table 8, 94% of the registries are unique combinations of date of application of the TOP questionnaire and HASH key.

<br>

```{r Duplicated2}
    duplicated_rows_concat_TOP2 <- data.frame(duplicated_HASH_date = duplicated(CONS_TOP_df_dup_ENE_2020_prev2[,c("HASH_KEY","fech_ap_top")]), 
                                         row_dup_HASH_date = 1:nrow(CONS_TOP_df_dup_ENE_2020_prev2[,c("HASH_KEY","fech_ap_top")])) #%>%

    as.data.table(CONS_TOP_df_dup_ENE_2020_prev2)[, dup_hash_date_ap := .N, by = c("HASH_KEY","fech_ap_top")] %>% ##dim()
      dplyr::group_by(dup_hash_date_ap) %>%
      dplyr::summarise(n=n()) %>%
      mutate(perc = round(n / sum(n),3)*100) %>%
      mutate(perc = paste0(perc,"%")) %>%
      as.data.frame(.) %>%
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 8. Frequency and Percentage of Duplicated Values of the combination of HASH-Key & Date of Application of TOP", 
                   col.names= c("Times present in Dataset", " Frequencies", "Percentage"),  align =rep('c', 2))  %>%
      kable_styling(bootstrap_options = c("striped", "hover"),font_size = 11) %>%
  scroll_box(width = "100%", height = "350px")
```
<br>

  As can be seen in Table 9, in some cases the only thing that varies is the stage of treatment (005238a56b9614ead0903bb264de7be9_2016-12-28) in others also varies the qualitative observations (67e87f8ff93505867ccab2eb0150c7f0_2016-06-29) or variables relative to the content of the evaluation (f414c49e178c414f020b114b09d962d2_2017-06-23). **Can a single  combination of date of query and HASH have different dates of admission?**

<br>

```{r Duplicated2.2}
as.data.table(CONS_TOP_df_dup_ENE_2020_prev2)[, dup_hash_date_ap := .N, by = c("HASH_KEY","fech_ap_top")] %>%
  dplyr::filter(dup_hash_date_ap>1) %>% #Aquí veo quienes aparecen más de una vez
  dplyr::arrange(HASH_KEY,fech_ap_top) %>% 
  dplyr::select(HASH_KEY, hash_rut_completo, id_mod, ano_bd, fech_ap_top, TOP,fech_nac, Edad, Sexo, Plan.de.Tratamiento, Nombre.del.Centro, Sustancia.Principal.1, Sustancia.Principal.2, Sustancia.Principal.3, starts_with("Total"),starts_with("Dósis")) %>%
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 9. Duplicated rows of the combination of HASH-Key & Date of Application of TOP", 
                   #col.names= c("Duplicated", " Frequencies", "Percentage"),
                   align =rep('c', 102))  %>%
      kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  scroll_box(width = "100%", height = "350px")
```


### 5. Deletion of nearly exact duplicated cases

nbsp;
<br>
We need reduce the number of cases, but in the mean time, try to reduce the loss of information due to specific changes in each entry, despite it could be originated by different mechanisms (eg. different professionals evaluated the same patients for an specific stage of the treatment, but highlighting different things), other than comming from the same yearly dataset.

<br>


```{r deduplication1, echo=T, cache=T, paged.print=TRUE}
#create vector with variable names
names_top <- names(CONS_TOP_df_dup_ENE_2020_prev2[,c(1,2,4,8,10:48)])
#Group by duplicated rows 
as.data.table(CONS_TOP_df_dup_ENE_2020_prev2)[, dup_todo_TOP := .N, by = names_top] %>%
  data.table::as.data.table() %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev3",.,envir = .GlobalEnv)
#summarise duplicates and times
as.data.table(CONS_TOP_df_dup_ENE_2020_prev3)[, dup_todo_TOP := .N, by = names_top] %>%
  dplyr::group_by(dup_todo_TOP) %>%
  dplyr::summarise(n()) %>%
  data.frame() %>%
  dplyr::rename("Times present in Dataset"=dup_todo_TOP, "Number of Rows"=`n..`) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 10. Duplicated cases in almost every variable",
                 align ="cccc")  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10)
```

```{r dataset_creation, echo=F, paged.print=TRUE, cache=T, warning=F}
data.table::data.table(CONS_TOP_df_dup_ENE_2020_prev3) %>%
  dplyr::arrange(desc(ano_bd)) %>%
  dplyr::distinct_(.dots = names_top, .keep_all = TRUE) %>%
  dplyr::arrange(HASH_KEY, fech_ing, fech_ap_top, desc(ano_bd)) %>%
  data.table::as.data.table() %>%
  assign("CONS_TOP_df_dup_ENE_2020",.,envir = .GlobalEnv)
#Unlike base sorting with sort(), NA are: always sorted to the end for local data, even when wrapped with desc().
```

&nbsp;
<br>

As seen in Table 10, not many cases were dropped, which can be interpreted that there is different information regarding patients and specific treatments in each of the remaining `r nrow(CONS_TOP_df_dup_ENE_2020) %>% formatC(., format="f", big.mark=",", digits=0)` rows. 


&nbsp;
<br>
