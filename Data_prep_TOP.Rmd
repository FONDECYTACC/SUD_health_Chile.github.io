---
title: "Data Preparation of TOP Dataset"
date: "`r withr::with_locale(new = c('LC_TIME' = 'C'), code =format(Sys.time(),'%B %d, %Y'))`"
output:
  html_document:
    code_folding: hide 
    toc: true # table of content true
    toc_depth: 3  # upto three depths of headings (specified by #, ## and ###)
    toc_float: true
---

<style type="text/css">
.tablelines table, .tablelines td, .tablelines th {
        border: 1px solid black;
        }
.centrado {
    text-align: center;
}
.table.center {
    margin-left:auto; 
    margin-right:auto;
  }
.table_wrapper{
    display: block;
    overflow-x: auto;
    white-space: nowrap;
}
code.r{
  font-size: 8px;
}
body{ /* Normal  */
      text-align: justify;
  }
</style>

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px; text-align: justify;}
</style>
```{r prev, include=FALSE}
rm(list=ls());gc()
unlink(paste0(here::here(),"/*_cache"), recursive = TRUE)
path<-gsub("/SUD_CL","",here::here())
load(paste0(path,"/2.Rdata"))
```
```{r setup, include=FALSE}
#load("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/3.RData")
#load("H:/sud_cl/3.RData")
#path <-"G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/SUD_CL"
#Libraries used in the routine. Dont change the order
#if(!require(tidyr)){install.packages("tidyr")}
#if(!require(DataExplorer)){install.packages("DataExplorer")}
#if(!require(stringi)){install.packages("stringi", dependencies=TRUE, INSTALL_opts = c('--no-lock'))}
#if(!require(stringr)){install.packages("stringr")}
#if(!require(ggplot2)){install.packages("ggplot2")}
#if(!require(Hmisc)){install.packages("Hmisc")}
#if(!require(kableExtra)){install.packages("kableExtra")}
#if(!require(plotly)){install.packages("plotly")}
#if(!require(rbokeh)){install.packages("rbokeh")}
#if(!require(altair)){install.packages("altair")}
#if(!require(zoo)){install.packages("zoo")}
#if(!require(broom)){install.packages("broom")}
#if(!require(sqldf)){install.packages("sqldf")} 
#if(!require(devtools)){install.packages("devtools")}
#if(!require(Statamarkdown)){install_github("hemken/Statamarkdown")}
##if(!require(codebook)){install.packages("codebook")}
#if(!require(data.table)){install.packages("data.table")}
#if(!require(dplyr)){install.packages("dplyr")}
require(tidyr)
#require(DataExplorer)
require(stringi)
require(stringr)
require(ggplot2)
require(Hmisc)
require(kableExtra)
require(plotly)
require(rbokeh)
require(altair)
require(zoo)
require(broom)
require(sqldf)
require(devtools)
require(Statamarkdown)
require(codebook)
require(data.table)
require(dplyr)
require(DT)
require(janitor)
require(glue)
```

&nbsp;

<div class = "blue">
TOP or Treatment Outcomes Profile (“Perfil de Resultados de Tratamiento”) serves as a tool for monitoring and follow-up of SUD treatments. It is a questionnaire that every user must complete at the beginning of treatment, every three months during treatment, at treatment discharge, and some centers may apply it after discharge. **Hence, it is crucial to distinguish between the date of application and the date of admission. Additionally, to characterize each user and their profile in each phase of life, it is necessary to standardize his birth date**.
</div>


&nbsp;
<br>

### 1. Relationship of TOP Dataset with C1

```{r tab1_first_changes, cache=T}
#create the first changes into TOP dataset
CONS_TOP %>%
  dplyr::mutate(ano_bd=as.numeric(substr(TABLE,4,7))) %>%
  dplyr::mutate(id_mod=sub("(.{5}).", "\\1*",as.character(ID))) %>%
  dplyr::mutate(id_mod=sub("(.{6}).", "\\1*",as.character(id_mod))) %>% 
  dplyr::select(HASH_KEY, hash_rut_completo, id_mod, ID, ano_bd, everything()) %>%
  dplyr::arrange(desc(ano_bd)) %>% 
  assign("CONS_TOP_df",.,envir = .GlobalEnv)
as.data.frame(cbind("Vars. of TOP"=c(names(CONS_TOP_df), rep("",65)),"Vars. of C1"=names(CONS_C1_df_dup_ENE_2020)))  %>%
    knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                caption="Table 1. Comparison between variables of TOP and C1",
              col.names = c("Vars.\nof TOP", "Vars.\nof C1"),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
            scroll_box(width = "100%", height = "350px")
```

<br>

As seen in Table 1, the C1 dataset had more variables than the TOPs dataset. One of the variables in both datasets is age, sex, the center of treatment, the region of the center and type of center, primary substances, date of admission to treatment, and type of plan of the treatment. Considering the above, we might replace missing or invalid information of C1 with TOP, specially time-invariant variables.

### 2. Change Dates of Admission, Application of TOP and Birth

As shown in Table 2, we brought a new format to every date to show first a 4-digit year, 2-digit month, and 2-digit day. This format also matches the format of these variables in the C1 dataset. Additionally, we masked SENDA’s IDs to avoid the eventual identification of users from third parties.

<br>

```{r tab2_changes_dates, cache=T}
#change dates
CONS_TOP_df %>%
  dplyr::mutate(fech_ing= lubridate::parse_date_time(Fecha.de.Ingreso.a.Tratamiento, c("%d/%m/%Y"),exact=T)) %>% #No parse failures
  #dplyr::select(Fecha.de.Ingreso.a.Tratamiento,fech_ing) %>% head() #To see how it responds to changes. Many null values
  dplyr::mutate(fech_ing_sin_fmt= Fecha.de.Ingreso.a.Tratamiento) %>% #keep this variable for comparison
  dplyr::mutate(fech_ap_top= lubridate::parse_date_time(Fecha.Aplicación.TOP, c("%Y-%m-%d"),exact=T)) %>% #No parse failures
  #dplyr::select(Fecha.Aplicación.TOP,fech_ap_top) %>% head() #To see how it responds to changes.
  dplyr::mutate(fech_nac= lubridate::parse_date_time(str_trim(Fecha.Nacimiento), orders = c("%d/%m/%Y"),exact=T)) %>%
  #dplyr::select(Fecha.Nacimiento,fech_nac) %>% View() #To see how it responds to changes. No failures
  assign("CONS_TOP_df",.,envir = .GlobalEnv) #
#Example of transformations
CONS_TOP_df %>%
  dplyr::select(Fecha.de.Ingreso.a.Tratamiento,fech_ing,Fecha.Aplicación.TOP,fech_ap_top,Fecha.Nacimiento,fech_nac) %>% head() %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 2. Example of date of admission to treatment",
              col.names = c("Unformatted Date of Admission","Date of Admission", "Unformatted Date of Application", "Date of Application", "Unformatted Date of Birth","Date of Birth"),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10) 
```

&nbsp;
<br>

In the transformation of the dates of admission, we found a considerable number of missing values (n= `r formatC(CONS_TOP_df %>% dplyr::filter(is.na(fech_ing)) %>% summarise(n()) %>% as.numeric(),format="f", big.mark=",", digits=0)`). However, **there were `r CONS_TOP_df %>% dplyr::filter(is.na(fech_ap_top)) %>% summarise(n())` missing dates of application of the TOP** and  `r CONS_TOP_df %>% dplyr::filter(is.na(fech_nac)) %>% summarise(n())` missing birth dates (despite that `r CONS_TOP_df %>% dplyr::select(Edad) %>% dplyr::filter(Edad<18|Edad>90) %>% nrow()` cases could be invalid according to the criteria stated by SENDA's professionals). **The fact of having a few missing values in the date of admission is problematic because treatments are conceived as the unit in the C1 dataset  (understood as the combination of the date of admission and user ID). Suppose we do not obtain the remaining dates of admission missed. In that case, it is difficult to understand these profiles in the context of a treatment, and if they change within a treatment or in comparison to previous or following treatments**.


<br>

```{r fig1_fech_ing_nas, echo=T, fig.align='center',fig.cap= "Figure 1. Pie Chart of Missing Dates of Admission"}
#Hay un 1% de casos perdidos
CONS_TOP_df %>%
  dplyr::group_by(is.na(Fecha.de.Ingreso.a.Tratamiento)) %>% 
  dplyr::rename("MISS_DATE_ADM"=`is.na(Fecha.de.Ingreso.a.Tratamiento)`) %>% 
  summarise(n=n()) %>% 
  data.frame() %>%  mutate(perc=n/sum(n)) %>%
  ggplot(aes(x="", y=n, fill=MISS_DATE_ADM))+
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start=0) + 
  scale_fill_brewer("Missing Date\nof Admission") + theme_minimal() +
  theme(axis.text.x=element_blank())+
  geom_text(aes(y = n/2 + c(0, cumsum(n)[-length(n)]), 
                label = paste0(formatC(n, format="f", big.mark=",", digits=0), "\n(",scales::percent(perc),")")), size=4) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.border = element_blank(),
    panel.grid=element_blank(),
    axis.ticks = element_blank(),
    plot.title=element_text(size=14, face="bold")
  ) 
```

<br>


**We adopted the following guidelines:**

- Replace dates from the cases that share the same information within the TOP dataset (1), or
- Replace them from the C1 dataset, using the date of application and the stage of application as a reference to determine the closest date of admission (2)

<br>

First, we identified applications of the TOP that were applied for the same stage (TOP at Admission) and the same user on the coinciding dates of application. These cases could replace missing dates of admission.

```{r tab3_replace_date_adm_table_top}
CONS_TOP_df_dup_fech_ing_adm <- dplyr::select(CONS_TOP_df, HASH_KEY, fech_ap_top, fech_ing, TOP)%>% 
  dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% as.data.frame()
CONS_TOP_df_dup_fech_ing <- dplyr::select(CONS_TOP_df, HASH_KEY, fech_ap_top, fech_ing, TOP)%>% 
  dplyr::filter(!is.na(fech_ing)) %>% as.data.frame()
######################################
#nrow(CONS_TOP_df_dup_fech_ing) ##DESPITE HAS MORE ROWS, DOES NOT MAKE A DIFFERENCE IN THE QUANTITY
#nrow(CONS_TOP_df_dup_fech_ing_adm)
######################################
#Join datasets 
dplyr::left_join(CONS_TOP_df,CONS_TOP_df_dup_fech_ing, by = c("HASH_KEY", "fech_ap_top"), suffix = c("", ".y")) %>% #names() #junto con la BD que hice
  dplyr::filter(!is.na(fech_ing.y), is.na(fech_ing)) %>%  #filtro los casos que en que sí tengo fecha de ingreso en el merge, pero no la tengo en la BD.
  dplyr::select(row,ano_bd, HASH_KEY, hash_rut_completo, id_mod, Edad, Sexo, fech_ing, fech_ap_top, TOP, fech_ing.y) %>% #dejo para ver cómo la icorporo
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 3. HASHs with missing dates of admission that can be replaced by another case with the same characteristics",
              col.names = c("Row ID","Year of Dataset", "HASH KEY","HASH Key (Alternative)","SENDA's ID", "Year", "Sex", "Date of Admission", "Date of Application","Stage of TOP", "Date of Admission (replacement)" ),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
            scroll_box(width = "100%", height = "350px")
```

```{r save_changes0, cache=T}
# HASHs que pueden ser remplazados con otro caso de las mismas características dentro del top, que no sea de fecha de ingreso,no genere filas duplicadas (row_number) por cada fecha de admisión. Sólo tomará las aplicaciones ingreso. Esas las va a calzar con fechas de ingreso.
CONS_TOP_df_dup_fech_ing_adm <- dplyr::select(CONS_TOP_df, HASH_KEY, fech_ap_top, fech_ing, TOP)%>% 
  dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::group_by(HASH_KEY, fech_ap_top) %>% dplyr::mutate(row_leftjoin=row_number()) %>% ungroup()  %>% dplyr::filter(row_leftjoin==1) %>% as.data.frame() #lo que hagho es que si hay más de una fecha de ingreso en cada grupo de hash y fecha de aplicación, la dejo pasar y dejo la primera.

#AQUÍ SÓLO REEMPLAZO LA FECHA DE ADMISION CON UNA FILA QUE COMPARTA LA MISMA FECHA DE APLICACIÓN,DENTRO DE LOS CON TOP AL INGRESO, Y ME QUEDO CON LA FECHA DE INGRESO DE ESA VARIABLE. 
CONS_TOP_df %>%
  dplyr::group_by(HASH_KEY, fech_ap_top) %>% dplyr::mutate(row_leftjoin=row_number()) %>% ungroup() %>%
dplyr::left_join(CONS_TOP_df_dup_fech_ing_adm, by = c("HASH_KEY", "fech_ap_top","row_leftjoin"), suffix = c("", ".y")) %>% #names() #junto con la BD que hice, sólo tomo una.
  dplyr::mutate(OBS= case_when(is.na(fech_ing) & !is.na(fech_ing.y)~ "1.1.Replace miss date admission w TOPs w same stage & user",
                               TRUE ~ "")) %>%
  dplyr::mutate(fech_ing= ifelse(is.na(fech_ing)& !is.na(fech_ing.y),as.Date(as.character(fech_ing.y), format="%Y-%m-%d"), as.Date(as.character(fech_ing), format="%Y-%m-%d"))) %>%
  dplyr::mutate(fech_ing=as.Date(fech_ing)) %>%
  dplyr::mutate(fech_ap_top=as.Date(as.character(fech_ap_top))) %>% #APROVECHO DE NORMALIZAR ESTAS VARIABLES PARA QUE TENGAN LA MISMA ESTRUCTURA
  dplyr::mutate(fech_nac=as.Date(as.character(fech_nac))) %>%
  dplyr::select(-fech_ing.y, -TOP.y, -row_leftjoin) %>%
#PAra ver cómo evoluciona y si hay errores. Haasta el momento sólo hay un NA que parece justificado porque no calzan las fechas de aplicaicón.
#    dplyr::filter(HASH_KEY=="0669c73ad96e50fb9605c167cc40693e"|HASH_KEY=="ee0360d19dd5f300526c624c58090c79"|HASH_KEY=="c91ec6bb76b4cf5cb8b60f209#44a2208"|HASH_KEY=="ee0360d19dd5f300526c624c58090c79"|HASH_KEY=="153b828278ea88dc5ab15039e3e0c882") %>% dplyr::select(HASH_KEY,fech_ing, #fech_ing_sin_fmt )%>% print()
  
  #dplyr::group_by(Edad) %>% summarise(n=n()) %>% View()
 assign("CONS_TOP_df_dup_ENE_2020_prev0",., envir = .GlobalEnv) 
#str(CONS_TOP_df_dup_ENE_2020_prev0) #TENGO PROBLEMAS PARA FORMATEAR LA ECHA DE INGRESO SIN HORAS
```

Done this, we still found many cases that do not have a date of admission (n= `r formatC(CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(is.na(fech_ing)) %>% nrow(), format="f", big.mark=",", digits=0)`). Another option would be to replace the date of admission with the date of application, in the event of application. However, this was not possible due to inaccuracy of data, observed in the difference between the date of admission and the date of application of those that have both dates available (Mean=`r CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% summarise(Mean= mean(diff_fech_ing_ap), Median=quantile(diff_fech_ing_ap, c(.5)), Q25=quantile(diff_fech_ing_ap, c(.25)), Q75=quantile(diff_fech_ing_ap, c(.75))) %>% round(2) %>% dplyr::select(Mean)`; Mdn= `r CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% summarise(Mean= mean(diff_fech_ing_ap), Median=quantile(diff_fech_ing_ap, c(.5)), Q25=quantile(diff_fech_ing_ap, c(.25)), Q75=quantile(diff_fech_ing_ap, c(.75))) %>% round(2) %>% dplyr::select(Median)` [Q1= `r CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% summarise(Mean= mean(diff_fech_ing_ap), Median=quantile(diff_fech_ing_ap, c(.5)), Q25=quantile(diff_fech_ing_ap, c(.25)), Q75=quantile(diff_fech_ing_ap, c(.75))) %>% round(2) %>% dplyr::select(Q25)`, Q3= `r CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% summarise(Mean= mean(diff_fech_ing_ap), Median=quantile(diff_fech_ing_ap, c(.5)), Q25=quantile(diff_fech_ing_ap, c(.25)), Q75=quantile(diff_fech_ing_ap, c(.75))) %>% round(2) %>% dplyr::select(Q75)`]). **This means that TOP at admission was applied some days after being admitted to treatments**. 

```{r fig2_diff_dates_adm_application, echo=T, fig.align='center',fig.cap= "Figure 2. Histogram of Differences Between Dates of Admission and Dates of Application of TOP, among those questionnaires applied in the stage of admission"}
CONS_TOP_df_dup_ENE_2020_prev0 %>% 
  dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% 
  dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% 
  dplyr::select(diff_fech_ing_ap) %>% 
  ggplot(aes(x=as.numeric(diff_fech_ing_ap))) +
  geom_histogram(color="black", fill="white") +
  theme_classic() +
  labs(x= "Diff. in Dates of Admission & Date of Application of TOP", y ="Frequencies", caption=paste0("no. of cases= ",CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(!is.na(fech_ing), TOP=="Ingreso") %>% dplyr::mutate(diff_fech_ing_ap=as.numeric(fech_ing-fech_ap_top, units="days")) %>% summarise(n())))
```

<br>

In Table 4, we may see how many dates could be replaced by the dates in C1. We replaced these dates by selecting the applications corresponding to the stage of admission that had missing data. Then, we paired them with cases in C1 with the same HASH and the same date of admission (in which the date of application of the TOP for admission coincides with the date of admission in C1). Finally, we replaced it with this corresponding date.

```{r tab4_replace_date_adm_table_c1}
  #debiese poner una, HASHs with missing dates of admission that can be replaced by cases in C1 with the same characteristics",
CONS_TOP_df_dup_ENE_2020_prev0 %>% dplyr::filter(TOP=="Ingreso", is.na(fech_ing)) %>% #son aplicación Ingreso, les falta la fecha de ingreso
  dplyr::inner_join(dplyr::select(CONS_C1_df,HASH_KEY, fech_ing) %>% mutate(fech_ing=as.Date(as.character(fech_ing))), by=c("HASH_KEY"="HASH_KEY", "fech_ap_top"="fech_ing"), suffix=c(".TOP",".C1")) %>% as.data.frame() %>%
  dplyr::select(row,ano_bd, HASH_KEY, hash_rut_completo, id_mod, Edad, Sexo, fech_ing,fech_ing_sin_fmt, fech_ap_top, TOP) %>% 
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 4, HASHs with missing dates of admission that can be replaced by cases in C1 with the same characteristics",
              col.names = c("Row ID","Year of Dataset", "HASH KEY","HASH Key (Alternative)","SENDA's ID", "Year", "Sex", "Date of Admission", "Unformatted Date of Admission", "Date of Application","Stage of TOP"),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 9) %>%
      kableExtra::add_footnote( c("Note. The date of application of TOP should replace the missing Date of Admission."), notation = "none") %>%
            scroll_box(width = "100%", height = "350px")
```

```{r save_changes1, cache=T}
#Traerme casos con la fecha estandarizada en C1, crear una fecha de ingreso C1 también formateada, para ver cambios, luego agrupar los casos por HASH y fecha de ingreso, ver cuáles pueden haber más de un hash o fecha de ingreso, sacar sólo los primeros casos de cada combinación, de ahí sólo seleccionar las columnas de interes y convertirlo en data frame (no tibble)

CONS_C1_df_rownum <-CONS_C1_df %>% mutate(fech_ing_C1=fech_ing) %>%  #Actualización= 04-02-2020, ponerle fecha de ingreso formato Date 
   mutate(fech_ing=as.Date(as.character(fech_ing))) %>%
     mutate(fech_ing_C1=as.Date(as.character(fech_ing_C1))) %>%
  dplyr::group_by(HASH_KEY, fech_ing) %>%  
  dplyr::mutate(row_leftjoin=row_number()) %>% 
  ungroup()  %>% 
  dplyr::filter(row_leftjoin==1) %>%
  dplyr::select(HASH_KEY, fech_ing,row_leftjoin, fech_ing_C1) %>%
  data.frame()
  #agrupo por row porque no me interesa que no me traiga el repetido de la fecha de aplicación del top y el HASH, sólo me interesa que desde C1 no me traiga más de una fila.

#join
#n_veces_dup_hash_fech_top
CONS_TOP_df_dup_ENE_2020_prev0 %>% 
  mutate(fech_ing_na=fech_ing) %>%# solo hecha para visibilizar los que fueron reemplazados
  data.frame() %>%
  dplyr::left_join(CONS_C1_df_rownum, by=c("HASH_KEY"="HASH_KEY", "fech_ap_top"="fech_ing"), suffix=c(".TOP",".C1"))%>% #names()
  dplyr::mutate(OBS=case_when((is.na(fech_ing))&(TOP=="Ingreso")&(!is.na(fech_ing_C1))~glue::glue("{OBS};1.2.Replaced missing dates of admission from C1"),
                              TRUE~ OBS))%>% 
  dplyr::mutate(fech_ing= ifelse((is.na(fech_ing))&(TOP=="Ingreso")&(!is.na(fech_ing_C1)),fech_ing_C1, fech_ing)) %>%
  dplyr::mutate(fech_ing= as.Date(as.numeric(fech_ing), format="%Y-%m-%d")) %>% #tuve q agregarle más días para equipararlo
  #dplyr::select(-fech_ing_C1, -row_leftjoin) %>%
#para probar como SE COMPORTA LA TRANSFORMACIÓN
#  dplyr::filter(HASH_KEY=="0669c73ad96e50fb9605c167cc40693e"|HASH_KEY=="ee0360d19dd5f300526c624c58090c79") %>% dplyr::select(fech_ing, #fech_ing_sin_fmt,fech_ing_C1, fech_ap_top) %>% print()
#    dplyr::filter(HASH_KEY %in% c("9b74476e88c81cb019a468106d65ac85","f0210e3f219b7c4b85d9767fc5446c73","d4eeee40471666533d3cbbda0901fada", "c6b57a1ddf9555842bd46216851bf2ee", "92be85e2ace88e24a99fe3980bcd5fc0", "2adfa7e2f6d763c1c6c2b5ed35889243", "ec15af2d6521535ae5bdc50459a62f8c", "978988a1c417f54963eb9f5d84f07c60"), TOP=="Ingreso", is.na(fech_ing_na)) %>% #c6b57a1ddf9555842bd46216851bf2ee  este no debería incorporarlo, porque debiese ser NA
 # dplyr::select(fech_ing, fech_ing_sin_fmt,fech_ing_C1, fech_ap_top) %>% print()
 # View()
  dplyr::mutate(Edad_al_ing=lubridate::time_length(difftime(as.Date(fech_ing), as.Date(fech_nac)),"years")) %>%
  dplyr::mutate(Edad_al_ing=replace(Edad_al_ing, is.na(Edad), NA)) %>%
  as.data.frame() %>% 
  #dplyr::select(fech_nac,Edad_al_ing, fech_ing)
  #View()
  assign("CONS_TOP_df_dup_ENE_2020_prev1",., envir = .GlobalEnv) 
```


<br>

**And what about another important event that is present along the C1 dataset?** Despite that the C1 dataset had two types of events; unfortunately, no other admission dates could be replaced by the dates in C1. We filtered the applications corresponding to the discharge event that had missing data on the date of admission (n= `r CONS_TOP_df_dup_ENE_2020_prev1 %>% dplyr::filter(TOP=="Egreso", is.na(fech_ing)) %>% nrow()`). Then, we paired them with cases in C1 with the same HASH and the same date of discharge (in which the date of application of the TOP for discharge coincides with the date of discharge in C1), ending with `r CONS_TOP_df_dup_ENE_2020_prev1 %>% dplyr::filter(TOP=="Egreso", is.na(fech_ing)) %>% dplyr::inner_join(dplyr::select(CONS_C1_df,HASH_KEY, fech_ing, fech_egres) %>%   mutate(fech_egres=as.Date(as.character(fech_egres))), by=c("HASH_KEY"="HASH_KEY", "fech_ap_top"="fech_egres"), suffix=c(".TOP",".C1")) %>% as.data.frame() %>% nrow()` cases to match.

<br>

Another alternative could be the match by coinciding HASHs and years at the time of admission. However, we require to have valid dates of birth in the TOP dataset to calculate years at a given time. There were `r CONS_TOP_df_dup_ENE_2020_prev1 %>% dplyr::filter(!is.na(fech_nac)) %>% dplyr::select(fech_nac) %>% dplyr::filter(fech_nac<"1929-03-19"|fech_nac>"2001-11-01")  %>% nrow()` dates of birth that might represent invalid values along with the dataset, depending on contextual factors (such as the time in which the user was interviewed). That is why we decided to **get the age at the time of application of the TOP as a valid filter of valid dates of birth**. This criterion aims to bring consistency over both datasets in terms of admitted ages into programs. In the following table, these cases are presented in-depth. 

<br>

```{r tab5_edad, cache=T}
#CONS_TOP_df_dup_ENE_2020_prev1 %>% dplyr::filter(!is.na(fech_nac)) %>% dplyr::select(fech_nac, Edad) %>% dplyr::filter(fech_nac<"1929-03-19"|fech_nac>"2001-11-01")  %>% nrow()

#El filtro que hice yo no sirvió mucho, los rangos de edad. Ahí lo corregí por la influencia de 1929-03-20
#INVESTIGAR ESTE CASO.

  CONS_TOP_df_dup_ENE_2020_prev1 %>% 
  #dplyr::mutate(fech_nac=lubridate::parse_date_time(stringi::stri_sub(ID,-8,-1),"dmY")) %>% 
  dplyr::mutate(Edad_at_ap=lubridate::time_length(difftime(as.Date(fech_ap_top), as.Date(fech_nac)),"years")) %>% #AGREGADO EN APR 2020.
  dplyr::mutate(Edad_at_ap=replace(Edad_at_ap, is.na(fech_nac), NA)) %>% #AGREGADO EN APR 2020.
  #dplyr::filter(Edad<18|Edad>90) %>%
  dplyr::filter(Edad_at_ap<18|Edad_at_ap>90) %>%
  dplyr::mutate(Edad_at_ap=round(Edad_at_ap,2))%>%
  dplyr::filter(Edad_at_ap<18&Edad_at_ap>16) %>%
  nrow() -> edad_adolescentes_menores_18

  CONS_TOP_df_dup_ENE_2020_prev1 %>% 
  #dplyr::mutate(fech_nac=lubridate::parse_date_time(stringi::stri_sub(ID,-8,-1),"dmY")) %>% 
  dplyr::mutate(Edad_at_ap=lubridate::time_length(difftime(as.Date(fech_ap_top), as.Date(fech_nac)),"years")) %>% #AGREGADO EN APR 2020.
  dplyr::mutate(Edad_at_ap=replace(Edad_at_ap, is.na(fech_nac), NA)) %>% #AGREGADO EN APR 2020.
  #dplyr::filter(Edad<18|Edad>90) %>%
  dplyr::filter(Edad_at_ap<18|Edad_at_ap>90) %>%
  dplyr::mutate(Edad_at_ap=round(Edad_at_ap,2))%>%
  dplyr::filter(Edad_at_ap>17&Edad_at_ap<18) %>%
  nrow() -> edad_adolescentes_17

  
  CONS_TOP_df_dup_ENE_2020_prev1 %>% 
  #dplyr::mutate(fech_nac=lubridate::parse_date_time(stringi::stri_sub(ID,-8,-1),"dmY")) %>% 
  dplyr::mutate(Edad_at_ap=lubridate::time_length(difftime(as.Date(fech_ap_top), as.Date(fech_nac)),"years")) %>% #AGREGADO EN APR 2020.
  dplyr::mutate(Edad_at_ap=replace(Edad_at_ap, is.na(fech_nac), NA)) %>% #AGREGADO EN APR 2020.
  #dplyr::filter(Edad<18|Edad>90) %>%
  dplyr::filter(Edad_at_ap<18|Edad_at_ap>90) %>%
  dplyr::mutate(Edad_at_ap=round(Edad_at_ap,2))%>%
  dplyr::select(row, HASH_KEY, id_mod, fech_nac, ano_bd,Edad,Edad_at_ap,fech_ing) %>%
 knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 5. Cases that have a wrongly calculated age at the time of admission",
              col.names = c("Row ID","HASH KEY","SENDA's ID","Year of Birth","Year of Dataset",  "Age", "Age at Application\nof TOP", "Date of Admission"),
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
```

<br>

An important number of cases were available in the TOP dataset, permitting replacing invalid ages with the right information. Must note that `r edad_adolescentes_17` cases had around 17 years of the `r edad_adolescentes_menores_18` cases that were not adults at the time of TOP.  The next table presents those HASHs that had other registries with a valid age.

<br>

```{r tab6_wrong ages duplicates, echo=T,cache=T, paged.print=TRUE}
#list of distinct HASHs that have a wrongly assigned age
CONS_TOP_df_dup_ENE_2020_prev1 %>% 
    dplyr::mutate(Edad_at_ap=lubridate::time_length(difftime(as.Date(fech_ap_top), as.Date(fech_nac)),"years")) %>% #AGREGADO EN APR 2020.
  dplyr::mutate(Edad_at_ap=replace(Edad_at_ap, is.na(fech_nac), NA)) %>% #AGREGADO EN APR 2020.
  #dplyr::filter(Edad<18|Edad>90) %>%
  dplyr::filter(Edad_at_ap>=18,Edad_at_ap<=90) %>%
  #dplyr::filter(Edad<18|Edad>90) %>%
#  dplyr::mutate(Edad_al_ing=round(Edad_al_ing,2))%>%
#  dplyr::filter(Edad<18|Edad>90) %>%
   dplyr::select(HASH_KEY,fech_ap_top, Edad_at_ap) %>%
  dplyr::group_by(HASH_KEY,fech_ap_top) %>% 
  mutate(rn = row_number()) %>%
  dplyr::ungroup()%>%
  assign("distinct_hash_correct_age_adm_top",., envir = .GlobalEnv)
#dim(distinct_hash_wrong_age2_adm_top) #288 casos

dates_replace_invalid_value <- CONS_TOP_df_dup_ENE_2020_prev1 %>%
      dplyr::mutate(Edad_at_ap=lubridate::time_length(difftime(as.Date(fech_ap_top), as.Date(fech_nac)),"years")) %>% #AGREGADO EN APR 2020.
      dplyr::mutate(Edad_at_ap=replace(Edad_at_ap, is.na(fech_nac), NA)) %>% #AGREGADO EN APR 2020.
          #dplyr::filter(Edad<18|Edad>90) %>%
      dplyr::group_by(HASH_KEY,Edad_at_ap) %>% 
      dplyr::mutate(rn = row_number()) %>%
      dplyr::ungroup()%>%
      dplyr::left_join(distinct_hash_correct_age_adm_top, by=c("HASH_KEY", "fech_ap_top","rn"), suffix=c("",".corr_age_adm_top")) %>% #mantiene la misma cantidad de filas
      dplyr::arrange(HASH_KEY) %>% #order by hashs 
      #dplyr::filter(Edad<18|Edad>90) %>%
        dplyr::filter(Edad_at_ap<18|Edad_at_ap>90) %>%
        dplyr::filter(!is.na(Edad_at_ap.corr_age_adm_top)) %>% nrow()

#Then, apply these cases to the whole population
CONS_TOP_df_dup_ENE_2020_prev1 %>%
dplyr::mutate(Edad_at_ap=lubridate::time_length(difftime(as.Date(fech_ap_top), as.Date(fech_nac)),"years")) %>% #AGREGADO EN APR 2020.
dplyr::mutate(Edad_at_ap=replace(Edad_at_ap, is.na(fech_nac), NA)) %>% #AGREGADO EN APR 2020.
    #dplyr::filter(Edad<18|Edad>90) %>%
dplyr::group_by(HASH_KEY,Edad_at_ap) %>% 
dplyr::mutate(rn = row_number()) %>%
dplyr::ungroup()%>%
dplyr::left_join(distinct_hash_correct_age_adm_top, by=c("HASH_KEY", "fech_ap_top","rn"), suffix=c("",".corr_age_adm_top")) %>% #mantiene la misma cantidad de filas
dplyr::arrange(HASH_KEY) %>% #order by hashs 
#dplyr::filter(Edad<18|Edad>90) %>%
  dplyr::filter(Edad_at_ap<18|Edad_at_ap>90) %>%
  dplyr::filter(!is.na(Edad_at_ap.corr_age_adm_top)) %>% #nrow() # sólo 1 caso.
  dplyr::select(row, ano_bd, HASH_KEY, id_mod, fech_nac, ano_bd,Edad, Edad_at_ap,Edad_at_ap.corr_age_adm_top,fech_ing, fech_ap_top, everything()) %>%
  dplyr::select(-ID) %>%
 knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 6. Total cases with wrong ages at the time of admission, but their HASH had a valid age along the dataset",
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::scroll_box(width = "100%", height = "150px")
```

<br>

As seen in Table 6, only `r dates_replace_invalid_value` `r ifelse(dates_replace_invalid_value>1,"values","value")` could be replaced. We replaced SENDA ID, age, ID and date of birth `r ifelse(dates_replace_invalid_value>1,"to those cases","to this case")`, to get a much cleaner dataset of valid cases. 

<div class = "blue">
**One observation that comes from these transformations, is that many of TOPs applications that had missing values in one value, had missing values in many others more. Possibly, there were duplicated events, and some of them were invalid. If this is true, we only need to discard events with incomplete data instead of replacing them with valid information. But first, we need to check whether this happens frequently or not. This has to be contrasted in the following stages of data preparation**.
</div>

<br>

```{r guardar3_edad_save, cache=T}
#PARA OBTENER LAS EDADES DE APLICACION VALIDAS POR FECHA DE APLICACION DEL TOP
CONS_TOP_df_dup_ENE_2020_prev1 %>% 
    dplyr::mutate(Edad_at_ap=lubridate::time_length(difftime(as.Date(fech_ap_top), as.Date(fech_nac)),"years")) %>% #AGREGADO EN APR 2020.
  dplyr::mutate(Edad_at_ap=replace(Edad_at_ap, is.na(fech_nac), NA)) %>% #AGREGADO EN APR 2020.
  #dplyr::filter(Edad<18|Edad>90) %>%
  dplyr::filter(Edad_at_ap>=18,Edad_at_ap<=90) %>%
  #dplyr::filter(Edad<18|Edad>90) %>%
#  dplyr::mutate(Edad_al_ing=round(Edad_al_ing,2))%>%
#  dplyr::filter(Edad<18|Edad>90) %>%
   #dplyr::select(HASH_KEY,fech_ap_top, Edad_at_ap) %>%
  dplyr::group_by(HASH_KEY,fech_ap_top) %>% 
  mutate(rn = row_number()) %>%
  dplyr::ungroup()%>%
  assign("distinct_hash_correct_age_adm_top2",., envir = .GlobalEnv)
#dim(distinct_hash_wrong_age2_adm_top) #288 casos

CONS_TOP_df_dup_ENE_2020_prev1 %>%
      dplyr::mutate(Edad_at_ap=lubridate::time_length(difftime(as.Date(fech_ap_top), as.Date(fech_nac)),"years")) %>% #AGREGADO EN APR 2020.
      dplyr::mutate(Edad_at_ap=replace(Edad_at_ap, is.na(fech_nac), NA)) %>% #AGREGADO EN APR 2020.
          #dplyr::filter(Edad<18|Edad>90) %>%
      dplyr::group_by(HASH_KEY,Edad_at_ap) %>% 
      dplyr::mutate(rn = row_number()) %>%
      dplyr::ungroup()%>%
      dplyr::left_join(distinct_hash_correct_age_adm_top2, by=c("HASH_KEY", "fech_ap_top","rn"), suffix=c("",".corr_age_adm_top")) %>% 
#Join datasets 
    dplyr::mutate(OBS=case_when((Edad_at_ap<18 & !is.na(Edad_at_ap.corr_age_adm_top))|(Edad_at_ap>90 & !is.na(Edad_at_ap.corr_age_adm_top))~glue::glue("{OBS};1.3.Replaced invalid age at TOP application"),
                                TRUE ~ OBS))%>% 
    dplyr::mutate(OBS=case_when(Edad_at_ap<18|Edad_at_ap>90~glue::glue("{OBS};1.3.Invalid Age at the Time of Application of TOP"),
                                TRUE ~ OBS))%>% 
    dplyr::mutate(ID= ifelse((Edad_at_ap<18 & !is.na(Edad_at_ap.corr_age_adm_top))|(Edad_at_ap>90 & !is.na(Edad_at_ap.corr_age_adm_top)),ID.corr_age_adm_top, ID)) %>%
    dplyr::mutate(id_mod=ifelse((Edad_at_ap<18 & !is.na(Edad_at_ap.corr_age_adm_top))|(Edad_at_ap>90 & !is.na(Edad_at_ap.corr_age_adm_top)),id_mod.corr_age_adm_top,id_mod)) %>% 
    dplyr::mutate(fech_nac=ifelse((Edad_at_ap<18 & !is.na(Edad_at_ap.corr_age_adm_top))|(Edad_at_ap>90 & !is.na(Edad_at_ap.corr_age_adm_top)),fech_nac.corr_age_adm_top,fech_nac))%>%
    dplyr::mutate(Edad=ifelse((Edad_at_ap<18 & !is.na(Edad_at_ap.corr_age_adm_top))|(Edad_at_ap>90 & !is.na(Edad_at_ap.corr_age_adm_top)),Edad.corr_age_adm_top,Edad))%>%      
    dplyr::mutate(fech_nac=as.Date(fech_nac)) %>%
    dplyr::mutate(Edad_at_ap=lubridate::time_length(difftime(as.Date(fech_ap_top), as.Date(fech_nac)),"years")) %>% #AGREGADO EN APR 2020.
    dplyr::mutate(Edad_at_ap=replace(Edad_at_ap, is.na(fech_nac), NA)) %>% #AGREGADO EN APR 2020.
    dplyr::select(-ends_with(".corr_age_adm_top")) %>%
    dplyr::select(-rn,-TABLE,-fech_ing_na, -row_leftjoin, -fech_ing_C1) %>%


##un resumen   
     #dplyr::group_by(Edad) %>% summarise(n=n())  #baja de 273 a 227
#PARA REVISAR
#      dplyr::filter(HASH_KEY %in% as.character(as.vector(unlist(as.data.table(unlist(distinct_hash_wrong_age2_top)))))) %>% # select hashs of wrongly assigned ages. Hay               algunos que no los va a encontrar porque no los tiene, no mas
#        dplyr::select(HASH_KEY, Edad, fech_nac, Edad.y, fech_nac.y, fech_ing, ID, id_mod, ID.y, Edad_al_ing) %>%
#        arrange(HASH_KEY) %>%
#           View() 
#dplyr::select(-id_mod.y, -ID.y, -Edad.y, -fech_nac.y) %>% 
assign("CONS_TOP_df_dup_ENE_2020_prev2",., envir = .GlobalEnv) 
#POR QUÉ ESTE CASO NO QUEDO INCORPORADO  
  #CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::filter(!is.na(fech_ing), !is.na(Edad),is.na(Edad_al_ing)) %>% View()
  #CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::filter(!is.na(fech_ing), !is.na(Edad),is.na(Edad_al_ing)) %>% 
  #dplyr::select(HASH_KEY, id_mod, Fecha.Aplicación, fech_ing, fech_nac, Edad, Edad_al_ing)
```

```{r guardar3_edad_save_correction, cache=T, eval=F}
#EL CASO QUEDÓ PERDIDO EN ESTA TRANSFORMACIÓN. INVESTIGAR POR QUÉ, PERO POR MIENTRAS RESOLVERLO MANUALMENTE.
#POR QUÉ ESTE CASO NO QUEDO INCORPORADO  
  #CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::filter(!is.na(fech_ing), !is.na(Edad),is.na(Edad_al_ing)) %>% View()
#CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::filter(!is.na(fech_ing), !is.na(Edad),is.na(Edad_al_ing)) %>% 
#    dplyr::select(HASH_KEY, id_mod, Fecha.Nacimiento, fech_ing, fech_nac, Edad, Edad_al_ing)
#CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::filter(HASH_KEY=="ee0360d19dd5f300526c624c58090c79") %>% 
#    dplyr::select(HASH_KEY, id_mod, Fecha.Nacimiento, fech_ing, fech_nac, Edad, Edad_al_ing)

CONS_TOP_df_dup_ENE_2020_prev2 %>% 
dplyr::select(-TABLE,-fech_ing_na, -row_leftjoin, -fech_ing_C1) %>%
  as.data.frame() %>%
#    dplyr::mutate(Edad_al_ing=lubridate::time_length(difftime(as.Date(fech_ing), as.Date(fech_nac)))/(3*60*60)) %>%
#    dplyr::mutate(Edad_al_ing=replace(Edad_al_ing, is.na(Edad), NA)) %>%
#    dplyr::mutate(fech_nac=ifelse(HASH_KEY=="ee0360d19dd5f300526c624c58090c79",lubridate::as_datetime("1942-08-02"), fech_nac)) %>%
#  dplyr::mutate(fech_nac=as.Date(as.numeric(as.Date(lubridate::ymd(as.character(fech_nac)))))) %>%
#  dplyr::mutate(fech_nac=ifelse(HASH_KEY=="ee0360d19dd5f300526c624c58090c79",lubridate::ymd("1942-08-02"), #lubridate::ymd(as.character(fech_nac)))) %>%
#  dplyr::mutate(fech_nac=as.Date(fech_nac)) %>%
#  dplyr::mutate(Edad_al_ing=ifelse(HASH_KEY=="ee0360d19dd5f300526c624c58090c79",lubridate::time_length(difftime(as.Date(fech_ing), as.Date(fech_nac)),"years"), Edad_al_ing)) %>%
#    dplyr::filter(HASH_KEY=="ee0360d19dd5f300526c624c58090c79"|HASH_KEY=="153b828278ea88dc5ab15039e3e0c882"	) %>%  #para ver cómo se comporta.
#   dplyr::select(HASH_KEY, id_mod, Fecha.Nacimiento, fech_ing, fech_nac, Edad, Edad_al_ing) %>% View()
assign("CONS_TOP_df_dup_ENE_2020_prev2.2",., envir = .GlobalEnv) 
```

### 3. Inconsistencies between SENDA ID and HASH Key

```{r inconsistencies_in_id_inconsistent_hashs, cache=T,eval=T}
    #Take which has a combination of IDs and HASH Keys distinct to the rest
    #With this I may be subestimating the number of cases with a different concatenation.
    #Considering all the distinct combinations, i take what they have a duplicate ID
    #Select the duplicate IDs, it orders and...
    #Filter only cases that has distinct id.
    CONS_TOP_df_dup_ENE_2020_prev2 %>% dplyr::mutate(concat=paste0(ID,"_",HASH_KEY)) %>% 
    dplyr::distinct(concat, .keep_all = TRUE) %>% 
      dplyr::filter(duplicated(ID)) %>% #filter cases that have than one 
  dplyr::arrange(ID) %>%  #filter cases in which there is more than one ID, 
      #despite there is differents combinations of HASH and IDs, and then arrange IDs. This is possible only if a different HASH-Key contains more than one ID or viceversa.
      #take distincts IDs (exclude duplicated repeated IDs)
      dplyr::distinct(ID) %>% 
      assign("ids_more_one_hash_TOP",., envir = .GlobalEnv) # Differently put, take the distints IDs per HASH-Key, of the cases in which there are different combinations                                                      
    # of IDs and hash, and in which subgroup exists duplicated IDs.
    #There are 33 IDs that have more than one HASH key.
    #IMPORTANT: IF THE ID IS DUPLICATED, MIGHT NOT BE REFLECTED IN THIS RESUME IN TERMS OF QUANTITY.
```

The official individual IDs (RUN) were masked into HASH keys by an informatics professional (For more information about this process, visit the [encryption phase](https://fondecytacc.github.io/SUD_health_Chile.github.io/Encript.html)). We checked whether they were consistent with each SENDA ID and did not depend on other factors in their identification (eg., individual ID was not well processed), by searching for more than one HASH Key in each SENDA ID. `r nrow(ids_more_one_hash_TOP)` IDs that had more than one HASH key. These `r nrow(ids_more_one_hash_TOP)` IDs affected 183 registries.

<br>

```{r tab7_inconsistencies_in_id}
    # Then, apply these cases to the whole population. 
    CONS_TOP_df_dup_ENE_2020_prev2 %>%
      dplyr::filter(ID %in% as.character(as.vector(unlist(as.data.table(unlist(ids_more_one_hash_TOP)))))) %>% # Select IDs of cited cases
      dplyr::arrange(ID) %>% #ordeno por ids 
      #183 cases may be affected with this problem
      dplyr::select(row, ano_bd, id_mod, HASH_KEY, hash_rut_completo , Edad, Sexo,fech_ing,Plan.de.Tratamiento, Nombre.del.Centro, Tipo.Centro, Región.Centro, Comentario) %>%
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 7. Total registries that each ID have more than one HASH-KEY",
              col.names = c("Row ID","Year of Dataset", "SENDA ID", "HASH KEY", "HASH Key (Alternative)","Year", "Sex", "Date of Admission", "Treatment Plan", "Center", "Type of Center", "Region", "Comment"),
                 align =rep('c', 6))  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
            scroll_box(width = "100%", height = "350px")
```
    
```{r gen more_one_hash_per_id_enviado_Senda_prof, echo=T, paged.print=TRUE}
    CONS_TOP_df_dup_ENE_2020_prev2 %>%
      dplyr::filter(ID %in% as.character(as.vector(unlist(as.data.table(unlist(ids_more_one_hash_TOP)))))) %>% # Select IDs of cited cases
      dplyr::arrange(ID) %>% #ordeno por ids 
      dplyr::group_by(ID) %>%
      dplyr::distinct(HASH_KEY) %>%
      #183 cases may be affected with this problem
      write.csv2(file =paste0(path, "/Maureen/_8.mismo_ID_mas_de_un_HASH_TOP.csv"))
##33 casos con 66 hashs distintos.
#aCTUALIZACIÓN: estos coinciden con los que consulté por C1. No es necesario volverlos a preguntar.
```

**These inconsistent HASHs have been sent to SENDA professional, who made clear that these cases (every one of them also present in the C1 dataset) corresponded to users with different RUNs, so their HASHs should be different**.

<br>

### 4. Define criteria to classify duplicated cases

<br>
To define what can be considered a unique event, we identified how many unique combinations of admission dates and HASH keys. We found that only `r prop.table(table(duplicated(CONS_TOP_df_dup_ENE_2020_prev2[,c("HASH_KEY","fech_ing")])))[1] %>% round(3)*100` percent of the registries are unique combinations. Attending the the questionnaires' characteristics, it is possible to explore more specific time units (See Table 8).

<br>


```{r tab8_Duplicated}
#create the duplicated dataset, following the recommendation to separate columns
    as.data.table(CONS_TOP_df_dup_ENE_2020_prev2)[, dup_hash_date_adm_top := .N, by = c("HASH_KEY","fech_ing")] %>% ##dim()
      dplyr::group_by(dup_hash_date_adm_top) %>%
      dplyr::summarise(n=n()) %>%
      mutate(perc = round(n / sum(n),2)*100) %>%
      mutate(perc = paste0(perc,"%")) %>%
      dplyr::mutate(unique_cases= formatC(n/dup_hash_date_adm_top, format="f", big.mark=",", digits=0)) %>%
      as.data.frame(.) %>%
    # Duplicated rows
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 8. Frequency and Percentage of Duplicated Values of the combination of HASH-Key & Date of Admission", 
                   col.names= c("Times present in Dataset", " Frequencies", "Percentage", "Unique Cases"),  align =rep('c', 2))  %>%
      kable_styling(bootstrap_options = c("striped", "hover"),font_size = 11) %>%
  scroll_box(width = "100%", height = "350px")
```

<br>

```{r tab9_Duplicated2}
    duplicated_rows_concat_TOP2 <- data.frame(duplicated_HASH_date = duplicated(CONS_TOP_df_dup_ENE_2020_prev2[,c("HASH_KEY","fech_ap_top")]), 
                                         row_dup_HASH_date = 1:nrow(CONS_TOP_df_dup_ENE_2020_prev2[,c("HASH_KEY","fech_ap_top")])) #%>%
    as.data.table(CONS_TOP_df_dup_ENE_2020_prev2)[, dup_hash_date_ap := .N, by = c("HASH_KEY","fech_ap_top")] %>% ##dim()
      dplyr::group_by(dup_hash_date_ap) %>%
      dplyr::summarise(n=n()) %>%
      mutate(perc = round(n / sum(n),3)*100) %>%
      mutate(perc = paste0(perc,"%")) %>%
      dplyr::mutate(unique_cases= formatC(n/dup_hash_date_ap, format="f", big.mark=",", digits=0)) %>%
      as.data.frame(.) %>%
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 9. Frequency and Percentage of Duplicated Values of the combination of HASH-Key & Date of Application of TOP", 
                   col.names= c("Times present in Dataset", " Frequencies", "Percentage", "Unique Cases"),  align =rep('c', 2))  %>%
      kable_styling(bootstrap_options = c("striped", "hover"),font_size = 11) %>%
  scroll_box(width = "100%", height = "350px")
```
<br>

One of them is the date of application of the TOP questionnaire. As shown in Table 9, `r prop.table(table(duplicated(CONS_TOP_df_dup_ENE_2020_prev2[,c("HASH_KEY","fech_ap_top")])))[1] %>% round(3)*100`% of the registries are unique combinations of the date of application of the TOP questionnaire and HASH key.

<br>

```{r tab10_Duplicated2.2}
as.data.table(CONS_TOP_df_dup_ENE_2020_prev2)[, dup_hash_date_ap := .N, by = c("HASH_KEY","fech_ap_top")] %>%
  dplyr::filter(dup_hash_date_ap>1) %>% #Aquí veo quienes aparecen más de una vez
  dplyr::arrange(HASH_KEY,fech_ap_top) %>% 
  dplyr::slice(2000:2200) %>%
dplyr::select(-ID) %>%
  #  dplyr::select(HASH_KEY, hash_rut_completo, id_mod, ano_bd, fech_ap_top, TOP,fech_nac, Edad, Sexo, Plan.de.Tratamiento, Nombre.del.Centro, #Sustancia.Principal.1, Sustancia.Principal.2, Sustancia.Principal.3, starts_with("Total"),starts_with("Dósis")) %>%
      knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 10. Sample of Duplicated rows of the combination of HASH-Key & Date of Application of TOP", 
                   #col.names= c("Duplicated", " Frequencies", "Percentage"),
                   align =rep('c', 102))  %>%
      kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  scroll_box(width = "100%", height = "350px")
```
<br>

As can be seen in Table 10, in some cases the only thing that varies is the stage of treatment ot the TOP variable; in others also varies the qualitative observations or "comments" section; and in very few, there are changes in variables relative to the content of the evaluation. **Can a single combination of the date of application and HASH have different dates of admission?**

### 5. Deletion of nearly exact duplicated cases

<br>

We needed to reduce the number of cases, but in the meantime, reduce the loss of information due to specific changes in each entry. That is why we selected almost every variable to detect duplicated cases, excepting the following:

- SENDA ID (ID): The HASH Key identifier was the one recommended by SENDA Professionals.
- SENDA ID (masked characters 5 & 6) (id_mod): The HASH Key identifier was the one recommended by SENDA Professionals.
- Year of the Dataset (Source) (ano_bd) (TABLE): Let us detect cases that repeat among different yearly datasets.
- Events in the Dataset/ Row Number (row): We excluded this identifier because it is a unique number of each event that we arbitrarily generated.
- Name of the TOP Interviewer (Nombre.Apliacador.del.TOP): Identify each interviewer is not relevant for characterizing each user and their transitions at this stage.
- Observations (OBS): This variable was created in the context of the study, to include part of the process of standardization of the dataset. Not relevant to characterize each user and their transitions.
- Age at the Time of Admission (Edad_al_ing): Not included because it depends mainly on already present variables (Date of Birth and Date of Admission)
- Age at the Time of Application (Edad_at_ap): Not included because it depends mainly on already present variables (Date of Birth and Date of Application of TOP)

<br>

```{r tab11_deduplication1, echo=T, cache=T, paged.print=TRUE}
#create vector with variable names
#names_top <- names(CONS_TOP_df_dup_ENE_2020_prev2[,-c("id_mod","ano_bd","row","TABLE","Nombre.Apliacador.del.TOP")])
names_top <-names(subset(CONS_TOP_df_dup_ENE_2020_prev2, select = -c(ID,id_mod, ano_bd, row, Nombre.Apliacador.del.TOP, OBS, Edad_al_ing, Edad_at_ap)))
#Group by duplicated rows 
as.data.table(CONS_TOP_df_dup_ENE_2020_prev2)[, dup_todo_TOP := .N, by = names_top] %>%
dplyr::mutate(OBS=case_when(dup_todo_TOP>1~glue::glue("{OBS};1.4.Had a duplicated events with almost every variable in common"),
                            TRUE~OBS))%>% 
  data.table::as.data.table() %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev3",.,envir = .GlobalEnv)
#summarise duplicates and times
as.data.table(CONS_TOP_df_dup_ENE_2020_prev3)[, dup_todo_TOP := .N, by = names_top] %>%
  dplyr::group_by(dup_todo_TOP) %>%
  dplyr::summarise(n=n()) %>%
  mutate(perc = round(n / sum(n),3)*100) %>%
  mutate(perc = paste0(perc,"%")) %>%
  dplyr::mutate(unique_cases= formatC(n/dup_todo_TOP, format="f", big.mark=",", digits=0)) %>%
  data.frame() %>% 
  dplyr::rename("Times present in Dataset"=dup_todo_TOP, "Number of Rows"=`n`, "%"=perc, "Unique Cases"=unique_cases) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 11. Duplicated cases in almost every variable",
                 align ="cccc")  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10)
```

```{r guardar4_dataset_creation, echo=T, paged.print=TRUE, cache=T, warning=F}
data.table::data.table(CONS_TOP_df_dup_ENE_2020_prev3) %>%
  dplyr::arrange(desc(ano_bd)) %>%
  dplyr::distinct_at(.vars=names_top, .keep_all = TRUE) %>%
  dplyr::arrange(HASH_KEY, fech_ing, fech_ap_top, desc(ano_bd)) %>%
  data.table::as.data.table() %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev4",.,envir = .GlobalEnv)
#Unlike base sorting with sort(), NA are: always sorted to the end for local data, even when wrapped with desc().
```

&nbsp;
<br>

As seen in Table 11, not many cases were dropped, which can be interpreted as different information regarding users and specific treatments in each of the remaining `r nrow(CONS_TOP_df_dup_ENE_2020_prev4) %>% formatC(., format="f", big.mark=",", digits=0)` rows, in at least one of the 42 selected variables. 

<br>

We must consider that this dataset is focused on the contents of the treatment outcomes profile. Additionally, in Table 10, we observed that **many entries with the same dates of application and HASH had nearly the same values in variables of each application**, we excluded variables related to the source of information provided (e.g., it comes from one yearly or another, and the name of the interviewer), among others not relevant for the study. The variables related to the stage of treatment (TOP or Etapa.del.Tratamiento) were not considered, because in many cases, registries with the same date of application were categorized with different stages. Even some variables relative to the characteristics of the center were omitted (such as the region of the center or "Región.Centro" and their name "Nombre.Centro").

<br>

The following variables were used as a criterion to estimate duplicated rows in the dataset, meaning that any lost information by the deduplication would not correspond to a loss of information related to the questionnaire itself.

* Masked Identifier (RUN) (HASH_KEY)
* Type of Center (Tipo.Centro)
* Primary Substance of Consumption (1) (Sustancia.Principal.1)
* Primary Substance of Consumption (2) (Sustancia.Principal.2)
* Primary Substance of Consumption (3) Sustancia.Principal.3)
* Total Alcohol (Total.OH)
* Dose of Alcohol (Dósis.OH)
* Total Marijuana (Total.THC)
* Dose of Marijuana (Dósis.THC)
* Total Cocaine Paste Base (Total.PBC)
* Amount of Cocaine Paste Base (Dósis.PBC)
* Total Snort Cocaine (Total.COC)
* Dose of Snort Cocaine (Dósis.COC)
* Total Sedatives and Tranquillizers (Total.BZD)
* Dose of Sedatives and Tranquillizers (Dósis.BZD)
* Total Other Substances (Total.Otra)
* Dose of Other Substances (Dósis.Otra)
* Theft (Hurto)
* Robbery (Robo)
* Drug selling (Venta.Drogas)
* Fights (Riña)
* Total Domestic Violence (Total.VIF)
* Another Action (Otro)
* Total Behavior that transgresses social norms (Total.Transgresión)
* Psychological Health (Salud.Psicológica)
* Total of Paid Work (Total.Trabajo)
* Total College or school (Total.Educación)
* Total Physical Health (Salud.Física)
* Stable Place to Live (Lugar.Vivir)
* Housing conditions (Vivienda)
* Total Quality of Life (QoL) (Calidad.Vida)
* Date of Admission to Treatment (fech_ing)
* Date of Application of TOP (fech_ap_top)


```{r tab12_deduplication2, echo=T, cache=T, paged.print=TRUE}
#create vector with variable names
names_top2 <- c('HASH_KEY', 'Tipo.Centro', 'Sustancia.Principal.1', 'Sustancia.Principal.2', 'Sustancia.Principal.3', 'Total.OH', 'Dósis.OH', 'Total.THC', 'Dósis.THC', 'Total.PBC', 'Dósis.PBC', 'Total.COC', 'Dósis.COC', 'Total.BZD', 'Dósis.BZD', 'Total.Otra', 'Dósis.Otra', 'Hurto', 'Robo', 'Venta.Drogas', 'Riña', 'Total.VIF', 'Otro', 'Total.Transgresión', 'Salud.Psicológica', 'Total.Trabajo', 'Total.Educación', 'Salud.Física', 'Lugar.Vivir', 'Vivienda', 'Calidad.Vida', 'fech_ing', 'fech_ap_top')
#Group by duplicated rows 
as.data.table(CONS_TOP_df_dup_ENE_2020_prev4)[, dup_contents_TOP := .N, by = names_top2] %>%
  dplyr::mutate(OBS=case_when(dup_contents_TOP>1~glue::glue("{OBS};1.5.Had a duplicated event with relevant variables in common"),
                              TRUE~OBS))%>% 
  data.table::as.data.table() %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev5",.,envir = .GlobalEnv)
#summarise duplicates and times
as.data.table(CONS_TOP_df_dup_ENE_2020_prev5)[, dup_contents_TOP := .N, by = names_top2] %>%
  dplyr::group_by(dup_contents_TOP) %>%
  dplyr::summarise(n=n()) %>%
  mutate(perc = round(n / sum(n),3)*100) %>%
  mutate(perc = paste0(perc,"%")) %>%
  dplyr::mutate(unique_cases= formatC(n/dup_contents_TOP, format="f", big.mark=",", digits=0)) %>%
  data.frame() %>%
  dplyr::rename("Times present in Dataset"=dup_contents_TOP, "Number of Rows"=`n`, "%"=perc, "Unique Cases"=unique_cases) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 12. Duplicated cases in variables related to the content of TOPs",
                 align ="cccc")  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10)
```

```{r guardar6_dataset_creation2, echo=T, paged.print=TRUE, cache=T, warning=F}
data.table::data.table(CONS_TOP_df_dup_ENE_2020_prev5) %>%
  dplyr::arrange(desc(ano_bd)) %>%
  dplyr::distinct_at(.vars=names_top2, .keep_all = TRUE) %>%
  dplyr::arrange(HASH_KEY, fech_ing, fech_ap_top, desc(ano_bd)) %>%
  data.table::as.data.table() %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev6",.,envir = .GlobalEnv)
#Unlike base sorting with sort(), NA are: always sorted to the end for local data, even when wrapped with desc().
```

<br>

What happens if a case have the same date of application, but a different date of admission?. Is it possible that a user could be interviewed in the same date for different treatments? We should consider these inconsistencies in order to provide valid cases. There are around `r CONS_TOP_df_dup_ENE_2020_prev6 %>%   dplyr::mutate(concatenation_hash_date_ing_date_adm=paste0(HASH_KEY, fech_ing, fech_ap_top)) %>% dplyr::distinct(concatenation_hash_date_ing_date_adm, .keep_all = TRUE) %>% dplyr::mutate(concatenation_hash_date_ap_top=paste0(HASH_KEY, fech_ap_top)) %>% dplyr::filter(duplicated(concatenation_hash_date_ap_top)) %>% nrow() ` users with the same dates of application but different date of admission. **We sent these cases to SENDA professionals in order to discard any error**.

```{r tab13_diff_dates_of_application, echo=T, paged.print=TRUE, cache=T, warning=F}
CONS_TOP_df_dup_ENE_2020_prev6 %>% 
  dplyr::mutate(concatenation_hash_date_ing_date_adm=paste0(HASH_KEY, fech_ing, fech_ap_top)) %>% 
  dplyr::distinct(concatenation_hash_date_ing_date_adm, .keep_all = TRUE) %>% #descartar todas las combinaciones de filas con la misma fecha de todo y el mismo HASH.
  dplyr::mutate(concatenation_hash_date_ap_top=paste0(HASH_KEY, fech_ap_top)) %>% 
  dplyr::filter(duplicated(concatenation_hash_date_ap_top)) %>% #dejo a los que tienen duplicados la fecha de aplicación y el hash, ya que la tercera variable, en este caso, la fecha de ingreso es distinta.
      dplyr::arrange(concatenation_hash_date_ap_top) %>%  
      dplyr::select(HASH_KEY,fech_ing, fech_ap_top,concatenation_hash_date_ap_top) %>% 
  dplyr::inner_join(CONS_TOP_df_dup_ENE_2020_prev6, by=c("HASH_KEY", "fech_ap_top")) %>% #
  dplyr::select(-concatenation_hash_date_ap_top, -ID, -fech_ing.x) %>%
  dplyr::select(HASH_KEY, fech_ap_top, fech_ing.y,id_mod, ano_bd, TOP, Etapa.del.Tratamiento,everything()) %>%
  dplyr::rename("HASH Key"=HASH_KEY, "Date of\nAdmission"=fech_ing.y, "Date of\nApplication"=fech_ap_top, "ID"=id_mod, "Stage of\n Treatment"=Etapa.del.Tratamiento) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 13. Same date of the application of TOP, but different dates of Admission",
                 align =rep("c",58))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  scroll_box(width = "100%", height = "350px")
```

```{r gen more_one_date_admission_per_app_date_and_hash_env_prof_senda, echo=T, paged.print=TRUE}
    CONS_TOP_df_dup_ENE_2020_prev6 %>% 
    dplyr::filter(!is.na(fech_ing)) %>%
    dplyr::mutate(concatenation_hash_date_ing_date_adm=paste0(HASH_KEY, fech_ing, fech_ap_top)) %>% 
    dplyr::distinct(concatenation_hash_date_ing_date_adm, .keep_all = TRUE) %>% #descartar todas las combinaciones de filas con la misma fecha de todo y el mismo HASH.
    dplyr::mutate(concatenation_hash_date_ap_top=paste0(HASH_KEY, fech_ap_top)) %>% 
    dplyr::filter(duplicated(concatenation_hash_date_ap_top)) %>% #dejo a los que tienen duplicados la fecha de aplicación y el hash, ya que la tercera variable, en este caso, la fecha de ingreso es distinta.
    dplyr::arrange(concatenation_hash_date_ap_top) %>%  
    dplyr::select(HASH_KEY,fech_ing, fech_ap_top,concatenation_hash_date_ap_top) %>% 
    dplyr::inner_join(CONS_TOP_df_dup_ENE_2020_prev6, by=c("HASH_KEY", "fech_ap_top")) %>% #
    dplyr::select(ID,HASH_KEY, fech_ap_top, fech_ing.y,id_mod, ano_bd, TOP, Etapa.del.Tratamiento,everything()) %>%
    dplyr::group_by(concatenation_hash_date_ap_top) %>%
    dplyr::filter(!duplicated(fech_ing.y)) %>%
      #134 cases may be affected with this problem, 67 concatenations of hash date and ap top.
      write.csv2(file =paste0(path,"/Maureen/_9.mismo_HASH_y_fecha_de_aplicacion_TOP_mas_de_una_fecha_de_ingreso.csv"))
```   

<br>

Considering these cases are still being cleared, we would only consider as our key date the date of application only.

<br>

```{r generate_data_in_csv_to_stata, echo=T, paged.print=TRUE}
CONS_TOP_df_dup_ENE_2020_prev6 %>%
    dplyr::rename("dosisoh"=`Dósis.OH`, "dosisthc"=`Dósis.THC`, "dosispbc"=`Dósis.PBC`, "dosiscoc"=`Dósis.COC`, "dosisbzd"=`Dósis.BZD`, "dosisotra"=`Dósis.Otra`,"rina"=`Riña`, "totaltransgresion"=`Total.Transgresión`, "saludpsicologica"=`Salud.Psicológica`, "totaleducacion"=`Total.Educación`, "saludfisica"=`Salud.Física`) %>%
  as.data.frame() %>%
  write.csv2(., file ="CONS_TOP_df_dup_ENE_2020.csv")
```

<br>

### 6. TOPs in C1


```{r tab14_deduplication3, echo=T, cache=T, paged.print=TRUE,warning=F}
CONS_C1_df_dup_ENE_2020_unique_HASH_date<- dplyr::select(CONS_C1_df_dup_ENE_2020, hash_key, fech_ing) %>% dplyr::mutate(fech_ing= as.Date(as.character(fech_ing))) %>% group_by(hash_key, fech_ing) %>% dplyr::mutate(row_first=row_number()) %>% ungroup() %>% dplyr::filter(row_first==1) 

n_cases_hash1<-dplyr::left_join(CONS_TOP_df_dup_ENE_2020_prev6,CONS_C1_df_dup_ENE_2020_unique_HASH_date, by= c("HASH_KEY"="hash_key", "fech_ing")) %>% dplyr::filter(is.na(row_first)) %>% nrow()
n_cases_hash2<-dplyr::left_join(CONS_TOP_df_dup_ENE_2020_prev6,CONS_C1_df_dup_ENE_2020_unique_HASH_date, by= c("HASH_KEY"="hash_key", "fech_ing")) %>% dplyr::filter(is.na(row_first)) %>% distinct(HASH_KEY) %>% nrow()


dplyr::left_join(CONS_TOP_df_dup_ENE_2020_prev6,CONS_C1_df_dup_ENE_2020_unique_HASH_date, by= c("HASH_KEY"="hash_key", "fech_ing")) %>% dplyr::filter(is.na(row_first)) %>% group_by(is.na(fech_ing)) %>% summarise(n=n()) %>%
  data.frame() %>% 
  dplyr::rename("Missing Data in\n Date of Admission"=is.na.fech_ing., "Number of Rows"=`n`) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 14. Cases product of the combination of HASHs and dates of admission that are not present in C1 Dataset",
                 align ="cccc")  %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10)
```

As seen in Table 14, a small fraction of the combination of dates and HASHs was not present in C1 Dataset. Many of them due to missing variables in the date of admission. There are `r n_cases_hash1` cases of `r n_cases_hash2` distinct HASHs that were not included in the C1 dataset.

<br>

### 7. Probabilistic Deduplication

In order to catch some differences that would probabilistically match in terms of HASH-Key and date of admission, we ran data into a package in the software Stata called **`dtalink`**, with the following criteria:

1. Hash Key, with a weight applied of 125 points, in case this variable match, but minus 125 in case that does not match
2. Date of TOP Application will add 125 points with the same condition, and with a calliper of 5 days.
3. Type of center (if it is private or public) it was weighted with 5 points if matchs (1.25%), and minus 5 points if it does not.
4. For the variables related to the evaluation contents, each one was weighted with 5 points (1.25%) and minus 5 points, with a total weight of 145 (or 36.25%).
5. We used the age as blocks, to reduce computation time and match each cases within people of the same age
6. Matches will be considered worthy of analysis with 280 or more points (70%)
<br>

The code used in Stata is shown here:

&nbsp;
<br>

<div class="superbigimage">

```{r  stata_exp, include=T, echo=T, eval=T, cache=T}

 export_top<-
 data.frame(final="clear all") %>% 
  rbind("ssc install dtalink") %>% 
  rbind(paste0('import delimited "', gsub('/', '\\', path, fixed=T),'\\CONS_TOP_df_dup_ENE_2020.csv"'))%>%
  dplyr::rename("*final"="final") %>% 
  rbind('qui generate id_match = _n')%>%
  rbind('cap drop _id _matchID _matchflag _score')%>%
  rbind('gen fech_ap_top_mod = date(fech_ap_top, "YMD")')%>%
  
  rbind('dtalink hash_key 125 -125 fech_ap_top_mod 125 -125 5 tipocentro 5 -5  sustanciaprincipal1 5 -5 sustanciaprincipal2 5 -5 sustanciaprincipal3 5 -5 totaloh 5 -5 dosisoh 5 -5 totalthc 5 -5 dosisthc 5 -5 totalpbc 5 -5 dosispbc 5 -5 totalcoc 5 -5 dosiscoc 5 -5 totalbzd 5 -5 dosisbzd 5 -5 totalotra 5 -5 dosisotra 5 -5 hurto 5 -5 robo 5 -5 ventadrogas 5 -5 rina 5 -5 totalvif 5 -5 otro 5 -5 totaltransgresion 5 -5 saludpsicologica 5 -5 totaltrabajo 5 -5 totaleducacion 5 -5 saludfisica 5 -5 lugarvivir 5 -5 vivienda 5 -5 calidadvida 5 -5, block(edad) cutoff(300)') %>% 
  rbind('drop if missing(_score)') %>% 
  rbind(paste0('qui save "', gsub('/', '\\', path, fixed=T),'\\_CONS_TOP_df_match75_05_02_2020.dta", replace'))

export_top%>% knitr::kable("html") %>% 
kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size =10) 
  
write.table(export_top, file = paste0(path,"/SUD_CL/__stata_dtalink_top.do"), sep = "",row.names = FALSE, quote = FALSE,fileEncoding="UTF-8")

```
<!---
información sobre el peso de las variables está en: weight_dedup_top.xlsx
-->

</div> 

<br>

```{stata do, collectcode=TRUE,results="hide", eval=T}
*should be in the same folder of the .Rmd
cap do __stata_dtalink_top.do
```

<br>

```{r  dta_import, include=F, eval=T, echo=T, cache=T,results='hide'}
matches_from_stata_TOP <- haven::read_dta(paste0(path,"/Stata Duplicates Match/_CONS_TOP_df_match75_05_02_2020.dta"))
```

There were `r nrow(matches_from_stata_TOP)/2` cases with probabilistic matches, and `r length(unique(matches_from_stata_TOP$hash_key))` HASHs involved in these matches.

### 8. Transformations in TOPs Dataset

First, we can see that there are many types of plans that are variations from the original ones, such as PG-PAI 2. Following SENDA professionals' indications, we recoded these variations and collapsed the categories in M-PAI, P-PR, PG-PAI, and PG-PR. Must note that some cases are identified as men but they are in women-specific treatments.

```{r tab15_change_type_plan, echo=T, paged.print=TRUE, cache=T, warning=F}
CONS_TOP_df_dup_ENE_2020_prev6 %>%
    dplyr::count(Plan.de.Tratamiento, Sexo) %>% 
    dplyr::group_by(Sexo) %>% 
    mutate(prop = paste0(round(100 * prop.table(n)),"%")) %>%
    data.table::data.table() %>% 
    reshape::melt(id.vars = c(1:2)) %>% 
    reshape::cast(.,Plan.de.Tratamiento~Sexo+variable) %>% 
    data.table::as.data.table() %>%
    knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 15. Type of Plan by Sex", col.names= c("Type of\n Treatment", " Man (n)", "Man (%)","Women (n)","Women (%)"), 
                 align =rep('c', 5))  %>%
    kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10) %>%
  add_footnote( c("PR= Residential Program" ,"PAB= Basic Outpatient Program", "PAI= Intensive Outpatient Treatment", "Otro= Other (less frequent and often private or not part of SENDA programs)"), notation = "none")

#3 PR fijo, PRFlexible y PR fijo 2 se pasan a PG PR.//Pr-flexible no puede estar en LV//no hay casos
#4 tipo_de_plan: si tenemos un plan dentro del programa Alcohol-plan, se cambia a PG-plan // Sin casos
#5 tipo_de_plan: si tenemos un plan OTRO-plan se cambia a PG-plan // sin casos

#replace tipo_de_plan = "M-PAI" if tipo_de_plan=="M-PAI2"
#replace tipo_de_plan = "M-PR" if tipo_de_plan=="M-PR2"
#replace tipo_de_plan = "PG-PAI" if tipo_de_plan=="PG PAI 2"
#replace tipo_de_plan = "PG-PAB" if tipo_de_plan=="Otro"
#replace tipo_de_plan = "PG-PAB" if tipo_de_plan=="CALLE"
#replace tipo_de_plan = "" if tipo_de_plan=="NA"
CONS_TOP_df_dup_ENE_2020_prev6 %>%
  dplyr::mutate(OBS=if_else(Plan.de.Tratamiento %in% unlist(c("M-PAI2","M-PR2","PG PAI 2","Otro","CALLE")),paste0(as.character(OBS),";","1.6. Collapsed Treatment Plans"),as.character(OBS),missing=as.character(OBS)))%>%
  dplyr::mutate(tipo_de_plan=dplyr::recode(Plan.de.Tratamiento,"M-PAI2"= "M-PAI", "M-PR2"="M-PR","PG PAI 2"="PG-PAI", "Otro"="PG-PR")) %>%
#PARA VER LO QUE PASA
  #  dplyr::count(Plan.de.Tratamiento, Sexo) %>% 
#    dplyr::group_by(Sexo) %>% 
#    mutate(prop = paste0(round(100 * prop.table(n)),"%")) %>%
#    data.table::data.table() %>% 
#    reshape::melt(id.vars = c(1:2)) %>% 
#    reshape::cast(.,Plan.de.Tratamiento~Sexo+variable) %>% 
#    data.table::as.data.table() %>%
#  as.factor(ty)
  assign("CONS_TOP_df_dup_ENE_2020_prev7",.,envir = .GlobalEnv)
```
<br>
Considering the abovementioned observation, we changed those mens with Masculine identity (obtained from the C1 dataset) into a general population  (PR) plan.
<br>

```{r tab16_change_type_plan2, echo=T, paged.print=TRUE, cache=T, warning=F}
#CONS_TOP_df_dup_ENE_2020_prev7 %>% dplyr::filter(tipo_de_plan=="M-PAI"|tipo_de_plan=="M-PR", Sexo=="Mujer") %>% #dplyr::inner_join(dplyr::select(CONS_C1_df_dup_ENE_2020,HASH_KEY, identidad.de.genero), by="HASH_KEY") %>% dplyr::select(HASH_KEY, id_mod, #tipo_de_plan, identidad.de.genero) %>% dplyr::filter(!is.na(identidad.de.genero)) %>% data.table::as.data.table() %>% print()

CONS_TOP_df_dup_ENE_2020_prev7 %>% dplyr::filter(tipo_de_plan=="M-PAI"|tipo_de_plan=="M-PR", Sexo=="Hombre") %>% dplyr::inner_join(dplyr::select(CONS_C1_df_dup_ENE_2020,hash_key, identidad_de_genero), by=c("HASH_KEY"="hash_key")) %>% dplyr::select(HASH_KEY, id_mod, tipo_de_plan, identidad_de_genero) %>% dplyr::filter(!is.na(identidad_de_genero)) %>%
  data.table::as.data.table() %>%
    knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 16. Gender Identity of Men that were in Women-specific Plans", col.names= c("HASH Key", " ID", "Type of\n Plan","Gender Identity"),
                 align =rep('c', 5))  %>%
    kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10) %>%
  add_footnote( c("Femenino= Femenine Gender Identity","Masculino= Masculine Gender Identity","PAI= Intensive Outpatient Treatment","PR= Residential Program"), notation = "none")

CONS_C1_df_dup_ENE_2020_unique_gender<- dplyr::select(CONS_C1_df_dup_ENE_2020,hash_key, identidad_de_genero) %>% dplyr::filter(!is.na(identidad_de_genero)) %>% group_by(hash_key) %>% dplyr::mutate(row_join=row_number()) %>%ungroup() %>% dplyr::filter(row_join==1) %>% dplyr::mutate(identidad_de_genero=as.character(identidad_de_genero)) %>% data.table::as.data.table(.)

CONS_TOP_df_dup_ENE_2020_prev7 %>%
    dplyr::left_join(CONS_C1_df_dup_ENE_2020_unique_gender, by=c("HASH_KEY"="hash_key")) %>%
    dplyr::mutate(tipo_plan_m=ifelse(tipo_de_plan %in% c("M-PAI", "M-PR", "M-PAB"),1,0)) %>%
    dplyr::mutate(OBS= case_when((identidad_de_genero=="Masculino" & Sexo=="Hombre" & tipo_plan_m==1)~ paste0(as.character(OBS),";","1.7. Standardized Plans By Sex & Gender Id"),TRUE~as.character(OBS)))%>%
    dplyr::mutate(tipo_de_plan=ifelse(identidad_de_genero=="Masculino" & Sexo=="Hombre" & tipo_de_plan=="M-PAB","PG-PAB", tipo_de_plan)) %>%
      dplyr::mutate(tipo_de_plan=ifelse(identidad_de_genero=="Masculino" & Sexo=="Hombre" & tipo_de_plan=="M-PAI","PG-PAI", tipo_de_plan)) %>%
    dplyr::mutate(tipo_de_plan=ifelse(identidad_de_genero=="Masculino" & Sexo=="Hombre" & tipo_de_plan=="M-PR","PG-PR", tipo_de_plan)) %>% 
    #PARA VER LO QUE PASA
#    dplyr::count(tipo_de_plan, Sexo) %>% 
#    dplyr::group_by(Sexo) %>% 
#    mutate(prop = paste0(round(100 * prop.table(n)),"%")) %>%
#    data.table::data.table() %>% 
#    reshape::melt(id.vars = c(1:2)) %>% 
#    reshape::cast(.,tipo_de_plan~Sexo+variable) %>% 
#    data.table::as.data.table() %>%
#  print()
  dplyr::select(-dup_todo_TOP,-dup_contents_TOP,-row_join,-tipo_plan_m) %>%
  as.data.frame() %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev8",.,envir = .GlobalEnv)
```

Also, we generated an ID code of the center of treatment, in order to mask this name and avoid any possible identification of specific cases. However, two centers could not be obtained from C1 dataset because they were not available: "Centro de Tratamiento San Francisco" and "Kausana CIP CRC Antofagasta". **These centers will be consulted to the SENDA professional in order to clarify if they can be replace for another one with a center ID number** .
 
```{r tab17_prueba para transformar nombre centros en id, echo=T, paged.print=TRUE, cache=F, warning=F}
#Centro de Tratamiento San Francisco	220
#Kausana CIP CRC Antofagasta	1
#Ambos no tienen un par en C1 para dejarles código. El problema es que el Centro de Tratamiento San Francisco agrupa a 220 personas.
distinct_HASH_center_not_present_in_C1<- CONS_TOP_df_dup_ENE_2020_prev8 %>% dplyr::filter(Nombre.del.Centro=="Centro de Tratamiento San Francisco") %>% distinct(HASH_KEY) 
CONS_C1_df_dup_ENE_2020 %>%
dplyr::filter(hash_key %in% as.character(as.vector(unlist(as.data.table(unlist(distinct_HASH_center_not_present_in_C1)))))) %>%
dplyr::select(nombre_centro) %>% distinct(nombre_centro) %>%
        knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 17. Different Centers of Treatment that would not be matched with C1 dataset", 
                   #col.names= c("Duplicated", " Frequencies", "Percentage"),
                   align =rep('c', 102))  %>%
      kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  scroll_box(width = "100%", height = "250px")
```

<br>

Also, we collapsed the primary substance of consumption into fewer categories that would be more representative of the patterns of consumption among the Chilean population in terms of SUDs.

<br>

```{r guardar5_main_sub, echo=T, paged.print=TRUE, cache=T, warning=F}
#data.table(table(CONS_TOP_df_dup_ENE_2020_prev8$Sustancia.Principal.1))
CONS_TOP_df_dup_ENE_2020_prev8 %>% 
  dplyr::mutate(sus_prin1=as.character(Sustancia.Principal.1)) %>%
  dplyr::mutate(sus_prin1= dplyr::recode(sus_prin1,
                                              "Hipnóticos "= "Tranquilizantes e Hipnóticos",
                                              "Sedantes:  diazepam, Valium, clonazepam, Ravotril, alprazolam, adax, barbitúricos, fenobarbital." = "Tranquilizantes e Hipnóticos",
                                              "Anfetaminas"="Estimulante tipo anfetaminas",
                                              "Extasis"="Estimulante tipo anfetaminas",
                                              "Fenilciclidina"="Estimulante tipo anfetaminas",
                                              "Metanfetaminas y otros derivados"="Estimulante tipo anfetaminas",
                                              "Otros Estimulantes"="Estimulante tipo anfetaminas",
                                              "LSD"="Alucinógenos",
                                              "Otros Alucinógenos"="Alucinógenos",
                                              "Crack"="Pasta Base",
                                              "Heroína"="Opioides",
                                              "Metadona"="Opioides",
                                              "Otros Opioides Analgésicos: morfina, codeína, meperidina,  demerol, tramadol, tramal."="Opioides",
                                              "Inhalables: neopren, GHB, óxido nitroso (gas hilarante), \"poppers\", solventes, gasolina, diluyente"="Inhalables",
                                              "Esteroides Anabólicos"="Otros",
                                              "Hongos"="Alucinógenos")) %>%
dplyr::mutate(OBS=case_when(sus_prin1=="SIN CONSUMO"~paste0(OBS,";","1.8.Primary Substance1, Invalid due to No Consumption"),
                            TRUE~OBS))%>%    
dplyr::mutate(sus_prin1= dplyr::na_if(sus_prin1, "SIN CONSUMO")) %>%
  dplyr::mutate(sus_prin2=as.character(Sustancia.Principal.2)) %>%
  dplyr::mutate(sus_prin2= dplyr::recode(sus_prin2,
                                              "Hipnóticos "= "Tranquilizantes e Hipnóticos",
                                              "Sedantes:  diazepam, Valium, clonazepam, Ravotril, alprazolam, adax, barbitúricos, fenobarbital." = "Tranquilizantes e Hipnóticos",
                                              "Anfetaminas"="Estimulante tipo anfetaminas",
                                              "Extasis"="Estimulante tipo anfetaminas",
                                              "Fenilciclidina"="Estimulante tipo anfetaminas",
                                              "Metanfetaminas y otros derivados"="Estimulante tipo anfetaminas",
                                              "Otros Estimulantes"="Estimulante tipo anfetaminas",
                                              "LSD"="Alucinógenos",
                                              "Otros Alucinógenos"="Alucinógenos",
                                              "Crack"="Pasta Base",
                                              "Heroína"="Opioides",
                                              "Metadona"="Opioides",
                                              "Otros Opioides Analgésicos: morfina, codeína, meperidina,  demerol, tramadol, tramal."="Opioides",
                                              "Inhalables: neopren, GHB, óxido nitroso (gas hilarante), \"poppers\", solventes, gasolina, diluyente"="Inhalables",
                                              "Esteroides Anabólicos"="Otros",
                                              "Hongos"="Alucinógenos")) %>%
dplyr::mutate(OBS=case_when(sus_prin2=="SIN CONSUMO"~paste0(OBS,";","1.8.Primary Substance2, Invalid due to No Consumption"),
                            TRUE~OBS))%>%
dplyr::mutate(sus_prin2= dplyr::na_if(sus_prin2, "SIN CONSUMO")) %>%
  dplyr::mutate(sus_prin3=as.character(Sustancia.Principal.3)) %>%
  dplyr::mutate(sus_prin3= dplyr::recode(sus_prin3,
                                              "Hipnóticos "= "Tranquilizantes e Hipnóticos",
                                              "Sedantes:  diazepam, Valium, clonazepam, Ravotril, alprazolam, adax, barbitúricos, fenobarbital." = "Tranquilizantes e Hipnóticos",
                                              "Anfetaminas"="Estimulante tipo anfetaminas",
                                              "Extasis"="Estimulante tipo anfetaminas",
                                              "Fenilciclidina"="Estimulante tipo anfetaminas",
                                              "Metanfetaminas y otros derivados"="Estimulante tipo anfetaminas",
                                              "Otros Estimulantes"="Estimulante tipo anfetaminas",
                                              "LSD"="Alucinógenos",
                                              "Otros Alucinógenos"="Alucinógenos",
                                              "Crack"="Pasta Base",
                                              "Heroína"="Opioides",
                                              "Metadona"="Opioides",
                                              "Otros Opioides Analgésicos: morfina, codeína, meperidina,  demerol, tramadol, tramal."="Opioides",
                                              "Inhalables: neopren, GHB, óxido nitroso (gas hilarante), \"poppers\", solventes, gasolina, diluyente"="Inhalables",
                                              "Esteroides Anabólicos"="Otros",
                                              "Hongos"="Alucinógenos")) %>%
dplyr::mutate(OBS=case_when(sus_prin3=="SIN CONSUMO"~paste0(OBS,";","1.8.Primary Substance3, Invalid due to No Consumption"),
                            TRUE~OBS))%>%
dplyr::mutate(sus_prin3= dplyr::na_if(sus_prin3, "SIN CONSUMO")) %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev9",.,envir = .GlobalEnv)
```

```{r guardar6_tidy_of_dataset, echo=T, paged.print=TRUE, cache=T, warning=F}
CONS_TOP_df_dup_ENE_2020_prev9 %>% 
  dplyr::left_join(dplyr::select(CONS_C1_df_dup_ENE_2020, nombre_centro, id_centro) %>% 
  dplyr::distinct(nombre_centro, id_centro), by=c("Nombre.del.Centro"="nombre_centro")) %>% 
  #dplyr::select(-row_join) %>% 
  assign("CONS_TOP_df_dup_ENE_2020_prev9",.,envir = .GlobalEnv)
```

```{r guardar7_change_in_labels, echo=T, paged.print=TRUE, cache=T, warning=F}
CONS_TOP_df_dup_ENE_2020_prev9 %>%
  dplyr::mutate(TOP=as.factor(TOP)) %>%
  dplyr::mutate(Etapa.del.Tratamiento=as.factor(Etapa.del.Tratamiento)) %>%
  dplyr::mutate(Sexo=as.factor(Sexo)) %>%
  dplyr::mutate(Tipo.Centro=as.factor(Tipo.Centro)) %>%
  dplyr::mutate(Hurto=as.factor(Hurto)) %>%
  dplyr::mutate(Robo=as.factor(Robo)) %>%
  dplyr::mutate(Venta.Drogas=as.factor(Venta.Drogas)) %>%
  dplyr::mutate(Riña=as.factor(Riña)) %>%
  dplyr::mutate(Otro=as.factor(Otro)) %>%
  dplyr::mutate(Lugar.Vivir=as.factor(Lugar.Vivir)) %>%
  dplyr::mutate(Vivienda=as.factor(Vivienda)) %>%
  dplyr::mutate(tipo_de_plan=as.factor(tipo_de_plan)) %>%
  dplyr::mutate(sus_prin1=as.factor(sus_prin1)) %>%
  dplyr::mutate(sus_prin2=as.factor(sus_prin2)) %>%
  dplyr::mutate(sus_prin3=as.factor(sus_prin3)) %>%  
  as.data.frame(.) %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev9",.,envir = .GlobalEnv)

  metadata(CONS_TOP_df_dup_ENE_2020_prev9)$name <- "SENDA Treatment Outcomes Profile"
  metadata(CONS_TOP_df_dup_ENE_2020_prev9)$description <- "Information About Treatment Outcomes Profile of users of SENDA, 2015 to 2019"
  #http://docshare03.docshare.tips/files/29337/293377101.pdf Paper de TOP Validación Chilena ACC
codebook::var_label(CONS_TOP_df_dup_ENE_2020_prev9) <- 
  list(HASH_KEY = 'Codificación del RUN/Masked Identifier (RUN)',
    hash_rut_completo = 'HASH alternativo, en el escenario en que se asuma que el individuo al que se le codificó el RUN presente mayor edad/Alternative HASH-Key',
    id_mod = 'ID de SENDA para Presentación en Página Web (enmascara caracteres 5 y 6)/SENDA ID (masked characters 5 & 6)',
    ID = 'Codigo Identificación de SENDA/SENDA ID',
    ano_bd = 'Año de la Base de Datos/Year of the Dataset (Source)',
    row = 'Numerador de los eventos presentes en la Base de Datos/Events in the Dataset',
    Fecha.Aplicación.TOP = '(original, Recodificado en fech_ap_top)/',
    Nombre.Apliacador.del.TOP = 'Nombre Aplicador del TOP/Name of the TOP Interviewer',
    TOP = 'TOP',
    Etapa.del.Tratamiento = 'Etapa del Tratamiento/Stage of Treatment',
    Fecha.Nacimiento = 'Fecha de Nacimiento/Date of Birth',
    Edad = 'Edad (número entero)/Year (Discrete Number)',
    Sexo = 'Sexo/Sex',
    Fecha.de.Ingreso.a.Tratamiento = '(original, Recodificado en fech_ing)/',
    Plan.de.Tratamiento = '(original, Recodificado en tipo_de_plan)/',
    Nombre.del.Centro = 'Nombre del Centro de Tratamiento/Treatment Center',
    Tipo.Centro = 'Tipo de Centro/Type of Center',
    Sustancia.Principal.1 = '(original, Recodificado en sus_prin1)/',
    Sustancia.Principal.2 = '(original, Recodificado en sus_prin2)/',
    Sustancia.Principal.3 = '(original, Recodificado en sus_prin3)/',
    Total.OH = 'Total Alcohol/Total Alcohol',
    Dósis.OH = 'Dosis Consumo de Alcohol/Amount of Alcohol',
    Total.THC = 'Total Marihuana/Total Marijuana',
    Dósis.THC = 'Dosis Marihuana/Dose of Marijuana',
    Total.PBC = 'Total Pasta Base de Cocaína/Total Cocaine Paste Base',
    Dósis.PBC = 'Dosis Pasta Base de Cocaína/Dose of Cocaine Paste Base',
    Total.COC = 'Total Cocaína/Total Snort Cocaine',
    Dósis.COC = 'Dosis Cocaína/Dose of Snort Cocaine',
    Total.BZD = 'Total Sedantes o Tranquilizantes/Total Sedatives and Tranquillizers',
    Dósis.BZD = 'Dosis Sedantes o Tranquilizantes/Dose of Sedatives and Tranquillizers',
    Total.Otra = 'Total Otra sustancia problema/Total Other Substances',
    Dósis.Otra = 'Dosis Otra sustancia problema/Dose of Other Substances',
    Hurto = 'Hurto/Theft',
    Robo = 'Robo/Robbery',
    Venta.Drogas = 'Venta de Drogas/Drug selling',
    Riña = 'Riña/Fights',
    Total.VIF = ' Total Violencia Intrafamiliar/Total Domestic Violence',
    Otro = 'Otra Acción/Another Action',
    Total.Transgresión = 'Total Transgresión a la Norma Social/Total Behavior that transgresses social norms',
    Salud.Psicológica = 'Salud Psicológica/Psychological Health',
    Total.Trabajo = 'Total Trabajo Pagado Formal o Informal/Total of Paid Work',
    Total.Educación = 'Total Asistencia a Establecimiento Educacional o Capacitación Laboral/Total College or school ',
    Salud.Física = 'Total Salud Física/Total Physical Health',
    Lugar.Vivir = 'Lugar estable para vivir/Stable Place to Live',
    Vivienda = 'Vivienda con Condiciones Básicas/Housing conditions',
    Calidad.Vida = 'Total Calidad de Vida/Total Quality of Life (QoL)',
    Región.Centro = 'Región del Centro/Chilean Region of the Center',
    Comentario = 'Comentarios relacionados con la aplicación del TOP/Comments related to the application of TOP',
    fech_ing = 'Fecha de Ingreso a Tratamiento/Date of Admission to Treatment',
    fech_ing_sin_fmt = 'Fecha de Ingreso de Tratamiento (Sin Formato de Fecha)/Date of Admission (unformatted)',
    fech_ap_top = 'Fecha de Aplicación de TOP/Date of Application of TOP',
    fech_nac = 'Fecha de Nacimiento/Date of Birth',
    OBS = 'Observaciones al Proceso de Limpieza y Estandarización de Casos/Observations to the Process of Data Tidying & Standardization',
    Edad_al_ing = 'Edad a la Fecha de Ingreso a Tratamiento (numérico continuo)/Age at Admission to Treatment',
    Edad_at_ap = 'Edad a la Aplicación del Tratamiento (numérico continuo)/Age at the Application of TOP',
    tipo_de_plan = 'Tipo de Plan/Type of Plan',
    identidad_de_genero = 'Identidad de Género/Gender Identity',
    sus_prin1 = 'Sustancia Principal de Consumo (1)/Primary Substance of Consumption (1)',
    sus_prin2 = 'Sustancia Principal de Consumo (2)/Primary Substance of Consumption (2)',
    sus_prin3 = 'Sustancia Principal de Consumo (3)/Primary Substance of Consumption (3)',
    id_centro = 'ID de Centro/Center ID')

  as.data.frame(CONS_TOP_df_dup_ENE_2020_prev9) %>%
  janitor::clean_names()%>%
  assign("CONS_TOP_df_dup_ENE_2020_prev9",.,envir = .GlobalEnv)
  
  #PARA EXPORTAR LABELS A EXCEL
  #data.table::data.table(table(CONS_TOP_df_dup_ENE_2020_prev9$identidad.de.genero, exclude=NULL)) %>% mutate(export=paste0(row_number(),".",V1)) %>% select(-V1) %>% select(export,N)%>% copiar_nombres()
  #es mejor hacerlo con el paquete RIO, en el caso de STATA
save.image(paste0(gsub("/SUD_CL","",path),"/4.Rdata"))
unlink(paste0(path, '/*_cache'), recursive = TRUE)
#save.image("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/4.Rdata")
```

```{r dedup, echo=T, eval=F,paged.print=TRUE, cache=T, warning=F, eval=F}
library(reclin)
#load("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/5.RData")
aplicador_top2<-
CONS_TOP_df_dup_ENE_2020_prev9 %>%
  dplyr::group_by(nombre_apliacador_del_top) %>%
  dplyr::mutate(rn=row_number())%>%
  dplyr::ungroup() %>%
  dplyr::filter(rn==1)%>%
  dplyr::select(nombre_apliacador_del_top, region_centro,id_centro) %>%
  dplyr::mutate(nombre_apliacador_del_top=tolower(nombre_apliacador_del_top)) %>%
  dplyr::mutate(nombre_apliacador_del_top=stringr::str_replace_all(nombre_apliacador_del_top,c("ps." = "", "á" = "a", "é" = "e", "í"="i", "ó"="o","ú"="u","ps "=" ","ts."="","t.s."="","ã\u0081"="a","ts "=" ", "tr."="", "ì"="i"))) %>%
  dplyr::mutate(nombre_apliacador_del_top=str_trim(nombre_apliacador_del_top))
  
  linked_data_set <- pair_blocking(as.data.frame(aplicador_top2), as.data.frame(aplicador_top2))
  #Error: no se puede ubicar un vector de tamaño  36.2 Mb
  compare_pairs(linked_data_set,c("region_centro","id_centro"),
      default_comparator = jaro_winkler(0.9)) %>%
  score_problink(var = "weight") %>%
  select_n_to_m("weight", var = "ntom", threshold = 0) %>%
  link()
  
try(linked_data_set <- pair_blocking(CONS_TOP_df_dup_ENE_2020_prev9, CONS_TOP_df_dup_ENE_2020_prev9, "ID.centro") 
    %>%
  compare_pairs(by = c("Nombre.Apliacador.del.TOP"),
      default_comparator = jaro_winkler(0.8)) %>%
  score_problink(var = "weight") %>%
  select_n_to_m("weight", var = "ntom", threshold = 0) %>%
  link()
    )
```

```{r dedup2, echo=T, eval=F,paged.print=TRUE, cache=T, warning=F, eval=F}
#load("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/4.RData")
library(reclin)
try(linked_data_set <- pair_blocking(CONS_TOP_df_dup_ENE_2020_prev9, CONS_TOP_df_dup_ENE_2020_prev9, "id_centro") 
    %>%
  compare_pairs(by = c("", "firstname", "address", "sex"),
      default_comparator = jaro_winkler(0.9)) %>%
  score_problink(var = "weight") %>%
  select_n_to_m("weight", var = "ntom", threshold = 0) %>%
  link()
    )
try(linked_data_set <- pair_blocking(CONS_TOP_df_dup_ENE_2020_prev9, CONS_TOP_df_dup_ENE_2020_prev9, "ID.centro") 
    %>%
  compare_pairs(by = c("Nombre.Apliacador.del.TOP"),
      default_comparator = jaro_winkler(0.8)) %>%
  score_problink(var = "weight") %>%
  select_n_to_m("weight", var = "ntom", threshold = 0) %>%
  link()
    )


  require(RecordLinkage)
  require(dplyr)

############################# ene2020  
#load("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/5.RData")
CONS_C1_df_dup_ENE_2020 %>%
  dplyr::mutate(Edad= ifelse(is.na(Edad),0,Edad)) %>% #Para prevenir  Error in if (v1 == d1) return(x) : missing value where TRUE/FALSE needed
  dplyr::filter(!is.na(fech_ing)) %>% #Para prevenir  Error in if (v1 == d1) return(x) : missing value where TRUE/FALSE needed
dplyr::select("concat", "Edad") %>%
assign("CONS_C1_df_dup_ENE_2020_concat",.,envir = .GlobalEnv)

#Pairing
  pairs_edad=RLBigDataDedup(CONS_C1_df_dup_ENE_2020_concat, blockfld="Edad",convert.na = TRUE,strcmp=TRUE ,strcmpfun=levenshteinSim)
  pairs_edad_jaro=RLBigDataDedup(CONS_C1_df_dup_ENE_2020_concat, blockfld="Edad",convert.na = TRUE,strcmp=TRUE ,strcmpfun=levenshteinSim)
  getExpectedSize(pairs_edad) #no funciona
  getParetoThreshold(pairs_edad, quantil = 0.95) # no funciona
  
#Unsupervised classification by clustering  
  bclust_edad<- classifyUnsup(pairs_edad, method="bclust")
  k_means_edad<- classifyUnsup(pairs_edad, method="kmeans")
  
  p_edad=epiWeights(pairs_edad,withProgressBar=(sink.number()==0))
  
  edad_weights_em <- emWeights(p_edad,cutoff = 0.90, verbose = TRUE) #
  classify_edad <- epiClassify(p_edad,0.88,withProgressBar=(sink.number()==0))  
  classify_edad_em <- emClassify(classify_edad, 0.6)
  match_edad <- classify_edad_em$prediction
  results_edad <- cbind(classify_edad_em$pairs,match_edad)
  getPairs(classify_edad_em, min.weight = 0.5)
  getPairs(rpairs,min.weight=0.5, max.weight=0.5, filter.match="match")
  classify_edad
  ##strcomp
############################# APR-2020  -TOP
  CONS_TOP_df_dup_ENE_2020_prev9 %>%
    dplyr::select("ID.centro","Nombre.Apliacador.del.TOP") %>%
  dplyr::mutate(ID.centro= ifelse(is.na(ID.centro),0,ID.centro)) %>% #Para prevenir  Error in if (v1 == d1) return(x) : missing value where TRUE/FALSE needed
  as.data.frame() %>%
  assign("CONS_TOP_df_dup_ENE_2020_prev9_concat",.,envir = .GlobalEnv)
    pairs_id_aplicador=RecordLinkage::RLBigDataDedup(CONS_TOP_df_dup_ENE_2020_prev9_concat, blockfld="ID.centro",strcmp=TRUE ,strcmpfun = "jarowinkler", phonetic = numeric(0),phonfun = "soundex")
  getExpectedSize(pairs_id_aplicador) 
  getParetoThreshold(pairs_id_aplicador, quantil = 0.95)
bclust_ID<- classifyUnsup(pairs_id_aplicador, method="bclust") #no funciona
k_means_ID<- classifyUnsup(pairs_id_aplicador, method="kmeans")#no funciona
p_ID=epiWeights(pairs_id_aplicador,withProgressBar=(sink.number()==0))
classify_ID <- epiClassify(pairs_id_aplicador,0.88,withProgressBar=(sink.number()==0))   #0s and mixed positive/negative subscripts not allowed
classify_ID_em <- emClassify(ID_weights_em, 0.6) #No weights in rpairs!, LO PROBÉ CON PAIRS_ID_APLICADOR TAMBIÉN
ID_weights_em <- emWeights(pairs_id_aplicador,cutoff = 0.90, verbose = TRUE) #
getPairs(pairs_id_aplicador, min.weight = 0.5)
getPairs(p_ID,min.weight=0.5, max.weight=0.5, filter.match="match")

pairs_ID_jaro=RLBigDataDedup(CONS_TOP_df_dup_ENE_2020_prev9_concat, blockfld="ID.centro",strcmp=TRUE)
getExpectedSize(pairs_ID_jaro) #no funciona
getParetoThreshold(pairs_ID_jaro, quantil = 0.95) #Error in plot.window(...) : se necesitan valores finitos de 'ylim'
getExpectedSize(pairs_ID_jaro
classifyUnsup(pairs_ID_jaro, method="bclust") #no funciona Wrong class for rpairs!
```