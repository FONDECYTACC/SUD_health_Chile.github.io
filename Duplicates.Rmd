---
title: "Duplicated/ Repeated Cases in SISTRAT C1"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide  
    toc: true # table of content true
    toc_depth: 5  # upto three depths of headings (specified by #, ## and ###)
    toc_float: true
---

<style type="text/css">
.tablelines table, .tablelines td, .tablelines th {
        border: 1px solid black;
        }
.centrado {
    text-align: center;
}
.table.center {
    margin-left:auto; 
    margin-right:auto;
  }
.table_wrapper{
    display: block;
    overflow-x: auto;
    white-space: nowrap;
}
code.r{
  font-size: 8px;
}
body{ /* Normal  */
      text-align: justify;
  }
</style>

```{r prev, include=FALSE, cache=T}
rm(list=ls());gc()
unlink('SUD_CL/Duplicates_cache', recursive = TRUE)
```

```{r load, include=FALSE, cache=T}
load("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/1.Rdata")
if(!require(dplyr)){install.packages("dplyr")}
if(!require(data.table)){install.packages("data.table")}
require(data.table)
require(dplyr)
CONS_C1_df%>%
  dplyr::mutate(fech_ing_ano = lubridate::year(fech_ing), 
                fech_ing_mes = lubridate::month(fech_ing), 
                fech_ing_dia = lubridate::day(fech_ing)) %>%
  dplyr::mutate(concat=paste0(HASH_KEY,"_",fech_ing_ano,"_",fech_ing_mes,"_",fech_ing_dia)) %>%
  dplyr::mutate(duplicated_HASH_date = duplicated(concat)) %>%
  as.data.table() %>%
  assign("CONS_C1_df_dup",.,envir = .GlobalEnv)
#45526 trues
```

```{r setup, include = FALSE, cache=T}
#Libraries used in the routine. Dont change the order
if(!require(tidyr)){install.packages("tidyr")}
if(!require(DataExplorer)){install.packages("DataExplorer")}
if(!require(stringi)){install.packages("stringi")}
if(!require(stringr)){install.packages("stringr")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(Hmisc)){install.packages("Hmisc")}
if(!require(kableExtra)){install.packages("kableExtra")}
if(!require(plotly)){install.packages("plotly")}
if(!require(rbokeh)){install.packages("rbokeh")}
if(!require(altair)){install.packages("altair")}
if(!require(zoo)){install.packages("zoo")}
#if(!require(texreg)){install.packages("texreg")}
#if(!require(stargazer)){install.packages("stargazer")}
#if(!require(tab)){install.packages("tab")}
#remotes::install_github("leifeld/texreg",force = TRUE)
if(!require(broom)){install.packages("broom")}
if(!require(sqldf)){install.packages("sqldf")} 
if(!require(data.table)){install.packages("data.table")}
if(!require(dplyr)){install.packages("dplyr")}
unlink('SUD_CL/Duplicates_cache', recursive = TRUE)#para clear cache
```

## 1. Deletion of nearly exact duplicated cases

&nbsp;
<br>
The dataset was configured to find duplicated rows in almost every variable, excepting the row number in the whole consolidated dataset and the year of the dataset in which the row was obtained. For the purpose of this page, we will use the terms "rows" and "cases" as equal to refer to the entries of the dataset.

<br>

```{r echo=T, cache=T, paged.print=TRUE}
#create vector with variable names
names_c1 <- names(CONS_C1_df_dup[,c(3,5:106)])
#Group by duplicated rows 
as.data.table(CONS_C1_df_dup)[, dup_todo := .N, by = names_c1] %>%
  data.table::as.data.table() %>%
  assign("CONS_C1_df_dup_ENE_2020_prev",.,envir = .GlobalEnv)
#summarise duplicates and times
as.data.table(CONS_C1_df_dup)[, dup_todo := .N, by = names_c1] %>%
  dplyr::arrange(HASH_KEY, fech_ing, desc(ano_bd)) %>%
  dplyr::group_by(dup_todo) %>%
  dplyr::summarise(n()) %>%
  data.frame() %>%
  dplyr::rename("Times present in Dataset"=dup_todo, "Number of Rows"=`n..`) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 1. Duplicated cases in almost every variable",
                 align ="cccc")  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10)
```

```{r dataset_creation, echo=F, paged.print=TRUE, cache=T, warning=F}
data.table::data.table(CONS_C1_df_dup_ENE_2020_prev) %>%
  dplyr::arrange(desc(ano_bd)) %>%
  dplyr::distinct_(.dots = names_c1, .keep_all = TRUE) %>%
  dplyr::arrange(HASH_KEY, fech_ing, desc(ano_bd), desc(fech_egres)) %>%
  data.table::as.data.table() %>%
  assign("CONS_C1_df_dup_ENE_2020_prev",.,envir = .GlobalEnv)
#Unlike base sorting with sort(), NA are: always sorted to the end for local data, even when wrapped with desc().
```

&nbsp;
<br>
Since these duplicated rows contained the same values, **no additional information is lost by deleting these rows**. Considering this, of the original `r formatC(nrow(CONS_C1_df_dup), format="f", big.mark=",", digits=0)` cases, only `r formatC(nrow(CONS_C1_df_dup_ENE_2020_prev), format="f", big.mark=",", digits=0)` rows were selected to the analysis. Still, we need to identify which row has nearly the same but more recent information regarding an specific treatment of a patient, that is why we need to eliminate duplicated rows, but **keep events that contemplates more days of treatment, or comes from more recent yearly datasets**. Table 2 shows HASHs that possess negative days of treatment and their entries. **We meed to clarify some dates in order to avoid overlap between treatments. As can be seen in Table 2, a few can be replaced by an event with siilar dates, but there were others that may be imuted once the dataset is normalized.** 

<br>

```{r neg treat days, echo=T, paged.print=TRUE, message=F}
require(dplyr)
require(data.table)
HASHS_of_negtive_days_treat <- CONS_C1_df_dup_ENE_2020_prev %>% 
  dplyr::mutate(fech_ing_num=as.numeric(as.Date(fech_ing)), fech_egres_num= as.numeric(as.Date(fech_egres)),discharge_before_treatment=fech_egres_num-fech_ing_num) %>%
  dplyr::filter(discharge_before_treatment<0) %>%
  dplyr::select(row, ano_bd, HASH_KEY, id_mod, ano_nac, ano_bd,fech_ing, fech_egres,tipo_de_plan, tipo_de_programa, ID.centro, Edad, dias_trat, SENDA) %>% dplyr::distinct(HASH_KEY)
#
CONS_C1_df_dup_ENE_2020_prev %>% 
    dplyr::filter(HASH_KEY %in% as.character(as.vector(unlist(as.data.table(unlist(HASHS_of_negtive_days_treat)))))) %>%
    dplyr::arrange(HASH_KEY, fech_ing, desc(ano_bd)) %>%
    dplyr::select(row, ano_bd, HASH_KEY, id_mod, ano_nac, ano_bd,fech_ing, fech_egres,tipo_de_plan, tipo_de_programa, ID.centro, Edad, dias_trat, SENDA) %>% 
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 2 Negative days of treatment", align =rep('c', 101)) %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote( c("Assuming the date of retrieval, 2019-11-13"), notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "350px")


```

<br>

The second stage consisted in **eliminating rows that contained duplicated values in some variables related to the patient and more contextual variables. The following were selected:** HASH Key (HASH_KEY), date of admission (fech_ing), type of center(tipo_centro), ID of the center(ID.centro), type of program (Tipo.de.Programa), type of plan (Tipo.de.Plan), SENDA program (SENDA), main substance of consumption (Sustancia.Principal), other substances (first, second and third) (Otras.Sustancias.), frequency of consumption of the main substance (Frecuencia.de.Consumo..Sustancia.Principal), substance of initiation (Sustancia.de.Inicio) and year of the initiation (Edad.Inicio.Consumo).

<br>

```{r dataset_iteration1, echo=F, paged.print=TRUE, cache=T, warning=F, message=F}
require(data.table)
names_c1_stage2 <- c("HASH_KEY","fech_ing", "tipo_centro", "ID.centro", "Tipo.de.Programa", "Tipo.de.Plan", "SENDA", "Sustancia.Principal", "Otras.Sustancias.nº1","Otras.Sustancias.nº2","Otras.Sustancias.nº3", "Frecuencia.de.Consumo..Sustancia.Principal.","Sustancia.de.Inicio", "Edad.Inicio.Consumo")
require(dplyr)
data.table::data.table(CONS_C1_df_dup_ENE_2020_prev) %>%
  dplyr::mutate(dias_trat_inv=ifelse(dias_trat<0,0,dias_trat*-1))%>% #transforma los erroneos en 0
  #dplyr::group_by(dias_trat_inv) %>%summarise(n()) %>% View() para probarlo
  dplyr::arrange(desc(ano_bd),HASH_KEY, desc(fech_ing), desc(fech_egres),dias_trat_inv) %>%
  dplyr::distinct_(.dots = names_c1_stage2, .keep_all = TRUE) %>%
#  dplyr::arrange(HASH_KEY, fech_ing, desc(ano_bd)) %>%
  data.table::as.data.table() %>% #para contar las filas
 # dplyr::select(row) %>%  summarise(mean(row), sd(row)) #, lo mismo que en STATA. Se supone que una row es sensible a cambios distintos.
  assign("CONS_C1_df_dup_ENE_2020_prev2",.,envir = .GlobalEnv)
#Lo mismo que en STATA: Ahora hay 118,121. Una vez que introduje 
#  dplyr::arrange(HASH_KEY, fech_ing, desc(ano_bd), desc(fech_egres)) %>% criterio anterior
```

Of the total `r formatC(nrow(CONS_C1_df_dup_ENE_2020_prev2), format="f", big.mark=",", digits=0)` cases, there were `r CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::filter(hash_rut_completo!="") %>% nrow()` with an alternative HASH key, that could be replaced if the first HASH does not match any of the HASHs Keys of another datasets. In the following table, we can see that duplicated cases may be around 5.5% per yearly datasets.

```{r echo=T, paged.print=TRUE}
#Cases by year.
CONS_C1_df_dup_ENE_2020_prev2 %>% 
      dplyr::group_by(ano_bd) %>% 
      dplyr::tally() %>%
      as.data.frame() %>%
      dplyr::mutate(ano_bd=as.numeric(ano_bd)) %>%
      assign("cant_ano",., envir = .GlobalEnv)
CONS_C1_df_dup_ENE_2020_prev2 %>% 
  dplyr::group_by(ano_bd) %>% 
  distinct(HASH_KEY) %>% 
  dplyr::summarize(n=n()) %>% 
  dplyr::mutate(ano_bd= as.numeric(ano_bd)) %>%
  dplyr::left_join(cant_ano,by="ano_bd") %>% 
  mutate(dif=`n.y`-`n.x`, "%"=paste0(round(100 * dif/`n.y`, 1), "%")) %>%
  dplyr::rename("Year"=ano_bd, "Unique HASHs"=n.x, "Total Cases"=n.y, "Diff."=dif) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 3. Differences between HASHs and unique HASHs by year",
                 align ="cccc")  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10)
```
&nbsp;

## 2. Identification of HASH-Keys and ID's from SENDA

&nbsp;

There were `r CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::select(ano_bd,id,HASH_KEY) %>% dplyr::group_by(ano_bd,id) %>% tally() %>% dplyr::mutate(n_col=n) %>% dplyr::filter(n>1) %>% as.data.frame() %>% reshape::cast(.,ano_bd+id~n) %>% dplyr::arrange(ano_bd,id) %>% nrow() %>%  formatC(, format="f", big.mark=",", digits=0)` that has more than 1 repeated SENDAs ID in each yearly dataset. This same analysis but considering more than 1 repeated HASH in each yearly dataset, is around `r CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::select(ano_bd,id,HASH_KEY) %>% dplyr::group_by(ano_bd,HASH_KEY) %>% tally() %>%  dplyr::mutate(n_col=n) %>%  dplyr::filter(n>1) %>%   as.data.frame() %>%  reshape::cast(.,ano_bd+HASH_KEY~n) %>% dplyr::arrange(ano_bd, HASH_KEY) %>% nrow() %>% formatC(, format="f", big.mark=",", digits=0)`. Of the `r CONS_C1_df_dup_ENE_2020_prev2 %>% nrow() %>% formatC(, format="f", big.mark=",", digits=0)` cases, around `r CONS_C1_df_dup_ENE_2020_prev2 %>%  mutate(concat=paste0(id,"_",HASH_KEY)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% nrow() %>% formatC(, format="f", big.mark=",", digits=0)` had a unique combination of ID and HASH. There were `r CONS_C1_df_dup_ENE_2020_prev2 %>%  dplyr::distinct(HASH_KEY, .keep_all = TRUE) %>% nrow()  %>% formatC(, format="f", big.mark=",", digits=0)` unique HASHs, and `r CONS_C1_df_dup_ENE_2020_prev2 %>%  dplyr::distinct(id, .keep_all = TRUE) %>% nrow()  %>% formatC(, format="f", big.mark=",", digits=0)` unique IDs.

&nbsp;
<br>

Instead, there were `r CONS_C1_df_dup_ENE_2020_prev2 %>% mutate(concat=paste0(id,"_",HASH_KEY)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% dplyr::filter(duplicated(id)) %>% dplyr::arrange(id) %>%  dplyr::select(HASH_KEY,id,hash_rut_completo) %>% nrow() %>%  formatC(, format="f", big.mark=",", digits=0)` patients with duplicated HASH's in each ID. This represents a `r paste0(round((CONS_C1_df_dup_ENE_2020_prev2 %>% mutate(concat=paste0(id,"_",HASH_KEY)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% dplyr::filter(duplicated(id)) %>% dplyr::arrange(id) %>%  dplyr::select(HASH_KEY,id,hash_rut_completo) %>% nrow()/ CONS_C1_df_dup_ENE_2020_prev2 %>% nrow())*100,1),"%")` of the total cases.


```{r IDs w more than one hash, echo=T, paged.print=TRUE}
#Take which has a combination of IDs and HASH Keys distinct to the rest
#With this I may be subestimating the number of cases with a different concatenation.
#Considering all the distinct combinations, i take what they have a duplicate ID
#Select the duplicate IDs, it orders and...
#Filter only cases that has distinct id.
CONS_C1_df_dup_ENE_2020_prev2 %>% mutate(concat=paste0(id,"_",HASH_KEY)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% #once here, n° of cases has been replaced by distinct or unique combinations of IDs and HASH keys.
  dplyr::filter(duplicated(id)) %>% dplyr::arrange(id) %>%  #filter cases in which there is more than one ID, despite there is differents combinations of HASH and IDs, and then arrange IDs. This is possible only if a different HASH-Key contains more than one ID or viceversa.
  dplyr::distinct(id) %>% #take distincts IDs (exclude duplicated repeated IDs)
  assign("ids_more_one_hash",., envir = .GlobalEnv) # Differently put, take the distints IDs per HASH-Key, of the cases in which there are different combinations.
# of IDs and hash, and in which subgroup exists duplicated IDs.
 
#IMPORTANT: IF THE ID IS DUPLICATED, MIGHT NOT BE REFLECTED IN THIS RESUME IN TERMS OF QUANTITY.

# Then, apply these cases to the whole population
CONS_C1_df_dup_ENE_2020_prev2 %>%
dplyr::filter(id %in% as.character(as.vector(unlist(as.data.table(unlist(ids_more_one_hash)))))) %>% # Select IDs of cited cases
dplyr::arrange(id) %>% #ordeno por ids 
  #762 cases. 409 cases without duplicates.
      dplyr::select(-id,-TABLE,-14,-16,-17,-26,-27,-28,-29,-35,-36,-37,-88,-93,-94,-96,-101,-110,-11,-112) %>%
      dplyr::select(row, ano_bd, id_mod, HASH_KEY, hash_rut_completo ,fech_ing, fech_egres,tipo_de_plan, tipo_de_programa, ID.centro, everything()) %>%
 knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 4. Total cases that each ID have more than one HASH-KEY",
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
```

&nbsp;

For example, we can appreciate that an id like "MAMO108111971"contain different HASH_KEYs: `r  CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::filter(id=="MAMO108111971") %>% dplyr::distinct(HASH_KEY) %>%  dplyr::filter(row_number()==1)` and `r  CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::filter(id=="MAMO108111971") %>% dplyr::distinct(HASH_KEY) %>%  dplyr::filter(row_number()==2)`.

&nbsp;

```{r echo=F, paged.print=TRUE}
CONS_C1_df_dup_ENE_2020_prev2 %>% 
  dplyr::filter(id=="MASA124091985"|id=="NIAG108091996"|id=="JUGA108021973"|id=="MAMO108111971") %>%
  dplyr::arrange(id) %>%
      dplyr::select(-id,-TABLE,-14,-16,-17,-26,-27,-28,-29,-35,-36,-37,-88,-93,-94,-96,-101) %>%
      dplyr::select(row, ano_bd, id_mod,HASH_KEY, hash_rut_completo, fech_ing, fech_egres,tipo_de_plan, tipo_de_programa, ID.centro, everything()) %>%
 knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 5. Examples of problematic IDs",
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
```
&nbsp;


There were `r CONS_C1_df_dup_ENE_2020_prev2 %>% mutate(concat=paste0(id,"_",HASH_KEY)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% dplyr::filter(duplicated(HASH_KEY)) %>% dplyr::arrange(HASH_KEY) %>%  dplyr::select(HASH_KEY,id,hash_rut_completo) %>% nrow() %>%  formatC(, format="f", big.mark=",", digits=0)` HASHs with duplicated ID's en each hash. This represents a `r paste0(round((CONS_C1_df_dup_ENE_2020_prev2 %>% mutate(concat=paste0(id,"_",HASH_KEY)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% dplyr::filter(duplicated(HASH_KEY)) %>% dplyr::arrange(HASH_KEY) %>%  dplyr::select(HASH_KEY,id,hash_rut_completo) %>% nrow()/nrow(CONS_C1_df_dup_ENE_2020_prev2))*100,1),"%")` of the total cases. A much bigger number that could mean that **HASH could be less likely to represent more than one patient, compared to SENDAs ID.**

## 3. Focus on Duplicated Cases and Dates of Admission

&nbsp;

**We need to distinguish between duplicated cases and admissions from 2010 to 2019**  
One problem is that many variables could not be retrieved from  SENDAs datasets. We need to know if a certain amount of missing data can be replaced by another entry in the dataset that shares the same HASH and date of admission. A possible set of indexes could be the Date of discharge (fech_egres), Cause of discharge (motivodeegreso), Days of treatment (dias_trat) and Date of Last Treatment.

There were `r CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::mutate(concat=paste0(id,"_",HASH_KEY,"_",fech_ing,"_",fech_egres,"_",motivodeegreso,"_",dias_trat,"_",Fecha.Ultimo.Tratamiento)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% nrow() %>%  formatC(, format="f", big.mark=",", digits=0)` (which represents the `r paste0(round((CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::mutate(concat=paste0(id,"_",HASH_KEY,"_",fech_ing,"_",fech_egres,"_",motivodeegreso,"_",dias_trat,"_",Fecha.Ultimo.Tratamiento)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% nrow()*100/CONS_C1_df_dup_ENE_2020_prev2 %>% nrow),2),"%")` of the `r CONS_C1_df_dup_ENE_2020_prev2 %>% nrow() %>%  formatC(, format="f", big.mark=",", digits=0)` cases), with distinct cases with a unique ID, HASH, date of admission, date of discharge, cause of discharge, days treated and days of last treatment. Comparing the explanatory power of each variable: cause of discharge does not impact in the number of unique cases, maintaining other variables, neither dates of admission and discharge removed separately, maintaining the other variables, but if both are removed, we get `r CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::mutate(concat=paste0(id,"_",HASH_KEY,"_",motivodeegreso,"_",dias_trat,"_",Fecha.Ultimo.Tratamiento)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% nrow() %>%  formatC(, format="f", big.mark=",", digits=0)` unique cases. Days of treatment does, lowering into `r  CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::mutate(concat=paste0(id,"_",HASH_KEY,"_",fech_ing,"_",fech_egres,"_",motivodeegreso,"_",Fecha.Ultimo.Tratamiento)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% nrow() %>%  formatC(, format="f", big.mark=",", digits=0)` unique cases. If we remove the ID we get `r CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::mutate(concat=paste0(HASH_KEY,"_",fech_ing,"_",fech_egres,"_",motivodeegreso,"_",dias_trat,"_",Fecha.Ultimo.Tratamiento)) %>% dplyr::distinct(concat, .keep_all = TRUE) %>% nrow() %>%  formatC(, format="f", big.mark=",", digits=0)` unique cases.

&nbsp;

```{r echo=F, paged.print=TRUE, warning=F, message=F}
# OR plot
m1=glm(duplicated_HASH_date ~ is.na(fech_egres) + is.na(motivodeegreso) + is.na(dias_trat) + is.na(Fecha.Ultimo.Tratamiento), data=CONS_C1_df_dup_ENE_2020_prev2, family = binomial ( link = logit )) 
#m2=glm(duplicated ~ factor(sexo) + fech_egres +Fecha.Ultimo.Tratamiento, data = CONS_C1_df_dup_ENE_2020_prev2, family = binomial ( link = logit ))

m1_0 <- update(m1, . ~ 1)
require(lmtest)
cbind(Coef.=rbind("Intercept","Date of Discharge(NULL)", "Cause of Discharge(NULL)", "Days of Treatment(NULL)", "Date of Last Treatment(NULL)"),
      as.matrix.data.frame(round(Epi::ci.lin(m1, Exp=T),3))[,1:7]) %>% 
knitr::kable(., digits=3, scientific=FALSE,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 6. Coefficients of model to determinate whether events have the same HASH and Date of Admission",
      col.names= c("Covariates", "Coef.", "StdErr","z","P","OR", "CI 95% lower","CI 95% upper"),
      align =rep('c', 101)) %>%
 kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 11) %>%
  kableExtra::add_footnote(paste0("LR:",round(lmtest::lrtest(m1)$`LogLik`[1],2),", df=5, ","AIC=",round(m1$aic,2)), notation = "none")

```

&nbsp;

Of Table 6, we can identify that the fact that date of last treatment is missing may be associated with slightly more duplicated cases in comparison to cases that have a date of last treatment. This means that possibly we can replace this date with another entry that has the same date of admission and HASH key. This can be useful to  close ranges within treatments, by defining a date of admission and a date of discharge.

&nbsp;

## 4. Age in datasets

<br>

Based on the meeting on Dec. 05 of 2019, one of the main challenges was to check wether age was linked to the last 4 numbers of each ID. As we can see in the Figure 1, there is a clear correlation with a few residuals. If year of birth is regressed on year, we find that the intercept is `r coef(lm(ano_nac ~Edad, data= CONS_C1_df_dup_ENE_2020_prev2))[1] %>%  formatC(, format="f", big.mark=",", digits=2)` and the slope is `r coef(lm(ano_nac ~Edad, data= CONS_C1_df_dup_ENE_2020_prev2))[2] %>%  formatC(, format="f", big.mark=",", digits=2)`.

<br>

##### Figure 1. Scatterplot of Year of Birth and Age
```{r fig_fecha_nac_edad, fig.height=4, fig.width=8, warning=FALSE, fig.align = "center", message=F}
#plot(CONS_C1_df_dup_ENE_2020_prev2$ano_nac, CONS_C1_df_dup_ENE_2020_prev2$Edad, ylab="Age", xlab="Year of Birth")

#figure() %>%
 # ly_points(ano_nac, Edad, data = CONS_C1_df_dup_ENE_2020_prev2,
#    hover = c(row,ano_bd)) %>%
#  ly_abline(lm(ano_nac ~Edad, data= CONS_C1_df_dup_ENE_2020_prev2), type = 2, legend = "Regression") %>%
 #   x_axis(label = "Year of Birth")
 #   y_axis(label = "Age")
require(plotly)
plotly::plot_ly(CONS_C1_df_dup_ENE_2020_prev2, x = ~ano_nac, y = ~Edad, 
        text =  ~paste("Row: ", row, '<br>Year DB:', ano_bd),
        mode = "markers") %>% layout(xaxis=list(title="Year of Birth"), 
                                     yaxis=list(title="Age"))
```


<br>

We identified the outliers, ending up with 3 cases in which the expected age and year of birth presented a difference greater than 1 year. In Table 7 we can see the first 6 cases that had differences ordered by the magnitude of the difference. The rest of the `r CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::mutate(dif_edad=ano_nac-(2019-Edad)) %>% filter(dif_edad!=0) %>% nrow() %>% sum(-3) %>% formatC(, format="f", big.mark=",", digits=0)` had 12 months of difference.

<br>


```{r edad_fecha_nac, echo=T, paged.print=TRUE}
    CONS_C1_df_dup_ENE_2020_prev2 %>%
    dplyr::mutate(dif_edad=ano_nac-(2019-Edad)) %>%
      dplyr::filter(dif_edad!=0) %>%
      dplyr::arrange(desc(dif_edad)) %>%
      dplyr::select(-id,-TABLE,-14,-16,-17,-26,-27,-28,-29,-35,-36,-37,-88,-93,-94,-96,-101) %>%
      dplyr::select(row, ano_bd, ano_nac, Edad, dif_edad,
                    HASH_KEY, hash_rut_completo, id_mod,fech_ing, fech_egres,tipo_de_plan, tipo_de_programa, 
                    ID.centro, everything()) %>%
      head() %>%
 knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 7. Cases that have a different year of birth and age",
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
```


<br>

However, we may take account that there are `r paste0(round(CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::filter(Edad<18|Edad>90) %>% dplyr::summarise(n())/nrow(CONS_C1_df_dup_ENE_2020_prev2),3)*100,"%")` cases with inappropiate years, representing `r CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::filter(Edad<18) %>% dplyr::summarise(n()) %>% as.numeric() %>% formatC(, format="f", big.mark=",", digits=0)` cases with less than 18 years, and `r CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::filter(Edad>90) %>% dplyr::summarise(n()) %>% as.numeric() %>%  formatC(, format="f", big.mark=",", digits=0)` cases with more than 90 years. Most of the SENDAs IDs are constructed from the date of admission, as can be seen in Table 8:

<br>
```{r wrong ages, echo=T, paged.print=TRUE}
  CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::filter(Edad<18|Edad>90) %>%
    dplyr::select(row, HASH_KEY, id_mod, ano_nac, ano_bd,Edad,fech_ing) %>%
 knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 8. Cases that have a wrongly asigned age",
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
```

<br>

This may condition the data linkage, given that if I assign a missing value to a patient that in other registry has the correct age, it won't be match within the block assigned. In order to account for this possible bias, we checked whether cases may be replaced with data with another HASH Key.

<br>

```{r wrong ages duplicates, echo=T,cache=T, paged.print=TRUE}
#list of distinct HASHs that have a wrongly assigned age
CONS_C1_df_dup_ENE_2020_prev2 %>% dplyr::filter(Edad<18|Edad>90) %>%
  dplyr::distinct(HASH_KEY) %>%
  assign("distinct_hash_wrong_age2",., envir = .GlobalEnv)

#Then, apply these cases to the whole population
CONS_C1_df_dup_ENE_2020_prev2 %>%
dplyr::filter(HASH_KEY %in% as.character(as.vector(unlist(as.data.table(unlist(distinct_hash_wrong_age2)))))) %>% # select hashs of wrongly assigned ages
dplyr::arrange(HASH_KEY) %>% #order by hashs 
  dplyr::filter(Edad>=18,Edad<=90) %>% #nrow() #if you want to see how many cases would be changed: 387.
  #dplyr::filter(!duplicated(HASH_KEY)) %>% nrow() # 211 DIFFERENT HASHS WERE CAPTURED.
      dplyr::select(-id,-TABLE,-14,-16,-17,-26,-27,-28,-29,-35,-36,-37,-88,-93,-94,-96,-101) %>%
      dplyr::select(row, ano_bd, HASH_KEY, id_mod, ano_nac, ano_bd,Edad, fech_ing, fech_egres,tipo_de_plan, tipo_de_programa, ID.centro, everything()) %>%
 knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 9. Total cases with wrong ages but their HASH have a valid age along the dataset",
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
```

```{r transformation of ages in datasets, echo=F,cache=T, paged.print=TRUE}
#Capture every valid case distinct that has a valid age
CONS_C1_df_dup_age <- dplyr::select(CONS_C1_df, HASH_KEY, id, id_mod, Edad)%>% 
                      dplyr::filter(Edad>=18, Edad<=90) %>% #%>%  #dim rows 85490, 4 columns
                      dplyr::filter(!duplicated(HASH_KEY)) #lo mismo que  dplyr::distinct(HASH_KEY)
#Join datasets 
  dplyr::left_join(CONS_C1_df_dup_ENE_2020_prev2,dplyr::select(CONS_C1_df_dup_age,HASH_KEY,Edad, id,id_mod), by = "HASH_KEY", suffix = c("", ".y")) %>% # dim()
    dplyr::mutate(id= ifelse((Edad<18 & !is.na(Edad.y))|(Edad>90 & !is.na(Edad.y)),id.y, id)) %>%
    dplyr::mutate(id_mod=ifelse((Edad<18 & !is.na(Edad.y))|(Edad>90 & !is.na(Edad.y)),id_mod.y,id_mod)) %>% 
    dplyr::mutate(Edad= ifelse(Edad<18|Edad>90,Edad.y, Edad)) %>% #treat as invalid
 dplyr::select(-id_mod.y, -id.y) %>%
    #dplyr::group_by(Edad) %>% summarise(n=n()) %>% View()
    assign("CONS_C1_df_dup_ENE_2020_prev3",., envir = .GlobalEnv) 
  #The modification of age must be in the end of the changes, so it does not affect the rest of variables
```

<br>

We found that the age is a time-invariant variable. In order to find similar matches, we need to identify the date of admission and the HASH Key, but also considering the year, leading to `r CONS_C1_df_dup_ENE_2020_prev3 %>% dplyr::filter(Edad<18, Edad>90) %>% nrow()` invalid values in age, but `r CONS_C1_df_dup_ENE_2020_prev3 %>% dplyr::filter(is.na(Edad)) %>% nrow() %>%  formatC(, format="f", big.mark=",", digits=0)` missing values with `r CONS_C1_df_dup_ENE_2020_prev3 %>% dplyr::filter(is.na(Edad)) %>% distinct(HASH_KEY) %>% nrow() %>%  formatC(, format="f", big.mark=",", digits=0)` different HASH keys. This may be found in Table 10, as cases found correspond mainly to people that does not present any valid age throughout different ages.

<br>

```{r invalid values in age, echo=T, paged.print=TRUE}
CONS_C1_df_dup_ENE_2020_prev3 %>% 
  dplyr::filter(is.na(Edad)) %>% 
  arrange(HASH_KEY) %>%
  dplyr::select(row, ano_bd, HASH_KEY, id_mod, ano_nac, ano_bd,fech_ing, fech_egres,tipo_de_plan, tipo_de_programa, ID.centro, Edad, SENDA) %>%
 knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 10. Missing Ages among Patients with Wrong Dates of Birth",
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
```

<br>

Only 2 cases were replaced by cases in TOP dataset:

<br>

```{r invalid values in age replaced in TOP, echo=T, cache=T, paged.print=TRUE}
CONS_TOP_df_dup_age <- dplyr::select(CONS_TOP, HASH_KEY, ID, Sexo, Edad)%>% 
  dplyr::filter(Edad>=18, Edad<=90) %>% #%>%  #dim rowa 162449, 4 columns
  dplyr::mutate(id_mod=sub("(.{5}).", "\\1*",ID)) %>%
  dplyr::mutate(id_mod=sub("(.{6}).", "\\1*",id_mod)) %>%
  dplyr::select(-ID) %>%
  dplyr::filter(!duplicated(HASH_KEY)) #dplyr::distinct(HASH_KEY) %>% nrow() #37124 rows, 5 columns
#merge datasets w CONS C1
CONS_C1_df_dup_ENE_2020_prev3  %>% 
  dplyr::filter(is.na(Edad)) %>% 
  arrange(HASH_KEY) %>%
  dplyr::select(row, ano_bd, HASH_KEY, id_mod, ano_nac, ano_bd,fech_ing, fech_egres,tipo_de_plan, tipo_de_programa, ID.centro, Edad, SENDA) %>%
  dplyr::left_join(CONS_TOP_df_dup_age, by="HASH_KEY", suffix= c(".C1",".TOP")) %>%
  dplyr::filter(!is.na(id_mod.TOP)) %>%
  dplyr::select(row, ano_bd, HASH_KEY, id_mod.C1, ano_nac, ano_bd,fech_ing, fech_egres,tipo_de_plan, tipo_de_programa, ID.centro, Edad.C1, Edad.TOP,SENDA) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption="Table 11. Replaced Ages from TOP dataset",
                 align =rep('c', 101))  %>%
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 9) %>%
  kableExtra::scroll_box(width = "100%", height = "175px")
```

```{r final assignment, echo=F,cache=T, paged.print=TRUE}
#Join datasets 
  dplyr::left_join(CONS_C1_df_dup_ENE_2020_prev3, CONS_TOP_df_dup_age, by="HASH_KEY", suffix= c("",".TOP")) %>%
    dplyr::mutate(id= ifelse((Edad<18 & !is.na(Edad.TOP))|(Edad>90 & !is.na(Edad.TOP)),id.TOP, id)) %>%
    dplyr::mutate(id_mod=ifelse((Edad<18 & !is.na(Edad.TOP))|(Edad>90 & !is.na(Edad.TOP)),id_mod.TOP,id_mod)) %>% 
    dplyr::mutate(Edad= ifelse(Edad<18|Edad>90,Edad.TOP, Edad)) %>%
    dplyr::mutate(fech_nac=lubridate::parse_date_time(stringi::stri_sub(id,-8,-1),"dmY"), 
                  Edad_al_ing=lubridate::time_length(difftime(as.Date(fech_ing), as.Date(fech_nac)),"years")) %>%
  dplyr::mutate(fech_nac=replace(fech_nac, is.na(Edad), NA)) %>%
  dplyr::mutate(Edad_al_ing=replace(Edad_al_ing, is.na(Edad), NA)) %>%
   dplyr::select(-id_mod.TOP) %>%  
    #dplyr::group_by(Edad) %>% summarise(n=n()) %>% View()
    assign("CONS_C1_df_dup_ENE_2020",., envir = .GlobalEnv) 
#PARA VER CÓMO SE COMPORTA CON IS.NA
#CONS_C1_df_dup_ENE_2020 %>% dplyr::select(HASH_KEY, ano_bd, id, fech_ing, Edad_al_ing, fech_nac, Edad) %>% #dplyr::mutate(ano=as.numeric(fech_nac)/365.25) %>% dplyr::filter(is.na(Edad)) %>% View()
```

```{r generate data 3, echo=F, paged.print=TRUE}
write.csv2(CONS_C1_df_dup_ENE_2020, file ="CONS_C1_df_dup_ENE_2020.csv")
```

&nbsp;
<br>

## 5. Probabilistic Deduplication

In Table 12 we can see that most of the cases had at least one case with the same combination of HASH-Key and date of admission. We replaced the age of cases with the same HASH-Key and date of admission.

<br>

```{r duplicated rows, echo=T, paged.print=TRUE}

#create the duplicated dataset, following the recommendation to separate columns

duplicated_rows_concat <- data.frame(duplicated_HASH_date = duplicated(CONS_C1_df_dup_ENE_2020[,c("HASH_KEY","fech_ing_ano","fech_ing_mes","fech_ing_dia")]), 
                                     row_dup_HASH_date = 1:nrow(CONS_C1_df_dup_ENE_2020[,c("HASH_KEY","fech_ing_ano","fech_ing_mes","fech_ing_dia")])) #%>%
  #arroja 117,620 casos únicos, aunque son muchos menos
as.data.table(CONS_C1_df_dup_ENE_2020)[, dup_hash_date := .N, by = c("HASH_KEY","fech_ing_ano","fech_ing_mes","fech_ing_dia")] %>% ##dim() #arroja 117,190 casos únicos.
  dplyr::group_by(dup_hash_date) %>%
  dplyr::summarise(n=n()) %>%
  mutate(perc = round(n / sum(n),2)*100) %>%
  mutate(perc = paste0(perc,"%")) %>%
# Duplicated rows
#  data.frame(table(duplicated_rows_concat$duplicated_HASH_date,exclude=NULL),
#            `%`=paste0(round(prop.table(table(duplicated_rows_concat$duplicated_HASH_date,exclude=NULL)),3)*100,"%")) %>%
# as.data.frame(.) %>%  
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 12. Times that the combination of HASH-Key & Date of Admission may appear in the dataset", 
               col.names= c("Times", " Frequencies", "Percentage"),  align =rep('c', 2))  %>%
     kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 12)
```

<br>

In Figure 2 we can see every case and the distribution of duplicated cases in terms of the same and exact HASH key and the same date of admission.

<br>

```{r dup rows, fig.height=4, fig.width=8, warning=FALSE, fig.align = "center", message=F}
require(zoo)
#CONS_C1_df_dup_ENE_2020 %>%
as.data.table(CONS_C1_df_dup_ENE_2020)[, dup_hash_date := .N, by = c("HASH_KEY","fech_ing_ano","fech_ing_mes","fech_ing_dia")] %>% 
  dplyr::mutate(fech_ing_qrt=zoo::as.yearqtr(fech_ing)) %>%
  dplyr::select(fech_ing_qrt,dup_hash_date) %>%  dplyr::group_by(fech_ing_qrt) %>% 
  dplyr::summarise(duplicated = sum(dup_hash_date>1),n = sum(dup_hash_date), perc_dup=duplicated/n) %>%
  dplyr::filter(fech_ing_qrt>=2007) %>%
  ggplot2::ggplot(aes(x = fech_ing_qrt, y = perc_dup, label = paste0("n=",n))) +
  geom_line(color = "#0076A8", size=1) +
  #geom_text(aes(x = fech_ing_qrt, y = perc_dup-0.05, label = paste0(n)), vjust = -1,hjust = 0, angle=45, size=3) +
  sjPlot::theme_sjplot2() +
  labs(y="% of Duplicated Data",x="Years & Quarters, Date of Admission",caption="Note. Two cases with date of admission before 2007 were ignored") + ggtitle( "Figure 2. Duplicated entries  by year and quarter")+
  scale_y_continuous(limits=c(0, .075),labels = scales::percent) +
  scale_x_yearqtr(format="%YQ%q", n=20) +
  theme(axis.text.x = element_text(vjust = 0.5,hjust = 0.5,angle = 60)) 

```

&nbsp;

<br>

Cases shown in Table 12 represent exact matches. But in order to catch some differences that would probabilistically match in terms of HASH-Key and date of admission, we ran data into a package in the software Stata called **`dtalink`**, with the following criteria:

1. Hash Key, with a weight applied of 25 points, in case this variable match, but minus 25 in case that does not match
2. SENDA's ID, with a weight applied of 25 points, in case this variable match, but minus 25 in case that does not match
3. Sex, with a weight applied of 10 points, in case this variable match
4. Center's ID, with a weight applied of 10 points, in case this variable match
5. Date of Admission, with a weight applied of 30 points, in case this variable match, but minus 30 in case that does not match, and a calliper of 5 days to consider as a match a difference of 5 days or less
6. Blocking variable of Age, in order to match each cases between people with the same Age. 
7. Matches will be considered as significant if the match accumulates at least 70 points.

<br>

The code used in stata is shown here:

&nbsp;
<br>

```{stata dtalink, eval=FALSE}
cap ssc install unique

net from https://raw.githubusercontent.com/kkranker/stata-dtalink/master/
net describe dtalink
net install dtalink

* recast int real_fech_ing_mes

cap gen real_fech_ing_ano = real(fech_ing_ano)
cap gen real_fech_ing_mes = real(fech_ing_mes)
cap gen real_fech_ing_dia = real(fech_ing_dia)

cap gen edad_num = real(edad)
 
cap gen date_in = mdy(real_fech_ing_mes, real_fech_ing_dia, real_fech_ing_ano)
cap gen date_in = mdy(fech_ing_mes, fech_ing_dia, fech_ing_ano)

cap tab edad_num if edad_num>90 | edad_num<18

cap mycodebook hash_key if edad_num>90|edad_num<18, compact
return list

cap browse if missing(real(fech_ing_mes))
cap browse if missing(fech_ing)

generate id_match = _n

cap drop _id
dtalink hash_key 25 -25 id 25 -25 sexo 10 0 idcentro 10 0 date_in 30 -30 5, block(edad) cutoff(70) examples (1) describe

duplicates list _id, N
di 180905   - 31598/2

browse _matchID if _score==80
browse if _matchID== 24451
browse  _matchID if _score==90
browse hash_key sexo idcentro date_in edad fech_egres motivodeegreso  if _matchID== 45097
*see duplicated cases
browse _matchID row hash_key id edad sexo nombrecentro idcentro date_in fech_ing fech_egres dias_trat motivodeegreso tipo_de_programa tipo_de_plan senda if _score==90
browse _matchID row hash_key id edad sexo nombrecentro idcentro date_in fech_ing fech_egres dias_trat motivodeegreso tipo_de_programa tipo_de_plan senda if _score==100

```

<br>

An a analysis of probabilistic matches between events by the requirements listed above, showed us 1 case with a missing value in the date of admission, (correspondent to the HASH KEY "6c409c18bf7cc518819dc63c4e8e98ef"), 71 matches with a value of 90 points, and 429 matches with 100 points. Must note that 92.9% of HASHs involved in matching appear around 2 times (very possible considering the match would be produced by the coincidence of HASH Keys), and the remaining 7%, 4 times or more.

<br>

```{r  Case with no date of admission, include=F, eval=F}
CONS_C1 %>%
  dplyr::filter(HASH_KEY=="6c409c18bf7cc518819dc63c4e8e98ef") %>%
  #dplyr::select(row, ano_bd, HASH_KEY, id_mod, ano_nac, ano_bd,fech_ing, fech_egres, dias_trat,tipo_de_plan, tipo_de_programa, ID.centro, Edad) %>%
  head()
CONS_C1_df_dup_ENE_2020 %>%
  dplyr::filter(HASH_KEY=="6c409c18bf7cc518819dc63c4e8e98ef") %>%
  dplyr::select(row, ano_bd, HASH_KEY, id_mod, ano_nac, ano_bd,fech_ing, fech_egres, dias_trat,tipo_de_plan, tipo_de_programa, ID.centro, Edad) %>%
  head()
```

```{r  Fig 3, fig.height=4, fig.width=8, warning=FALSE, fig.align = "center", message=F}
#quantile(matches_hash_freq$n, .80)

#matches_hash_freq <- read.table(file = "clipboard", sep = "\t", header=TRUE)
#matches_hash_freq
prob<- c(1:200)/200 #generate options

#summary(matches_hash_freq)
#
require(readxl)
Duplicates_Matching_ene_2020 <- read_excel("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/Stata Duplicates Match/Duplicates_Matching_ene_2020.xlsx", 
    sheet = "unique value")
#quantile(Duplicates_Matching_ene_2020$n, prob)
hist(Duplicates_Matching_ene_2020$n, main=paste0("Figure 3. Histogram of HASH Keys in matches (n=",nrow(Duplicates_Matching_ene_2020),")"), breaks=10,xlab="Repetitions", ylab="Freq.")
```

<br>

An analysis of duplicated events showed that many ranges between the dates of admission and discharge are overlapping due to derivations, principally by changes in the center of treatment, being the following the most repeated among cases: Centro Tratamiento Adicciones Unidos, Hospital Santa Cruz; and Centro de Tratamiento adicciones Esperanza, Hospital Santa Cruz. This could be seen in the fact that many patients may move from centers 221 to 591, 147 to 358, 164 to 325, or 200 to 203. However, **to identify overlappings in treatments it is necessary to obtain the missing dates, and clean the dates that may be wrong**.

&nbsp;
<br>

Figure 4 let us observe how many treatments overlap. Many patients start from 2000 to nowadays.  This graphic may be seem a bit noisy, but we should see less black colored regions and more white areas between lines.

<br>

```{r  Fig 4, fig.height=10, fig.width=8, warning=FALSE, fig.align = "center", message=F, cache=T}

CONS_C1_df_dup_intervals<- CONS_C1_df_dup_ENE_2020 %>%
  dplyr::mutate(fech_ing_num2=as.numeric(as.Date(fech_ing))) %>%
  dplyr::mutate(fech_egres_num2=as.numeric(as.Date(fech_egres))) %>%
  dplyr::mutate(HASH_KEY_2=HASH_KEY) %>%
  dplyr::select(row,HASH_KEY_2, id_mod, ano_bd,fech_ing, fech_ing_num2,fech_egres,fech_egres_num2,Edad, Nombre.Centro, motivodeegreso, SENDA) %>% 
  dplyr::filter(motivodeegreso!="Derivación") %>%
  as.data.table()

require(sqldf)
require(gridExtra)
  ans3 <- sqldf("SELECT *
                 FROM CONS_C1_df_dup_intervals AS x  
                 INNER JOIN CONS_C1_df_dup_intervals AS y 
                 ON x.HASH_KEY_2 == y.HASH_KEY_2 AND 
                 x.fech_ing_num2 < y.fech_egres_num2 AND x.fech_egres_num2 > y.fech_ing_num2 AND x.row != y.row AND x.SENDA==y.SENDA") 
  #busca mismo hash, distinto row,pero fecha de ingreso menor o igual a la fecha de egreso del otro, y fecha de egreso mayor o igual a la fecha de ingreso del otro. ESTO ES PARA VER SI SE SUPERPONEN.
  random<-round(runif(1, 1, 100),0)
total_plot <- ans3 %>%
    dplyr::arrange(HASH_KEY_2, fech_ing_num2, row) %>% ggplot(.) + 
  geom_segment(aes(x = fech_ing, xend = fech_egres,
                   y = HASH_KEY_2, yend = HASH_KEY_2)) + theme(axis.line=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_text(""),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank()) +
  theme(plot.caption = element_text(hjust = 0, face= "italic")) +
    labs(x = "Dates of admission and discharge", y = "", caption="Note. Only patients that share characteristics and overlap between them")+
    ggtitle("Figure 4.1 Trajectories of every HASH from dates of admission to discharge")
sample_plot <- ans3 %>% 
    dplyr::arrange(HASH_KEY_2, fech_ing_num2, row) %>% 
  dplyr::slice(random:(random+25)) %>%
  mutate(Date = format(as.Date(fech_ing, format = "%Y-%m-%d"))) %>% 
  ggplot(aes(x=Date)) + 
  geom_segment(aes(x = fech_ing, xend = fech_egres,
                   y = HASH_KEY_2, yend = HASH_KEY_2,colour=as.factor(row),size=1/100)) + theme(axis.line=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_text(""),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank()) +
  #scale_x_date(breaks = scales::date_breaks("1 year"), date_labels = "%b %d") +
    theme(plot.caption = element_text(hjust = 0, face= "italic")) +
    labs(x = "Dates of admission and discharge", y = "", caption="Note. Only patients that share characteristics overlap between them",
         subtitle="Sample of 25 cases. Colored lines represent different rows in the dataset, but same HASH")+
    ggtitle("Figure 4.2 Trajectories of every HASH from dates of admission to discharge")
    #+
  #geom_text(vjust = -0.5, hjust=0, size = 1,
  #          aes(x = start_date, y = membershipID, 
  #              label = paste(round(mo_dur, 2), "months")))
grid.arrange(total_plot,sample_plot)

```

In Figure 4, we may notice that `r nrow(ans3)` entries from `r ans3 %>% distinct(HASH_KEY_2) %>% nrow()` different HASHs may share the same HASH Key, both are SENDA programs, but the date of admission is lesser than the date of discharge of another case, and the date of discharge is greater than the date of admission of that other case; and does not include derivation as a cause of discharge. These conditions let us see how many cases overlap with another entry in the dataset.

As can be seen in Table 14, many treatment discharge dates were NULL values, deriving in a misleading count of treatment days, which were calculated as the difference between the date in which the datasets were retrieved and the date of admission. This one of the reasons that this variable may confound the analysis of duplicate data because of different but overlapping treatments, or duplicated treatments. NA's represent the number of treatment days not available.  Considering the numbers exposed, we think that **cases in datasets from 2018 and after  may  be available and not be a part of incompleteness due to right censoring because they may still be in treatment up until the date of retrieval of the datasets (leaving an approximate of 272 HASHs and date of admissions left to analyse).**

<br>

```{r diff between dates,echo=T, paged.print=TRUE}
CONS_C1_df_dup_ENE_2020 %>%
  dplyr::filter(is.na(fech_egres)) %>%
  dplyr::mutate(fech_ing_num=as.numeric(as.Date(fech_ing)), dias_trat_trans= as.numeric(as.Date("2019-11-13"))-fech_ing_num, 
                diff_treat_days=dias_trat-dias_trat_trans) %>% #fecha del día de hoy 
  dplyr::select(HASH_KEY, id_mod, ano_bd, sexo, fech_ing, fech_ing_num, dias_trat_trans,dias_trat,diff_treat_days) %>%
  dplyr::group_by(diff_treat_days, ano_bd) %>%
  dplyr::summarize(n=n()) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 14. Missing Date of Discharge, Difference between Treatment Dates", col.names= c("Treat Days", "Year of Dataset", "N"),  align =rep('c', 3))  %>%
     kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 10) %>%
  kableExtra::add_footnote(c("Assuming the date of retrieval, 2019-11-13"), notation = "none")
#number of hash and date of admission.
#   HASHs_w_o_date_discharge %>%
#            dplyr::mutate(HASH_fecha_ingreso=paste0(HASH_KEY,"_",fech_ing_num)) %>% 
#            dplyr::left_join(combinacion_reemplazada,by="HASH_fecha_ingreso") %>%
#            dplyr::mutate(ano_bd.x=as.numeric(ano_bd.x)) %>%
#            dplyr::filter(is.na(HASH_KEY.y),ano_bd.x<=2017) %>%
#            dplyr::mutate(fech_ingres=as.Date(fech_ing_num)) %>% 
#            dplyr::select(c(1,2,14)) %>%
#            dplyr::rename("HASH"=HASH_KEY.x,"Ano_Base_Datos" =ano_bd.x, "Fecha_Ingreso"=fech_ingres) #%>% nrow()
```

&nbsp;
<br>

Considering that some cases may have the same HASH and date of admission  along the dataset, we found that 54 cases would not be included in the Table 14, because they can be replaced with a propper date of discharge  or inferred by more recent records, according to the information available.

<br>

```{r saving dates w o discharge date,echo=T, paged.print=TRUE,message=F}
HASHs_w_o_date_discharge<- CONS_C1_df_dup_ENE_2020 %>%
          dplyr::filter(is.na(fech_egres)) %>%
          dplyr::mutate(fech_ing_num=as.numeric(as.Date(fech_ing)), dias_trat_trans= as.numeric(as.Date("2019-11-13"))-fech_ing_num, 
                        diff_treat_days=dias_trat-dias_trat_trans,fech_egres_num=as.numeric(as.Date(fech_egres))) %>% #fecha del día de hoy 
          dplyr::select(row, HASH_KEY, id_mod, ano_bd, sexo, fech_ing, fech_ing_num, fech_egres_num, dias_trat_trans,dias_trat,diff_treat_days) %>%
          dplyr::select(HASH_KEY, ano_bd, fech_ing_num) %>%        
          dplyr::distinct(HASH_KEY,fech_ing_num)# %>% dim() 8142

CONS_C1_df_egres2<- CONS_C1_df_dup_ENE_2020 %>%
  dplyr::mutate(fech_ing_num2=as.numeric(as.Date(fech_ing))) %>%
  dplyr::mutate(fech_egres_num2=as.numeric(as.Date(fech_egres))) %>%
  dplyr::mutate(HASH_KEY_2=HASH_KEY) %>%
  dplyr::filter(!is.na(fech_egres)) %>%
  dplyr::select(row,HASH_KEY_2, id_mod, ano_bd,fech_ing, fech_ing_num2,fech_egres,fech_egres_num2,Edad, Nombre.Centro, motivodeegreso) %>% 
  as.data.table()

require(data.table) #v>=1.9.8
 
#54 cases of C1 that do not have dates of discharge,  that can be replaced with cases in C1 that have available dates of discharge but with a date of admission equal  or greater than  the not   available.
CONS_C1_df_egres2[HASHs_w_o_date_discharge, on = .(HASH_KEY_2=HASH_KEY,fech_ing_num2 >= fech_ing_num), nomatch = 0,
      .(row,HASH_KEY,id_mod, ano_bd,fech_ing, fech_egres,Edad,Nombre.Centro,motivodeegreso)] %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
              caption="Table 15. Cases with the same HASH and date of admission, that had a more recent date of discharge", align =rep('c', 101)) %>% 
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 9) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
#Update of 31-12-2019, nomatch= 0 may be wrong. Finally, it was right for this analysis. Similar to left join:
#CONS_C1_df_egres[HASHs_w_o_date_discharge, on = .(HASH_KEY_2=HASH_KEY,fech_ing_num >= fech_ing_num), #nomatch = 0, its an inner join
#      .(row,HASH_KEY,id_mod, ano_bd,fech_ing, fech_egres,Edad,Nombre.Centro,motivodeegreso)]  %>%      dplyr::filter(!is.na(HASH_KEY))
#fuzzyjoin::fuzzy_left_join(as_tibble(HASHs_w_o_date_discharge),as_tibble(CONS_C1_df_egres2),
#                           by = c("HASH_KEY" = "HASH_KEY", "fech_ing_num" <= "fech_ing_num2"), 
#                           match_fun = list(`==`, `>`))
# OR
#sqldf("
#SELECT *
#FROM HASHs_w_o_date_discharge  
#INNER JOIN CONS_C1_df_egres2 
#ON HASHs_w_o_date_discharge.HASH_KEY == CONS_C1_df_egres2.HASH_KEY AND 
#  HASHs_w_o_date_discharge.fech_ing_num <= CONS_C1_df_egres2.fech_ing_num2") 
```

&nbsp;
<br>

In Table 16, we offer a table of each HASH and dates of discharge. This Table may permit to estimate if one of the dates may be replaced by the last date or definetly erase the case.**As stated in the meeting of Jan. 13 of 2020, an alternative would be to impute days of treatment and generate a new date of discharge by adding the days of treatment to the date of admission.**

<br>


```{r analyzing replace of dates w o discharge date,echo=T, paged.print=TRUE, message=F, cache=T}
HASHs_w_o_date_discharge<- CONS_C1_df_dup_ENE_2020 %>%
          dplyr::filter(is.na(fech_egres)) %>%
          dplyr::mutate(fech_ing_num=as.numeric(as.Date(fech_ing)), dias_trat_trans= as.numeric(as.Date("2019-11-13"))-fech_ing_num, 
                        diff_treat_days=dias_trat-dias_trat_trans,fech_egres_num=as.numeric(as.Date(fech_egres))) %>% #fecha del día de hoy 
          dplyr::select(row, HASH_KEY, id_mod, ano_bd, sexo, fech_ing, fech_ing_num, fech_egres_num, dias_trat_trans,dias_trat,diff_treat_days) %>%
          dplyr::select(HASH_KEY, ano_bd, fech_ing_num) %>%        
          dplyr::distinct(HASH_KEY,fech_ing_num)# %>% dim() 8142

CONS_C1_df_egres2<- CONS_C1_df_dup_ENE_2020 %>%
  dplyr::mutate(fech_ing_num2=as.numeric(as.Date(fech_ing))) %>%
  dplyr::mutate(fech_egres_num2=as.numeric(as.Date(fech_egres))) %>%
  dplyr::mutate(HASH_KEY_2=HASH_KEY) %>%
  dplyr::filter(!is.na(fech_egres)) %>%
  dplyr::select(row,HASH_KEY_2, id_mod, ano_bd,fech_ing, fech_ing_num2,fech_egres,fech_egres_num2,Edad, Nombre.Centro, motivodeegreso) %>% 
  as.data.table()
#153394 rows

require(data.table) #v>=1.9.8
#54 cases of C1 that do not have dates of discharge,  that can be replaced with cases in C1 that have available dates of discharge but with a date of admission equal  or greater than  the not   available.
CONS_C1_df_dup_w_date_discharge <- CONS_C1_df_egres2[HASHs_w_o_date_discharge, on = .(HASH_KEY_2=HASH_KEY,fech_ing_num2 >= fech_ing_num), nomatch = 0,
                  .(row,HASH_KEY,id_mod, ano_bd,fech_ing, fech_egres, fech_egres_num2, Edad,Nombre.Centro,motivodeegreso)]
#select hashs for analysis
CONS_C1_df_dup_w_date_discharge_HKEY <-CONS_C1_df_dup_w_date_discharge %>% distinct(HASH_KEY)

dplyr::left_join(CONS_C1_df_dup,CONS_C1_df_dup_w_date_discharge, by = "HASH_KEY", suffix = c("", ".disch")) %>% # dim()
dplyr::mutate(fech_egres_corr= ifelse(is.na(fech_egres),fech_egres_num2,as.character(fech_egres))) %>% 
  dplyr::filter(HASH_KEY %in% as.character(as.vector(unlist(as.data.table(unlist(CONS_C1_df_dup_w_date_discharge_HKEY)))))) %>%
  dplyr::select(row,ano_bd, HASH_KEY, fech_ing, fech_egres, fech_ing.disch, fech_egres.disch, fech_egres_corr) %>%
  dplyr::arrange(HASH_KEY, fech_ing) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
              caption="Table 16. HASHs with more recent date of discharge, for analysis and replace", align =rep('c', 101)) %>% 
   kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 9) %>%
  kableExtra::scroll_box(width = "100%", height = "350px")

#NO SE PUEDEN RESCATAR DE TOPs
#CONS_C1_df_dup_ENE_2020_w_date_disch <- CONS_C1_df_dup_ENE_2020 %>% dplyr::filter(is.na(fech_egres)) #no puedo rescatar de TOP
#CONS_TOP %>%
#  dplyr::mutate(fech_ing= lubridate::parse_date_time(Fecha.de.Ingreso.a.Tratamiento, c("%d/%m/%Y"),exact=T)) %>% #no fallan casos en ser transformados
#  dplyr::filter(TOP=="Egreso", Etapa.del.Tratamiento=="Egreso") %>%
#  dplyr::mutate(fech_ap_top= lubridate::parse_date_time(Fecha.Aplicación.TOP, c("%Y-%m-%d"),exact=T)) %>% #ni un caso falla en ser transformado
#  dplyr::mutate(concat=paste0(HASH_KEY,"_",fech_ing)) %>%
#  dplyr::right_join(CONS_C1_df_dup_ENE_2020_w_date_disch,by="concat") %>% 
#  dplyr::filter(!is.na(fech_ap_top)) %>%
#  dplyr::select(HASH_KEY.x, fech_ing.x,concat,fech_egres,fech_ap_top) %>%View()
```

```{r saving dataset in 3 Rdata,echo=F, paged.print=TRUE}
#NO SE PUEDEN RESCATAR DE TOPs
#CONS_C1_df_dup_ENE_2020_w_date_disch <- CONS_C1_df_dup_ENE_2020 %>% dplyr::filter(is.na(fech_egres)) #no puedo rescatar de TOP
#CONS_TOP %>%
#  dplyr::mutate(fech_ing= lubridate::parse_date_time(Fecha.de.Ingreso.a.Tratamiento, c("%d/%m/%Y"),exact=T)) %>% #no fallan casos en ser transformados
#  dplyr::filter(TOP=="Egreso", Etapa.del.Tratamiento=="Egreso") %>%
#  dplyr::mutate(fech_ap_top= lubridate::parse_date_time(Fecha.Aplicación.TOP, c("%Y-%m-%d"),exact=T)) %>% #ni un caso falla en ser transformado
#  dplyr::mutate(concat=paste0(HASH_KEY,"_",fech_ing)) %>%
#  dplyr::right_join(CONS_C1_df_dup_ENE_2020_w_date_disch,by="concat") %>% 
#  dplyr::filter(!is.na(fech_ap_top)) %>%
#  dplyr::select(HASH_KEY.x, fech_ing.x,concat,fech_egres,fech_ap_top) %>%View()
save.image("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/3.Rdata")
```
<br>

Leaving behind the last questions that may condition the analysis, we ran a probabilistic match based on the criteria defined above in the **`dtalink`** software. In Table 17 there is a selection of probabilistics matches by 90 of the 100 points defined. The first two cases have the same date of admission and cause of discharge, but different dates of discharge and center of treatment and what is more important, they may be overlapping between them along 90 days. In contrast, the following 2 cases below do not overlap, but were matched due to de span of +/-5 days as a calliper.The next 3 cases correspond to a patient that was admitted in 2014-06-04 and may have abandoned a program in a determined center, but ended finishing treatment in another center in 2015. The next match that follows let us interpret that patient was registered in more than one center in a time lapse of 6 days, but the next patient may be in more than one center for 377 days (FEME1_-011993). The patient PAHE1_-111981 was admited for 0 days in a CESFAM, but changed to a therapeutical community inmmediately afterwards. Finally, case YAPO2**121989	and ROMA1_-011979 had the same date of admission but in a different center and not in a program of SENDA.

<br>

```{r saving dates_w_o_discharge_date,echo=T, paged.print=TRUE}
CONS_C1_df_dup_ENE_2020 %>%
dplyr::filter(row %in% c(54760,71542,83766,83830,58436,67549,59294,72579,73114,54953,56452,38864,53878,44514,53958,47284,54973,45002,45995,51619,61353,61572,52659,54383,47377)) %>% 
  dplyr::arrange(factor(row, levels = c(54760,71542,83766,83830,58436,67549,59294,72579,73114,54953,56452,38864,53878,44514,53958,47284,54973,45002,45995,51619,61353,61572,52659,54383,47377))) %>%
  dplyr::select(row,HASH_KEY,id_mod,Edad,Sexo,Nombre.Centro,ID.centro,fech_ing,fech_egres,dias_trat,motivodeegreso,tipo_de_programa,tipo_de_plan,SENDA) %>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
                   caption="Table 17. Example of probabilistic matches", align =rep('c', 101)) %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8)  %>%
  kableExtra::scroll_box(width = "100%", height = "350px")
```
