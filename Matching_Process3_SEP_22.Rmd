---
title: "Ambulatory or residential? a multi-state analysis of treatments for substance use disorders (Step 3)"
date: "`r withr::with_locale(new = c('LC_TIME' = 'C'), code =format(Sys.time(),'%B %d, %Y'))`"
output:
  html_document:
    code_folding: hide  
    toc: true # table of content true
    toc_depth: 5  # upto three depths of headings (specified by #, ## and ###)
    toc_float: true
---

```{css zoom-lib-src, echo = FALSE}
script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"
```

```{js zoom-jquery, echo = FALSE}
 $(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
      $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
      $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
      $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
  });
```

```{=html}
<style type="text/css">
.tablelines table, .tablelines td, .tablelines th {
        border: 1px solid black;
        }
.centrado {
    text-align: center;
}
.table.center {
    margin-left:auto; 
    margin-right:auto;
  }
.table_wrapper{
    display: block;
    overflow-x: auto;
    white-space: nowrap;
}
code.r{
  font-size: 8px;
}
body{ /* Normal  */
      text-align: justify;
  }
.superbigimage{
    overflow-y:scroll;
    white-space: nowrap;
}
.superbigimage img{
    overflow-y: scroll;
    overflow-x: hidden;
}
</style>
```
```{=html}
<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px; text-align: justify;}
</style>
```
```{r prev_setup, include = FALSE, cache=T}
rm(list=ls());gc()
if(!grepl("4.0.2",R.version.string)){stop("Different version (must be 4.0.2)")}
path<-dirname(rstudioapi::getSourceEditorContext()$path)

if (grepl("CISS Fondecyt",path)==T){
    setwd("C:/Users/CISS Fondecyt/Mi unidad/Alvacast/SISTRAT 2019 (github)/SUD_CL/");load("C:/Users/CISS Fondecyt/Mi unidad/Alvacast/SISTRAT 2019 (github)/mult_state_2_apr22.RData")
  } else if (grepl("andre",path)==T){
    setwd('C:/Users/andre/Desktop/SUD_CL/');load("E:/Mi unidad/Alvacast/SISTRAT 2019 (github)/mult_state_2_apr22.RData")
  } else if (grepl("E:",path)==T){
    setwd("E:/Mi unidad/Alvacast/SISTRAT 2019 (github)/SUD_CL/");load("E:/Mi unidad/Alvacast/SISTRAT 2019 (github)/mult_state_2_apr22.RData")
  } else if (grepl("G:",path)==T){
    setwd("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/SUD_CL/");load("E:/Mi unidad/Alvacast/SISTRAT 2019 (github)/mult_state_2_apr22.RData")
  } else {
    setwd("~/");load("~/mult_state_2_apr22.RData");path.expand("~/mult_state_2_apr22.RData")
  }

```

```{r setup, include = FALSE, cache=T}
#Libraries used in the routine. Dont change the order
local({r <- getOption("repos")
       r["CRAN"] <- "http://cran.r-project.org" 
       options(repos=r)
})
copiar_nombres <- function(x,row.names=FALSE,col.names=TRUE,dec=",",...) {
  if(class(ungroup(x))[1]=="tbl_df"){
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)    
        }
  } else {
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)       
  }
 }
}  

try(library(boot))
library(matrixStats)
library(knitr)
library(tidyr)
library(stringi)
library(stringr)
library(ggplot2)
library(Hmisc)
library(kableExtra)
library(plotly)
library(janitor)
library(rbokeh)
library(zoo)
library(broom)
library(sqldf)
library(devtools)
library(codebook)
library(data.table)
library(panelr)
library(RColorBrewer)
library(lsmeans)
library(finalfit)
suppressPackageStartupMessages(library(ggiraph))
suppressPackageStartupMessages(library(sf))
library(treemapify)
library(dplyr)
library(tidyverse)
library(epiR)
library(survminer)
library(ggfortify)
library(survMisc)

library(foreign)
library(Hmisc)
library(gridExtra)
library(reshape2)
library(stargazer)
library(tableone)
library(MatchIt)
library(cobalt)
library(eha)
library(igraph)
library(Amelia)
library(DiagrammeR) 
library(mstate)
library(flexsurv)
library(muhaz)
library(Metrics)
#library(hesim)

if(packageVersion('flexsurv')<2.1){stop("flesurv must have resolved error of centering continuous predictors")}
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:

try_with_time_limit <- function(expr, cpu = Inf, elapsed = Inf)
{
  y <- try({setTimeLimit(cpu, elapsed); expr}, silent = TRUE) 
  if(inherits(y, "try-error")) NULL else y 
}
eval_fork <- function(..., timeout=60){

  #this limit must always be higher than the timeout on the fork!
  setTimeLimit(timeout+5);      

  #dispatch based on method
  ##NOTE!!!!! Due to a bug in mcparallel, we cannot use silent=TRUE for now.
  myfork <- parallel::mcparallel({
    eval(...)
  }, silent=FALSE);

  #wait max n seconds for a result.
  myresult <- parallel::mccollect(myfork, wait=FALSE, timeout=timeout);

  #try to avoid bug/race condition where mccollect returns null without waiting full timeout.
  #see https://github.com/jeroenooms/opencpu/issues/131
  #waits for max another 2 seconds if proc looks dead 
  while(is.null(myresult) && totaltime < timeout && totaltime < 2) {
     Sys.sleep(.1)
     enddtime <- Sys.time();
     totaltime <- as.numeric(enddtime - starttime, units="secs")
     myresult <- parallel::mccollect(myfork, wait = FALSE, timeout = timeout);
  }

  #kill fork after collect has returned
  tools::pskill(myfork$pid, tools::SIGKILL);    
  tools::pskill(-1 * myfork$pid, tools::SIGKILL);  

  #clean up:
  parallel::mccollect(myfork, wait=FALSE);

  #timeout?
  if(is.null(myresult)){
    stop("R call did not return within ", timeout, " seconds. Terminating process.", call.=FALSE);      
  }

  #move this to distinguish between timeout and NULL returns
  myresult <- myresult[[1]];

  #reset timer
  setTimeLimit();     

  #forks don't throw errors themselves
  if(inherits(myresult,"try-error")){
    #stop(myresult, call.=FALSE);
    stop(attr(myresult, "condition"));
  }

  #send the buffered response
  return(myresult);  
}

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:

knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- Sys.time()
    } else {
      # calculate the time difference after a chunk
      res <- ifelse(difftime(Sys.time(), now)>(60^2),difftime(Sys.time(), now)/(60^2),difftime(Sys.time(), now)/(60^1))
      # return a character string to show the time
      warning(ifelse(difftime(Sys.time(), now)>(60^2),paste("Time for this code chunk to run:", round(res,1), "hours"),paste("Time for this code chunk to run:", round(res,1), "minutes")))
    }
  }
}))
knitr::opts_chunk$set(time_it = TRUE)
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:


if(.Platform$OS.type == "windows") withAutoprint({
  memory.size()
  memory.size(TRUE)
  memory.limit()
})
memory.limit(size=56000)
```

<br>

# Cumulative Transition Hazards of Joint Models

Cumulative baseline hazard can be estimated non-parametrically through a Breslow estimator. Must take note that we are assuming a semi-markov process in these transitions. The cumulative hazards obtained through the times specified by `r length(seq(90,1826,length.out=180))` points. 

<br>

```{r msfit2.0, eval=T, echo=T, paged.print=T, error=T}
# Semi-parametric models
#Since there are tied event times, we need to specify ties="breslow" in order to obtain the Aalen-Johansen estimator of
fitform2 <- Surv(time, status) ~  factor(tipo_de_plan_res_1)
n_trans <- max(trans_matrix, na.rm = T)
n_trans2 <- max(trans_matrix, na.rm = T)
n_trans2_9s <- max(trans_matrix2, na.rm = T)
```

<br>

As seen in the formula above, we included the transition-specific covariables regarding the time that arrived to the state into the models.

<br>

<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:650px; overflow-x: scroll; width:100%">
```{r fit3_wcov_pre, eval=T, echo=T, error= T, paged.print=TRUE, warnings =T}
#m2_1_ggam m2_2_ggam m2_3_ggam m2_4_logn
#m2_1_rp5 m2_2_rp4 m2_3_rp2 m2_4_rp3
#defined a series of Royston-Parmar models with a function of restricted cubic splines, in which the knots (#df -1) are defined in each percentile of the distribution. 
fits_c_logn2 <- vector(mode = "list", length = n_trans2)
fits_c_ggam2 <- vector(mode = "list", length = n_trans2)
fits_c_ggam_orig2 <- vector(mode = "list", length = n_trans2)
fits_c_rp042 <- vector(mode = "list", length = n_trans2)
fits_c_rp032 <- vector(mode = "list", length = n_trans2)
fits_c_rp012 <- vector(mode = "list", length = n_trans2)
fits_c_rp022 <- vector(mode = "list", length = n_trans2)


ms_d_match_surv$arrival<-ms_d_match_surv$Tstart
#APR 2022, had to center the variable to avoid convergence issues
ms_d_match_surv_exp<-ms_d_match_surv

#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
no_attempts <- 30

form<-
  function(i=1){
  f<-dplyr::case_when(i==4~paste0("Surv(time, status) ~ ",fitform2," + arrival")[[3]],i==3~paste0("Surv(time, status) ~ ",fitform2," + arrival")[[3]],i==2~paste0("Surv(time, status) ~ ",fitform2," + arrival")[[3]],T~paste0("Surv(time, status) ~ ",fitform2,"")[[3]])
  return(f)
}

for (i in 1:3){
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
        attempt <- attempt + 1
    try(
      r <- flexsurvreg(formula=as.formula(form(i)),
                             data = subset(dplyr::mutate(ms_d_match_surv_exp,arrival=scale(arrival, scale=F)), trans == i),
                             dist = "gengamma.orig")
        )
    }
    fits_c_ggam_orig2[[i]] <- r
}  

for (i in 1:3){
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
      r <- flexsurvreg(formula=as.formula(form(i)),
                                   data = subset(dplyr::mutate(ms_d_match_surv_exp,arrival=scale(arrival, scale=F)), trans == i),
                                   dist = "gengamma")
      )
    }
    fits_c_ggam2[[i]] <- r
}

for (i in 4){
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
      r <- flexsurvreg(formula=as.formula(form(i)),
                                   data = subset(dplyr::mutate(ms_d_match_surv_exp,arrival=scale(arrival, scale=F)), trans == i),
                                   dist = "lnorm")
      )
    }
    fits_c_logn2[[i]] <- r
}  

for (i in 1){
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
      r <- flexsurvspline(formula=as.formula(form(i)),
                            k=4,
                               data = subset(ms_d_match_surv_exp, trans == i))
      )
    }
    fits_c_rp042[[i]] <- r
}
for (i in 2){
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
      r <- flexsurvspline(formula=as.formula(form(i)),
                            k=3,
                               data = subset(ms_d_match_surv_exp, trans == i))
      )
    }
    fits_c_rp032[[i]] <- r
}

for (i in 3){
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
      r <- flexsurvspline(formula=as.formula(form(i)),
                            k=1,
                               data = subset(ms_d_match_surv_exp, trans == i))
      )
    }
    fits_c_rp012[[i]] <- r
}

for (i in 4){
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
      r <- flexsurvspline(formula=as.formula(form(i)),
                            k=2,
                               data = subset(ms_d_match_surv_exp, trans == i))
      )
    }
    fits_c_rp022[[i]] <- r
}
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
```
</div>


<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:650px; overflow-x: scroll; width:100%">
```{r fit3_wcov_pre_9s, eval=T, echo=T, error= T, paged.print=TRUE, warnings =T}
# m2_1_gom m2_2_gom m2_3_logn m2_4_ggam m2_5_logn m2_6_ggam m2_7_ggam m2_8_ggam 
#m2_1_rp9 m2_2_rp10 m2_3_rp10 m2_4_rp7 m2_5_rp3 m2_6_rp4 m2_7_rp4 m2_8_rp2

fits_c_gomp3 <- vector(mode = "list", length = n_trans2_9s)
fits_c_logn3 <- vector(mode = "list", length = n_trans2_9s)
fits_c_ggam3 <- vector(mode = "list", length = n_trans2_9s)
fits_c_ggam_orig3 <- vector(mode = "list", length = n_trans2_9s)
fits_c_rp083 <- vector(mode = "list", length = n_trans2_9s)
fits_c_rp093 <- vector(mode = "list", length = n_trans2_9s)
fits_c_rp063 <- vector(mode = "list", length = n_trans2_9s)
fits_c_rp023 <- vector(mode = "list", length = n_trans2_9s)
fits_c_rp033 <- vector(mode = "list", length = n_trans2_9s)
fits_c_rp013 <- vector(mode = "list", length = n_trans2_9s)


ms_d_match_surv_oct_2022$arrival<-ms_d_match_surv_oct_2022$Tstart
#APR 2022, had to center the variable to avoid convergence issues
ms_d_match_surv_oct_2022_exp<-ms_d_match_surv_oct_2022

#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
no_attempts <- 30

form_9s<-
  function(i=1){
  f<-dplyr::case_when(i==9~paste0("Surv(time, status) ~ ",fitform2," + arrival")[[3]], i==8~paste0("Surv(time, status) ~ ",fitform2," + arrival")[[3]], i==7~paste0("Surv(time, status) ~ ",fitform2," + arrival")[[3]], i==6~paste0("Surv(time, status) ~ ",fitform2," + arrival")[[3]], i==5~paste0("Surv(time, status) ~ ",fitform2," + arrival")[[3]], i==4~paste0("Surv(time, status) ~ ",fitform2," + arrival")[[3]],i==3~paste0("Surv(time, status) ~ ",fitform2," + arrival")[[3]],i==2~paste0("Surv(time, status) ~ ",fitform2,"")[[3]],T~paste0("Surv(time, status) ~ ",fitform2,"")[[3]])
  return(f)
}


#It looks like the hazard is decreasing for a large portion of the follow-up, so the best fitting shape parameter is negative, and positive shape parameters give zero likelihood. I managed to get it to fit using
#https://treeage.zendesk.com/hc/en-us/articles/360002682794-Gompertz-distribution-with-negative-shape-parameter-
#Some implementations of the Gompertz restrict a to be strictly positive, which ensures that the
#probability of survival decreases to zero as x increases to infinity. The more flexible implementation
#given here is consistent with streg in Stata

#Gompertz distribution with unrestricted shape parameter,

for (i in 1:2){
  options(warn = 2)
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
      try(
        r <- flexsurvreg(formula= as.formula(form_9s(i)),
                                   data = subset(dplyr::mutate(ms_d_match_surv_oct_2022_exp,arrival=scale(arrival, scale=F)), trans == i), inits=c(-1, 1/mean(subset(ms_d_match_surv_oct_2022_exp, trans == i)[["time"]])),
                        # control=list(reltol=1e-16,fnscale = 16e2),
                                   dist = "gompertz")
      )
    }
    fits_c_gomp3[[i]] <- r
}
options(warn=0)


for (i in c(3,5)){

    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
        r <- flexsurvreg(formula= as.formula(form_9s(i)),
            data = subset(dplyr::mutate(ms_d_match_surv_oct_2022_exp,arrival=scale(arrival, scale=F)), trans == i),
                                   dist = "lnorm")
      )
    }
    fits_c_logn3[[i]] <- r
}  


for (i in c(4,6,7,8)){
    options(warn = 2)
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
        attempt <- attempt + 1
    try(
        r <- flexsurvreg(formula= as.formula(form_9s(i)),
             data = subset(dplyr::mutate(ms_d_match_surv_oct_2022_exp,arrival=scale(arrival, scale=F)), trans == i), 
                         control=list(reltol=1e-16,fnscale = 16e2, trace=100),
                             dist = "gengamma.orig", )
        )
    }
    fits_c_ggam_orig3[[i]] <- r
}
options(warn=0)

for (i in c(4,6,7,8)){
    options(warn = 2)
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
        r <- flexsurvreg(formula= as.formula(form_9s(i)),
            data = subset(dplyr::mutate(ms_d_match_surv_oct_2022_exp,arrival=scale(arrival, scale=F)), trans == i),
            control=list(reltol=1e-16,fnscale = 16e2, trace=100),
                                   dist = "gengamma")
      )
    }
    fits_c_ggam3[[i]] <- r
}
options(warn=0)

#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
invisible("RP")
#method: SANN, "Nelder-Mead", "CG", L-BFGS-B y BFGS Brent
#file:///C:/Users/CISSFO~1/AppData/Local/Temp/MicrosoftEdgeDownloads/0a14410e-d817-4ad6-a810-99e535568c58/RumenickPereiraDaSilva_DISSERT.pdf

fits_c_rp073[[1]] <- flexsurvspline(Surv(time, status)~ factor(tipo_de_plan_res_1),
    k=7,#k is equivalent to df-1 in the notation of stpm for Stata
    data = subset(ms_d_match_surv_oct_2022_exp, trans == 1), 
    # knots= 
    #inits=c(-1, 1/mean(subset(ms_d_match_surv_oct_2022_exp, trans == i)[["time"]])),
    #control=list(reltol=1e-16, fnscale=16e4, maxit = 4e3, trace=3e2, abstol=1e-16), 
    #en STATA, -41654.94 log-likelihood
    #control= list(trace=3e2, maxit = 4e3, reltol=1e-16, abstol=1e-16), #lower = -Inf, upper = 41654
    hessian=T#,
    #method = "SANN",
    #control = list(maxit = 2e4, temp = 20, trace=1e1) # para SANN
    # knots = log(c(4,12))
    )

fits_c_rp083[[2]] <- flexsurvspline(Surv(time, status)~ factor(tipo_de_plan_res_1),
    k=8,#k is equivalent to df-1 in the notation of stpm for Stata
    data = subset(ms_d_match_surv_oct_2022_exp, trans == 2), 
    # knots= 
    #inits=c(-1, 1/mean(subset(ms_d_match_surv_oct_2022_exp, trans == i)[["time"]])),
    #control=list(reltol=1e-16,fnscale=-16e4, maxit = 4e3, trace=3e2), 
    #en STATA, -41654.94 log-likelihood
    #control= list(trace=3e2, maxit = 4e3, reltol=1e-16, abstol=1e-16), #lower = -Inf, upper = 41654
    hessian=T#,
    #method = "SANN",
    #control = list(maxit = 2e4, temp = 20, trace=1e1) # para SANN
    # knots = log(c(4,12))
    )

for (i in c(3)){
    options(warn = 2)
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
        r <- flexsurvspline(formula= Surv(time, status) ~ factor(tipo_de_plan_res_1) + arrival,
                            k=9,
            data = subset(dplyr::mutate(ms_d_match_surv_oct_2022_exp,arrival=scale(arrival, scale=F)), trans == i),
            control=list(reltol=1e-16, trace=3e2, maxit = 1e3, reltol=1e-16, abstol=1e-16) #fnscale = 1600
        ))
    }
    fits_c_rp093[[i]] <- r
}
options(warn = 0)

for (i in 4){
    options(warn = 2)
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
        r <- flexsurvspline(formula= as.formula(form_9s(i)),
                            k=5,
            data = subset(dplyr::mutate(ms_d_match_surv_oct_2022_exp,arrival=scale(arrival, scale=F)), trans == i),
            control=list(reltol=1e-16,fnscale = 16e2, trace=3e2)    
        ))
    }
    fits_c_rp063[[i]] <- r
}
options(warn = 0)

for (i in 5){
    options(warn = 2)
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
        r <- flexsurvspline(formula= as.formula(form_9s(i)),
                            k=1,
            data = subset(dplyr::mutate(ms_d_match_surv_oct_2022_exp,arrival=scale(arrival, scale=F)), trans == i),
            control=list(reltol=1e-16,fnscale = 16e2, trace=3e2)    
        ))
    }
    fits_c_rp023[[i]] <- r
}
options(warn = 0)

for (i in c(6,7)){
    options(warn = 2)
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
        r <- flexsurvspline(formula= as.formula(form_9s(i)),
                            k=2,
            data = subset(dplyr::mutate(ms_d_match_surv_oct_2022_exp,arrival=scale(arrival, scale=F)), trans == i),
            control=list(reltol=1e-16,fnscale = 16e2, trace=3e2)    
        ))
    }
    fits_c_rp033[[i]] <- r
}
options(warn = 0)

for (i in 8){
    options(warn = 2)
    r <- NULL
    attempt <- 0
    while( is.null(r) && attempt <= no_attempts ) {
      attempt <- attempt + 1
    try(
        r <- flexsurvspline(formula= as.formula(form_9s(i)),
                            k=0,
            data = subset(dplyr::mutate(ms_d_match_surv_oct_2022_exp,arrival=scale(arrival, scale=F)), trans == i),
            control=list(reltol=1e-16,fnscale = 16e2, trace=3e2)    
        ))
    }
    fits_c_rp013[[i]] <- r
}
options(warn = 0)
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_

```
</div>


The scale of arival is centered is set in `r round(attr(scale(ms_d_match_surv_exp$arrival,scale=F),"scaled:center"),1)` days for the 5 states model, and `r round(attr(scale(ms_d_match_surv_oct_2022_exp$arrival,scale=F),"scaled:center"),1)` for the 9 states model.


<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:650px; overflow-x: scroll; width:100%">
```{r msfit2.0.5, eval=T, echo=T, paged.print=T, error=T}
#https://wilmarigl.de/wp-content/uploads/2018/01/tutorial_hr_parsurvmodels.pdf

#> ### First fix a patient with reference values for the covariates
#> ### and 0 for all the time-dependent covariates; this will give the
#> ### baseline hazards

#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_    
# Database to contrast adjustments
newdat_a <- data.table::data.table(tipo_de_plan_res_1= factor(c(rep(1,1*n_trans2))),
  arrival=rep(0,),
  strata= rep(1:n_trans2,1)
                       )
newdat_b <- data.table::data.table(tipo_de_plan_res_1= factor(c(rep(0,1*n_trans2))),
  arrival=rep(0,),
  strata= rep(1:n_trans2,1)
                       )

newdat_c <- data.table::data.table(tipo_de_plan_res_1= factor(c(rep(1,1*n_trans2_9s))),
  arrival=rep(0,),
  strata= rep(1:n_trans2_9s,1)
                       )
newdat_d <- data.table::data.table(tipo_de_plan_res_1= factor(c(rep(0,1*n_trans2_9s))),
  arrival=rep(0,),
  strata= rep(1:n_trans2_9s,1)
                       )

#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#APR 2022- SCALING
newdat_a_sc<-mutate(newdat_a,arrival=scale(1096- attr(scale(ms_d_match_surv_exp$arrival,scale=F),"scaled:center"),scale=F))
newdat_b_sc<-mutate(newdat_b,arrival=scale(1096- attr(scale(ms_d_match_surv_exp$arrival,scale=F),"scaled:center"),scale=F))

newdat_c_sc<-mutate(newdat_c,arrival=scale(731- attr(scale(ms_d_match_surv_oct_2022_exp$arrival,scale=F),"scaled:center"),scale=F))
newdat_d_sc<-mutate(newdat_d,arrival=scale(731- attr(scale(ms_d_match_surv_oct_2022_exp$arrival,scale=F),"scaled:center"),scale=F))

 newdat_a$arrival<-ifelse(newdat_a$arrival==0,1096,newdat_a$arrival)
 newdat_b$arrival<-ifelse(newdat_b$arrival==0,1096,newdat_b$arrival)
 newdat_c$arrival<-ifelse(newdat_c$arrival==0,1096,newdat_c$arrival)
 newdat_d$arrival<-ifelse(newdat_d$arrival==0,1096,newdat_d$arrival)

#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_

fitted_flexsurvreg2<-data.frame()
fit_flexsurvreg2<-data.frame()

#7 distributions
#4 transitions
dists_w_covs_5s_w_arrival<-cbind.data.frame(covs=rep("fits_c_",(7*n_trans)),
              formal=rep(c("Generalized gamma", "Generalized gamma (original)", "Lognormal", paste0("RP0",1:4)),1*n_trans2),
              dist=rep(c("gengamma","gengamma.orig", "lnorm", rep("no dist",4)),n_trans2),
              model=rep(c("ggam2", "ggam_orig2", "logn2", paste0("rp0",1:4,2)),1*n_trans2),
              trans=rep(1:n_trans2, each=7))

dists_w_covs_5s_w_arrival<-dists_w_covs_5s_w_arrival %>% 
  dplyr::filter(model %in% c(paste0("rp0",1:4,"2"),"ggam2","logn2")) %>% 
  dplyr::filter(dplyr::case_when(model=="logn2" & trans==4~T,
                                 model=="ggam2" & trans %in% 1:3~T,
                                 model=="rp022" & trans==4~T,
                                 model=="rp042" & trans==1~T,
                                 model=="rp032" & trans==2~T,
                                 model=="rp012" & trans==3~T,
                                 T~F)) %>% 
  dplyr::mutate(get_nd_a=dplyr::case_when(!grepl("ggam|logn",model)~"newdat_a",T~"newdat_a_sc")) %>% 
  dplyr::mutate(get_nd_b=dplyr::case_when(!grepl("ggam|logn",model)~"newdat_b",T~"newdat_b_sc"))

```
</div>


<div style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:650px; overflow-x: scroll; width:100%">
```{r msfit2.0.5_9s, eval=T, echo=T, paged.print=T, error=T}
# m2_1_gom m2_2_gom m2_3_logn m2_4_ggam m2_5_logn m2_6_ggam m2_7_ggam m2_8_ggam 
#m2_1_rp9 m2_2_rp10 m2_3_rp10 m2_4_rp7 m2_5_rp3 m2_6_rp4 m2_7_rp4 m2_8_rp2
invisible("Every model is scaled in the arrival")

fitted_flexsurvreg3<-data.frame()
fit_flexsurvreg3<-data.frame()
```
</div>

<br>

```{r msfit2.1, eval=T, echo=T, paged.print=T, error=T}
# Semi-parametric models
#Since there are tied event times, we need to specify ties="breslow" in order to obtain the Aalen-Johansen estimator of
#the transition probability

#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
formula3_mstate<-
as.formula(paste0("Surv(time, status) ~", paste0(fitform2," + arrival + strata(trans)")[[3]]))

cox_fits <- survival::coxph(formula3_mstate, 
                            data = ms_d_match_surv_exp, method = "breslow") 

cox_fits_9s <- survival::coxph(formula3_mstate, 
                            data = ms_d_match_surv_oct_2022_exp, method = "breslow") 


paste0("Test the Proportional Hazards Assumption of a Cox Regression:")
cox.zph(cox_fits)
paste0(c("Not-proportional hazards"))


invisible(c("dists_w_covs_5s_w_arrival ver para ver la distribución"))
#1° TRANS, un modelo con splines cúblicos restringidos a 4 nudos (RP05) y la distribución F generalizado (después G-gamma en STATA) obtuvieron un mejor ajuste. En R, el único que Gen-F es peor que RP
#2° TRANS, un modelo con splines cúblicos restringidos a 3 nudos (RP04) y la distribución F generalizado (después G-gamma en STATA) obtuvieron un mejor ajuste.
#3° TRANS, un modelo con splines cúblicos restringidos a 2 nudos (RP03) y la distribución F generalizado (Lognormal en STATA) obtuvieron un mejor ajuste.
#4° TRANS, un modelo con splines cúblicos restringidos a 2 nudos (RP03) y la distribución F generalizado (Lognormal en STATA) obtuvieron un mejor ajuste.
#EN STATA, todos los RPs son mejores que los paramétricos. En R, sólo la transición 3 y 4 tienen menor error en  Gen-F en el max time

invisible("At October 2022")
##m2_1_ggam m2_2_ggam m2_3_ggam m2_4_logn
#m2_1_rp5 m2_2_rp4 m2_3_rp2 m2_4_rp3


sel_param_fits_a <- vector(length = n_trans, mode = "list") 
    sel_param_fits_a[[1]]<- fits_c_ggam2[[1]] #fits_c_genf2[[1]] 
    sel_param_fits_a[[2]]<- fits_c_ggam2[[2]]
    sel_param_fits_a[[3]]<- fits_c_ggam2[[3]] 
    sel_param_fits_a[[4]]<- fits_c_logn2[[4]] 

sel_param_fits_b <- vector(length = n_trans, mode = "list") 
    sel_param_fits_b[[1]]<- fits_c_rp042[[1]] 
    sel_param_fits_b[[2]]<- fits_c_rp032[[2]]
    sel_param_fits_b[[3]]<- fits_c_rp012[[3]]
    sel_param_fits_b[[4]]<- fits_c_rp022[[4]]


# m2_1_gom m2_2_gom m2_3_logn m2_4_ggam m2_5_logn m2_6_ggam m2_7_ggam m2_8_ggam 
#m2_1_rp9 m2_2_rp10 m2_3_rp10 m2_4_rp7 m2_5_rp3 m2_6_rp4 m2_7_rp4 m2_8_rp2

sel_param_fits_c <- vector(length = n_trans2_9s, mode = "list") 
    sel_param_fits_c[[1]]<- fits_c_gomp3[[1]] #fits_c_genf2[[1]] 
    sel_param_fits_c[[2]]<- fits_c_gomp3[[2]]
    sel_param_fits_c[[3]]<- fits_c_logn3[[3]] 
    sel_param_fits_c[[4]]<- fits_c_ggam3[[4]] 
    sel_param_fits_c[[5]]<- fits_c_logn3[[5]] 
    sel_param_fits_c[[6]]<- fits_c_ggam3[[6]] 
    sel_param_fits_c[[7]]<- fits_c_ggam3[[7]] 
    sel_param_fits_c[[8]]<- fits_c_ggam3[[8]] 

sel_param_fits_d <- vector(length = n_trans2_9s, mode = "list") 
    sel_param_fits_d[[1]]<- fits_c_rp083[[1]] 
    sel_param_fits_d[[2]]<- fits_c_rp093[[2]]
    sel_param_fits_d[[3]]<- fits_c_rp093[[3]]
    sel_param_fits_d[[4]]<- fits_c_rp063[[4]]   
    sel_param_fits_d[[5]]<- fits_c_rp023[[5]] 
    sel_param_fits_d[[6]]<- fits_c_rp033[[6]]
    sel_param_fits_d[[7]]<- fits_c_rp033[[7]]
    sel_param_fits_d[[8]]<- fits_c_rp013[[8]]       
```



```{r aft_to_avg_hr_1, eval=T, echo=T, paged.print=TRUE, error=T}
#https://stats.stackexchange.com/questions/533495/can-one-compare-hazard-ratio-and-average-hazard-ratio?noredirect=1&lq=1
#2_1_gom m2_2_gom m2_3_logn m2_4_ggam m2_5_logn m2_6_ggam m2_7_ggam m2_8_ggam 

calcAHRgeo <- function(x, h0, h1, ft, wt){
integrand <- function(x){ log(h1(x)/h0(x)) * wt(x) * ft(x) }
logahr <- integrate(integrand, lower=0, upper=x)$value
ahr <- exp(logahr)
return(ahr)
}


#https://wilmarigl.de/wp-content/uploads/2018/01/tutorial_hr_parsurvmodels.pdf
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
invisible("Log-normal")#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
require(flexsurv)

logn_aft_to_ahr<-
function(x, trans){
  fit.lnm<-get(x)[[trans]]
    # Probability Density Functions
    f0 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    dlnorm(x=x, meanlog=meanlog, sdlog=sdlog)
    }
    f1 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"]+coef(fit.lnm)["factor(tipo_de_plan_res_1)1"],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    dlnorm(x=x, meanlog=meanlog, sdlog=sdlog)
    }
    ft <- function(x){ (f0(x) + f1(x))}
    # Survival functions
    S0 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    plnorm(q=x, meanlog=meanlog, sdlog=sdlog, lower=FALSE)
    }
    S1 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"]+coef(fit.lnm)["factor(tipo_de_plan_res_1)1"],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    plnorm(q=x, meanlog=meanlog, sdlog=sdlog, lower=FALSE)
    }
    St <- function(x){ ( S0(x) * f0(x) + S1(x) * f1(x) ) / ( f0(x) + f1(x) ) }
    ## St <- function(x){ (S0(x) + S1(x))/2} ## assuming same number of events
    # Hazard functions
    h0 <- function(x, f=f0, S=S0){f(x)/S(x)}
    h1 <- function(x, f=f1, S=S1){f(x)/S(x)}
    newList <- list("90 days" = calcAHRgeo(x=90, h0=h0, h1=h1, ft=ft, wt=St), 
                    "1 year" = calcAHRgeo(x=365.25, h0=h0, h1=h1, ft=ft, wt=St),
                    "3 years" = calcAHRgeo(x=1096, h0=h0, h1=h1, ft=ft, wt=St),
                    "5 years" = calcAHRgeo(x=1826, h0=h0, h1=h1, ft=ft, wt=St)
                    )
    return(newList)
}

logn_aft_to_ahr_lo<-
function(x, trans){
  fit.lnm<-get(x)[[trans]]
    # Probability Density Functions
    f0 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    dlnorm(x=x, meanlog=meanlog, sdlog=sdlog)
    }
    f1 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"]+confint(fit.lnm)["factor(tipo_de_plan_res_1)1",1],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    dlnorm(x=x, meanlog=meanlog, sdlog=sdlog)
    }
    ft <- function(x){ (f0(x) + f1(x))}
    # Survival functions
    S0 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    plnorm(q=x, meanlog=meanlog, sdlog=sdlog, lower=FALSE)
    }
    S1 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"]+confint(fit.lnm)["factor(tipo_de_plan_res_1)1",1],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    plnorm(q=x, meanlog=meanlog, sdlog=sdlog, lower=FALSE)
    }
    St <- function(x){ ( S0(x) * f0(x) + S1(x) * f1(x) ) / ( f0(x) + f1(x) ) }
    ## St <- function(x){ (S0(x) + S1(x))/2} ## assuming same number of events
    # Hazard functions
    h0 <- function(x, f=f0, S=S0){f(x)/S(x)}
    h1 <- function(x, f=f1, S=S1){f(x)/S(x)}
    newList <- list("90 days" = calcAHRgeo(x=90, h0=h0, h1=h1, ft=ft, wt=St), 
                    "1 year" = calcAHRgeo(x=365.25, h0=h0, h1=h1, ft=ft, wt=St),
                    "3 years" = calcAHRgeo(x=1096, h0=h0, h1=h1, ft=ft, wt=St),
                    "5 years" = calcAHRgeo(x=1826, h0=h0, h1=h1, ft=ft, wt=St)
                    )
    return(newList)
}

logn_aft_to_ahr_up<-
function(x, trans){
  fit.lnm<-get(x)[[trans]]
    # Probability Density Functions
    f0 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    dlnorm(x=x, meanlog=meanlog, sdlog=sdlog)
    }
    f1 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"]+confint(fit.lnm)["factor(tipo_de_plan_res_1)1",2],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    dlnorm(x=x, meanlog=meanlog, sdlog=sdlog)
    }
    ft <- function(x){ (f0(x) + f1(x))}
    # Survival functions
    S0 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    plnorm(q=x, meanlog=meanlog, sdlog=sdlog, lower=FALSE)
    }
    S1 <- function(x,
    meanlog = coef(fit.lnm)["meanlog"]+confint(fit.lnm)["factor(tipo_de_plan_res_1)1",2],
    sdlog = exp(coef(fit.lnm)["sdlog"])){
    plnorm(q=x, meanlog=meanlog, sdlog=sdlog, lower=FALSE)
    }
    St <- function(x){ ( S0(x) * f0(x) + S1(x) * f1(x) ) / ( f0(x) + f1(x) ) }
    ## St <- function(x){ (S0(x) + S1(x))/2} ## assuming same number of events
    # Hazard functions
    h0 <- function(x, f=f0, S=S0){f(x)/S(x)}
    h1 <- function(x, f=f1, S=S1){f(x)/S(x)}
    newList <- list("90 days" = calcAHRgeo(x=90, h0=h0, h1=h1, ft=ft, wt=St), 
                    "1 year" = calcAHRgeo(x=365.25, h0=h0, h1=h1, ft=ft, wt=St),
                    "3 years" = calcAHRgeo(x=1096, h0=h0, h1=h1, ft=ft, wt=St),
                    "5 years" = calcAHRgeo(x=1826, h0=h0, h1=h1, ft=ft, wt=St)
                    )
    return(newList)
}
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
invisible("Generalized gamma")#_#_#_#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_#_
# Probability Density Functions
ggam_aft_to_ahr<-
function(x, trans){
  fit.ggm<-get(x)[[trans]]
    f0 <- function(x,
    mu = coef(fit.ggm)["mu"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    dgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    f1 <- function(x,
    mu = coef(fit.ggm)["mu"]+coef(fit.ggm)["factor(tipo_de_plan_res_1)1"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    dgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    ft <- function(x){ (f0(x) + f1(x))}
    # Cumulative Density Functions
    S0 <- function(x,
    mu = coef(fit.ggm)["mu"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    pgengamma(q=x, mu=mu, sigma=sigma, Q=Q, lower=FALSE)
    }
    S1 <- function(x,
    mu = coef(fit.ggm)["mu"]+coef(fit.ggm)["factor(tipo_de_plan_res_1)1"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    pgengamma(q=x, mu=mu, sigma=sigma, Q=Q, lower=FALSE)
    }
    St <- function(x){ ( S0(x) * f0(x) + S1(x) * f1(x) ) / ( f0(x) + f1(x) ) }
    ## St <- function(x){ (S0(x) + S1(x))/2} ## assuming same number of events
    ## Hazard functions
    h0 <- function(x,
    mu = coef(fit.ggm)["mu"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    hgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    h1 <- function(x,
    mu = coef(fit.ggm)["mu"]+coef(fit.ggm)["factor(tipo_de_plan_res_1)1"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    hgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    
    newList <- list("90 days" = calcAHRgeo(x=90, h0=h0, h1=h1, ft=ft, wt=St), 
                    "1 year" = calcAHRgeo(x=365.25, h0=h0, h1=h1, ft=ft, wt=St),
                    "3 years" = calcAHRgeo(x=1096, h0=h0, h1=h1, ft=ft, wt=St),
                    "5 years" = calcAHRgeo(x=1826, h0=h0, h1=h1, ft=ft, wt=St)
                    )
    return(newList)
}
ggam_aft_to_ahr_lo<-
function(x, trans){
  fit.ggm<-get(x)[[trans]]
    f0 <- function(x,
    mu = coef(fit.ggm)["mu"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    dgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    f1 <- function(x,
    mu = coef(fit.ggm)["mu"]+confint(fit.ggm)["factor(tipo_de_plan_res_1)1",1],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    dgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    ft <- function(x){ (f0(x) + f1(x))}
    # Cumulative Density Functions
    S0 <- function(x,
    mu = coef(fit.ggm)["mu"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    pgengamma(q=x, mu=mu, sigma=sigma, Q=Q, lower=FALSE)
    }
    S1 <- function(x,
    mu = coef(fit.ggm)["mu"]+confint(fit.ggm)["factor(tipo_de_plan_res_1)1",1],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    pgengamma(q=x, mu=mu, sigma=sigma, Q=Q, lower=FALSE)
    }
    St <- function(x){ ( S0(x) * f0(x) + S1(x) * f1(x) ) / ( f0(x) + f1(x) ) }
    ## St <- function(x){ (S0(x) + S1(x))/2} ## assuming same number of events
    ## Hazard functions
    h0 <- function(x,
    mu = coef(fit.ggm)["mu"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    hgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    h1 <- function(x,
    mu = coef(fit.ggm)["mu"]+confint(fit.ggm)["factor(tipo_de_plan_res_1)1",1],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    hgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    
    newList <- list("90 days" = calcAHRgeo(x=90, h0=h0, h1=h1, ft=ft, wt=St), 
                    "1 year" = calcAHRgeo(x=365.25, h0=h0, h1=h1, ft=ft, wt=St),
                    "3 years" = calcAHRgeo(x=1096, h0=h0, h1=h1, ft=ft, wt=St),
                    "5 years" = calcAHRgeo(x=1826, h0=h0, h1=h1, ft=ft, wt=St)
                    )
    return(newList)
}
ggam_aft_to_ahr_up<-
function(x, trans){
  fit.ggm<-get(x)[[trans]]
    f0 <- function(x,
    mu = coef(fit.ggm)["mu"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    dgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    f1 <- function(x,
    mu = coef(fit.ggm)["mu"]+confint(fit.ggm)["factor(tipo_de_plan_res_1)1",2],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    dgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    ft <- function(x){ (f0(x) + f1(x))}
    # Cumulative Density Functions
    S0 <- function(x,
    mu = coef(fit.ggm)["mu"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    pgengamma(q=x, mu=mu, sigma=sigma, Q=Q, lower=FALSE)
    }
    S1 <- function(x,
    mu = coef(fit.ggm)["mu"]+confint(fit.ggm)["factor(tipo_de_plan_res_1)1",2],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    pgengamma(q=x, mu=mu, sigma=sigma, Q=Q, lower=FALSE)
    }
    St <- function(x){ ( S0(x) * f0(x) + S1(x) * f1(x) ) / ( f0(x) + f1(x) ) }
    ## St <- function(x){ (S0(x) + S1(x))/2} ## assuming same number of events
    ## Hazard functions
    h0 <- function(x,
    mu = coef(fit.ggm)["mu"],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    hgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    h1 <- function(x,
    mu = coef(fit.ggm)["mu"]+confint(fit.ggm)["factor(tipo_de_plan_res_1)1",2],
    sigma =exp(coef(fit.ggm)["sigma"]),
    Q = coef(fit.ggm)["Q"]){
    hgengamma(x=x, mu=mu, sigma=sigma, Q=Q)
    }
    
    newList <- list("90 days" = calcAHRgeo(x=90, h0=h0, h1=h1, ft=ft, wt=St), 
                    "1 year" = calcAHRgeo(x=365.25, h0=h0, h1=h1, ft=ft, wt=St),
                    "3 years" = calcAHRgeo(x=1096, h0=h0, h1=h1, ft=ft, wt=St),
                    "5 years" = calcAHRgeo(x=1826, h0=h0, h1=h1, ft=ft, wt=St)
                    )
    return(newList)
}

print("Average hazard ratio")


cat("Model of 5 states, first transition")
ggam_aft_to_ahr("fits_c_ggam2",1)



cat("Model of 9 states, transitions 3 4 5 6 7 8")

logn_aft_to_ahr("fits_c_logn3",3)
logn_aft_to_ahr_lo("fits_c_logn3",3)
logn_aft_to_ahr_up("fits_c_logn3",3)

ggam_aft_to_ahr( "fits_c_ggam3", 4)
ggam_aft_to_ahr_lo( "fits_c_ggam3", 4)
ggam_aft_to_ahr_up( "fits_c_ggam3", 4)

logn_aft_to_ahr("fits_c_logn3",5)

ggam_aft_to_ahr( "fits_c_ggam3", 6)

try(ggam_aft_to_ahr( "fits_c_ggam3", 7)) #error

ggam_aft_to_ahr( "fits_c_ggam3", 8)

#aHR

# cat("The average HR (residential:outpatient) for patients with a follow-up period of",
#     "3 months",
#     "\nthe average hazard ratio is ",
#     round(ahr.maxt3m, 2), ".")
```


```{r aft_to_avg_hr_1_2, eval=T, echo=T, paged.print=TRUE, error=T}
#https://stats.stackexchange.com/questions/533495/can-one-compare-hazard-ratio-and-average-hazard-ratio?noredirect=1&lq=1

#The OC is the probability P(T1 < T0) that a randomly chosen survival time T1 from group G1 is smaller than a randomly
#chosen survival time T0 from group G0. 

# The concordance probability represents the pairwise probability of lower patient risk given longer survival time. The c-index and the concordance probability estimate have been used to estimate the concordance probability when patient-specific risk scores are continuous. 
# average HRs which them selves approximate the odds of concordance, defined for two treatment groups A and B as OC = P(TA < TB)/P(TB < TA), where TA and TB denote survival times from two subjects randomly selected from these groups. Odds of concordance can be conveniently transformed into concordance probabilities c = P(TA < TB) = OC/(OC + 1), which are intuitive effect size measures
# probabilidad de que grupo B[ambulatorio] tenga >T que A[residencial]
# /probabilidad de que grupo A[residencial] tenga >T que B[ambulatorio]
# AHR (average hazard ratio) setting, the weight for all cases at risk at an event time t is set to the product of the estimated survival probability and the inverse of the estimated probability of censoring at that time.
# AHR: La ponderación por cada tiempo evento t es= p(supervivencia)* 1/p(censura|t)

```

<br>

# Session Info

```{r session_info, echo=T, error=T, paged.print=TRUE}
Sys.getenv("R_LIBS_USER")

rstudioapi::getSourceEditorContext()

if (grepl("CISS Fondecyt",rstudioapi::getSourceEditorContext()$path)==T){
    save.image("C:/Users/CISS Fondecyt/Mi unidad/Alvacast/SISTRAT 2019 (github)/mult_state_3_apr22.RData")
  } else if (grepl("andre",rstudioapi::getSourceEditorContext()$path)==T){
    save.image("C:/Users/andre/Desktop/SUD_CL/mult_state_3_apr22.RData")
  } else if (grepl("E:",rstudioapi::getSourceEditorContext()$path)==T){
    save.image("E:/Mi unidad/Alvacast/SISTRAT 2019 (github)/mult_state_3_apr22.RData")
  } else if (grepl("G:",rstudioapi::getSourceEditorContext()$path)==T){
    save.image("G:/Mi unidad/Alvacast/SISTRAT 2019 (github)/mult_state_3_apr22.RData")
  } else {
    save.image("~/mult_state_3_apr22.RData")
    path.expand("~/mult_state_3_apr22.RData")
  }

sessionInfo()
sesion_info <- devtools::session_info()
dplyr::select(
  tibble::as_tibble(sesion_info$packages),
  c(package, loadedversion, source)
) %>% 
  DT::datatable(filter = 'top', colnames = c('Row number' =1,'Variable' = 2, 'Percentage'= 3),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        '', htmltools::em('Packages')),
      options=list(
initComplete = htmlwidgets::JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```
